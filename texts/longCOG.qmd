---
title: "Preoperative Cognitive Profile Predictive of Cognitive Decline after Subthalamic Deep Brain Stimulation in Parkinson’s Disease"
shorttitle: "Cognition in PD after STN DBS"
author:
  - name: Josef Mana
    corresponding: false
    orcid: "0000-0002-7817-3978"
    email: "josef.mana@protonmail.com"
    role:
      - Conceptualization
      - Data curation
      - Investigation
      - Formal analysis
      - Methodology
      - Software
      - Visualization
      - Writing - original draft
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Ondrej Bezdicek
    corresponding: true
    orcid: "0000-0002-5108-0181"
    email: "ondrej.bezdicek@gmail.com"
    role:
      - Conceptualization
      - Data curation
      - Investigation
      - Methodology
      - Supervision
      - Writing - original draft
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Filip Ruzicka
    corresponding: false
    email: "filr@seznam.cz"
    role:
      - Investigation
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Anna Fecikova
    corresponding: false
    email: "Anna.Fecikova@vfn.cz"
    role:
      - Investigation
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Olga Klempirova
    corresponding: false
    email: "novakovaol@seznam.cz"
    role:
      - Investigation
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Tomas Nikolai
    corresponding: false
    email: "nikolai@centrum.cz"
    role:
      - Investigation
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Tereza Uhrova
    corresponding: false
    email: "tereza.uhrova@vfn.cz"
    role:
      - Investigation
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Evzen Ruzicka
    corresponding: false
    email: "eruzi@lf1.cuni.cz"
    role:
      - Conceptualization
      - Funding acquisition
      - Investigation
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Dusan Urgosik
    corresponding: false
    email: "urgosik@gmail.com"
    role:
      - Investigation
    affiliations:
      - id: "NHH"
        name: "Na Homolce Hospital, Prague, Czech Republic"
        department: "Department of stereotactic and radiation neurosurgery"
  - name: Robert Jech
    corresponding: false
    orcid: "0000-0002-9732-8947"
    email: "jech@cesnet.cz"
    role:
      - Conceptualization
      - Data curation
      - Funding acquisition
      - Investigation
      - Resources
      - Supervision
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
abstract: "Cognitive decline represents a severe non-motor symptom of Parkinson’s disease (PD) that can significantly reduce benefits of subthalamic deep brain stimulation (STN DBS). Here, we aimed to identify pre-surgery cognitive profile associated with faster post-surgery cognitive decline in STN DBS treated PD patients to characterize patients who could benefit from more monitoring during treatment course. A retrospective observational study of 126 PD patients treated by STN DBS combined with oral dopaminergic therapy followed for 3.54 years on average (SD = 2.32) with repeated assessments of cognition was conducted. Pre-surgery cognitive profile was obtained via a comprehensive neuropsychological examination. Data were analyzed using exploratory factor analysis for pre-surgery cognitive profile extraction and Bayesian generalized linear mixed models for description of the longitudinal cognitive outcome. Overall, we observed a mild annual cognitive decline of 0.90 points from a total of 144 points in the Mattis Dementia Rating Scale (95% posterior probability interval (PPI) [-1.19, -0.62]). Pre-surgery executive deficit predicted the rate of post-surgery cognitive decline (b = -0.39, 95% PPI [-0.63, -0.15]). The predictive utility of pre-surgery executive deficit resulted from summing small effects of several single test scores. Patients with PD treated with STN DBS experience only mild annual post-surgery cognitive decline. According to our data and models patients with worse long-term cognitive prognosis can be identified via pre-surgery examination of executive functions. Aggregating results from multiple executive tests to estimate cognitive prognosis of PD patients treated with STN DBS is likely superior to examining single test scores."
keywords:
  - Parkinson’s disease
  - deep brain stimulation
  - cognition
  - longitudinal
  - latent variable analysis
format:
 apaquarto-pdf:
   documentmode: man
   a4paper: true
   pdf-engine: lualatex
   floatsintext: false
   keep-tex: false
bibliography: references.bib
warning: false
echo: false
---

{{< include _extensions/wjschne/apaquarto/_apa_title.qmd >}}

# Introduction

Bilateral subthalamic nucleus (STN) deep brain stimulation (DBS) is an advanced symptomatic treatment of Parkinson’s disease (PD) that can successfully reduce motor symptoms and improve patients’ quality of life [@armstrong2020; @bratsos2018]. On the other hand, prior research revealed considerable heterogeneity in cognitive outcomes after STN DBS with a small to moderate post-surgery decline in verbal fluency and equivocal results for other cognitive domains [@combs2015; @mehanna2017; @parsons2006]. The ability to predict which patients are likely to develop post-surgery cognitive decline can thus prove useful for patient selection and for guiding post-surgery patient monitoring. In this article, we aim to describe pre-surgery cognitive profile extractable from clinically available neuropsychological evaluation that indicates higher risk of long-term post-surgery cognitive decline in everyday clinical settings.

Studies addressing the task of predicting post-surgery cognitive decline in STN DBS treated PD patients can be broadly divided to two groups, randomized controlled trials (RCT) and long-term observational studies. In a typical RCT, patients are randomized to treatment and placebo groups and outcomes are compared in a full factorial design (evaluating interactions between group and time of assessment as the estimand of interest). Courtesy of their experimental control RCTs allow for causal inference and are well suited for providing guidelines for patient selection. However, even though RCTs are regarded as a gold standard for causal inference, it is ethically unacceptable to deny DBS treatment for PD patients for longer time intervals than necessary. Long-term (i.e., more than three years after surgery) outcomes can thus be best described by observational studies. While observational studies usually do not allow for causal inference and are not well suited for guiding patient selection due to a lack of proper control group and resulting collider bias [@cinelli2022], they are well suited for description of patients’ long-term outcomes. Longitudinal observational studies can serve as a basis for selecting high-risk STN DBS treated patients that would benefit from increased monitoring.

Previous longitudinal observational studies reported that PD patients treated with STN DBS showing pre-surgery deficit in attention and executive functions are at risk of faster post- surgery cognitive decline or developing dementia [@bove2020; @gruber2019; @kim2014; @kishore2019; @smeding2009]. However, previous studies aimed at identifying any possible pre-surgery predictors of post-surgery cognitive decline accepting high false positive error rates in the process. In this study, we complement prior findings by identifying a sparse solution to the problem of identifying pre-surgery cognitive profile that is predictive of long-term post-surgery cognitive decline in naturalistic clinical settings. In other words, we aim to describe a minimal significant pre-surgery cognitive profile that predicts higher rate of post-surgery cognitive decline in a sample derived from everyday clinical practice.

In a typical observational study aiming to determine pre-surgery risk factors of post- surgery cognitive decline the authors employ the following two-step procedure. In the first step, a series of separate univariate analyses for each potential predictor is conducted to pre-select variables for further analysis. In the second step, predictors that achieved an arbitrary threshold (e.g., p \< 0.05) are used to predict the cognitive decline in a subsequent multiple regression model [@bove2020; @gruber2019; @kim2014; @smeding2009]. This procedure can lead to false positive error rates that are magnitudes higher than the expected nominal five percent. To overcome this shortcoming, we apply to our data the Bayesian Lasso regression, a method developed for identifying small amount of significant predictors out of a larger pool of possible predictors such as results from a comprehensive neuropsychological battery [@park2008].

Another way to achieve sparsity in prediction of post-surgery cognitive decline is to reduce the number of potential predictors. In the context of neuropsychological assessment this can be accomplished straightforwardly via a latent variable approach such as factor analysis that statistically extracts commonalities across several cognitive tasks. Added benefit of employing such a procedure to pre-surgery predictors is that latent variable approaches can reduce the impact of the task impurity problem – the observation that any cognitive task involves several cognitive functions at once [@burgess2014; @whitney2010a].

Overall, in this study we aimed to derive a sparse solution to the task of identifying pre- surgery cognitive profile predictive of long-term post-surgery cognitive decline in STN DBS treated PD patients. In other words, instead of identifying any pre-surgery cognitive variables that can be predictive of post-surgery decline, we aimed to identify only the most likely predictive ones. To this end, we asked the following research questions: *RQ1)* What is the size of expected long-term rate of cognitive decline after STN DBS in PD patients? *RQ2)* What is the pre-surgery cognitive profile that is predictive of long-term post-surgery cognitive decline in STN DBS treated PD? To answer these questions, we analyzed data of retrospectively sampled longitudinally followed STN DBS treated PD patients with a single pre-surgery comprehensive neuropsychological assessment and up to five post-surgery cognitive screening assessments.

# Materials and methods

## Participants

The data of all patients diagnosed with idiopathic PD following United Kingdom Parkinson’s Disease Society Brain Bank Criteria [@hughes1992] that underwent cognitive evaluation for STN DBS treatment at General University Hospital in Prague between years 2000 and 2020 were retrospectively gathered from clinical records and considered for inclusion in the study. Patients with atypical parkinsonian syndromes, dementia, depression at the time of pre- surgery assessment (according to an independent psychiatric evaluation), recurrent psychotic conditions or a gait disorder despite optimal dopaminergic therapy during pre-surgery assessment were not implanted and were thus not included in the study. Furthermore, only patients who underwent pre-surgery and at least one post-surgery assessment were included. All included patients were treated via continuous bilateral STN DBS in conjunction with dopaminergic therapy. Bilateral STN DBS implantation was performed as previously described [@jech2012; @jech2006; @urgosik2011]. All patients provided signed informed consent and the study was approved by the General University Hospital Ethics Committee in Prague, Czech Republic.

## Assessments

All patients underwent a comprehensive pre-surgery assessment including neuropsychological and neurological examinations. The patients were followed up post-surgery with similar examination protocol at varying time intervals according to their options. Post- surgery, patients were first contacted one year after the surgery and every two years afterwards. The pre-surgery assessment was performed with the usual dopaminergic therapy (ON medication). In the post-surgery assessment, patients were examined in the ON medication condition and STN DBS ON with optimal stimulation parameters.

### Pre-surgery neuropsychological measures

The neuropsychological assessment was arranged analogously to the standard International Parkinson and Movement Disorder Society (MDS) neuropsychological battery at Level II for mild cognitive impairment in Parkinson’s disease (PD-MCI) [@bezdicek2017; @litvan2012]. The battery consisted of 10 tests in 5 cognitive domains: (i) attention: Trail Making Test, part A (TMT-A) [@bezdicek2012; @bezdicek2017a; @partington1949] and dot color naming condition from Prague Stroop Test (PST-D) [@bezdicek2015a] for sustained visual attention; (ii) executive functions: Trail Making Test, part B (TMT-B) [@bezdicek2012; @bezdicek2017a; @partington1949] for set shifting, and Tower of London task (TOL) [@michalec2017; @shallice1982] for planning; (iii) language: Similarities (Sim.) from Wechsler Adult Intelligence Scale, third revision (WAIS-III) [@wechsler2010] for conceptualization, and category verbal fluency test (CFT, category Animals) [@nikolai2015] for speeded word production; (iv) working memory: Digit Span backward (DS-B) from WAIS-III [@wechsler2010] and Spatial Span backward (SS-B) from Wechsler Memory Scale, third edition (WMS-III) [@wechsler2011] for auditory and spatial working memory respectively; and (v) memory: Rey Auditory Verbal Learning Test delayed recall (RAVLT-DR) [@bezdicek2014; @frydrychova2018] for explicit verbal learning and memory, and WMS-III Family Pictures delayed recall (FP-DR) for visuo-spatial memory [@wechsler2011]. Furthermore, we administered the following tests beyond the battery: Prague Stroop Test, naming color of neutral words (PST-W) and interference condition (i.e., naming color of contrasting color words, PST-C) for sensitivity to interference [@bezdicek2015a], Controlled Oral Word Association Test (COWAT, letters K + P) [@nikolai2015] for mental flexibility, and WMS-III letter-number sequencing (LNS) [@wechsler2011] for working memory. Finally, anxiety was assessed with the State-Trait Anxiety Inventory for the state (STAI-X1) and trait (STAI-X2) anxiety [@spielberger1983].

### Longitudinal neuropsychological measures

Patients’ longitudinal cognitive state was assessed pre-surgery and post-surgery with MDS battery at Level I using Mattis Dementia Rating Scale, second edition (DRS-2) [@bezdicek2015; @jurica2001]. DRS-2 is a routinely employed cognitive screening measure in PD that has been shown to have acceptable discriminative performance for PD-MCI in Czech population with both sensitivity estimated to be around 0.8 [@bezdicek2015; @mazancova2020]. Furthermore, subjective depressive symptoms were assessed with Beck Depression Inventory, second edition (BDI-II) [@beck1996; @ciharova2020] at each assessment. BDI-II was not used for pre-surgery exclusion due to depression which was instead ascertained by an independent neuropsychiatric evaluation.

### Neurological examination

Patients’ motor state was assessed with part three of the Movement Disorders Society Unified Parkinson's Disease Rating Scale (MDS-UPDRS III) in medication ON and medication OFF state during the pre-surgery levodopa test. Scores of patients who underwent the older version of the Unified Parkinson’s Disease Rating Scale (UPDRS III) were converted to the MDS-UPDRS III scale using the method described by @hentz2015. The levodopa equivalent daily dose (LEDD) was calculated at each assessment time-point according to @tomlinson2010.

## Statistical analysies

### Deriving pre-surgery cognitive profile

Latent cognitive factors were extracted from the data via an exploratory factor analysis (EFA) with varimax rotation using ordinary least squares to find the minimum residual solution [@harman1966]. We opted for the orthogonal varimax rotation because: (i) extracting orthogonal factors can be statistically advantageous in later steps of our analysis due to reducing multicollinearity, and (ii) in the framework of PD-MCI, it is considered desirable to describe patients’ cognitive profile by factors or tests that are independent of each other [@litvan2012].

All pre-surgery cognitive tests listed above were entered into EFA as input variables (see Supplementary Materials for the exact processing pipeline). Missing observations were multiply imputed using a parametric bootstrap via the “missMDA” R package to create one hundred imputed data sets We then computed EFA with three up to eight factors via the “psych” R package [@rsoft; @missMDA; @psych] using each imputed data set. Within each imputed data set, factor scores for each patient were calculated using the regression method [@thomson1951].

We based the number of extracted factors on a combination of the root-mean-square error approximation (RMSEA), Tucker-Lewis Index (TLI), and consistency of each factor model across imputations. TLI is a measure of a goodness-of-fit such that higher values of TLI imply better fit and values exceeding 0.90 are considered to indicate a good model fit. On the other hand, RMSEA is a measure of badness-of-fit such that lower values imply better fit with values less than 0.08 indicating an adequate model fit [@browne1992]. A model was considered consistent if the model identified similar factors across imputed data sets.

### Describing and predicting post-surgery cognitive decline

Longitudinal data were analyzed using Bayesian generalized linear mixed models (GLMMs). Whereas commonly used analysis of change scores in the pre-test/post-test study design [@combs2015; @kim2014; @parsons2006] confounds true change with measurement error [@singer2003], GLMMs overcome this issue by estimating both group-level (i.e., “fixed effect”) as well as patient-level (i.e., “random effect”) parameters. Furthermore, modelling patient-level effects results in partial pooling of parameter estimates (shifting parameter estimates towards each other), which reduces the influence of outliers and facilitates reliable group-level inference [@gelman2012; @tuerlinckx2006].

To describe the rate of post-surgery cognitive decline, we estimated a GLMM with longitudinal DRS-2 performance as an outcome predicted by the time after surgery on the group-level and correlated patient-specific intercepts and slopes on the patient-level. Since the group-level slope of this model represents the expected rate of cognitive decline after STN DBS, it constituted the empirical estimand [@lundberg2021] for *RQ1*. To evaluate suitability of the linear model we compared it to an equivalent non-linear model that estimated post-surgery cognitive trajectory via tensor product smooths [@wood2012]. Both models were fitted using non-informative improper flat priors to ensure that their parameters are informed primarily by the data.

Two GLMMs were estimated to evaluate predictive utility of pre-surgery cognitive profile. The longitudinal DRS-2 performance was predicted on a group-level by post-surgery time slopes varying by either patients’ pre-surgery cognitive tests’ scores (the “test scores” model) or patients’ pre-surgery latent cognitive factors’ scores extracted from the EFA reported above (the “factor scores” model). Both models further included correlated patient-level intercepts and slopes. To check robustness of our findings we compared the results to estimates of GLMMs that also included group-level effects of age, LEDD and BDI-II (and their interaction with the time after surgery) to adjust for potentially confounding effects of aging, dopaminergic medication, and depressive symptoms.

Since previous long-term studies demonstrated that a subset of PD patients treated with STN DBS can develop dementia which may lead to heavy tails in the data distribution of cognitive test scores, we modelled the data distribution with Student-t instead of Gaussian likelihood. Furthermore, because the outcome DRS-2 has a maximum of 144 points which is achieved by a large proportion of healthy people [@bezdicek2015], we used the right-censored version of Student-t to account for the ceiling effect. Models’ likelihoods had following specification:

$$P(DRS_i = DRS_{max}) = 1 - T(\vartheta,\mu_i,\sigma), for DRS_i \in N_{max}, N_{max} = {i: drs_i = drs_{max}}$$ $$DRS_i \sim~ t(\vartheta,\mu_i,\sigma), for DRS_i \in N_1, N_1 = {i: drs_i < drs_{max}}$$ $$\mu_i = \alpha + \delta_{time}time_i + \sum_{j=1}^{m} (\beta_{predictor[j]}predictor_{[j]i} + \delta_{predictor[j]}time_ipredictor_{[j]i}) + \bar{\alpha}_{id[i]} + \bar{\delta}_{id[i]}time_i$$

*i* = 1…*n*, where *n* is the total number of assessments across all patients, *m* is the total number of pre-surgery predictors, $DRS_{max}$ is the maximal attainable score in DRS-2 (i.e., a raw score of 144), *T()* is the Student-t cumulative distribution function, *t()* is the Student-t probability density function, $time_i$ is the time from surgery at assessment *i*, $predictor_{[j]i}$ is the pre-surgery cognitive score in the predictor (i.e., either a test or latent factor) *j* of the patient evaluated at assessment *i*, and the remaining terms denote model parameters. Empirical estimands relating to *RQ2* comprised of the two sets of $\delta_{predictor[j]}$ representing the expected prognostic value of single pre-surgery cognitive tests and latent cognitive factors.

We specified equivalent prior distributions for model parameters of both the “test scores” and the “factor scores” models. We used the Bayesian Lasso priors for all group-level parameters barring the intercept. This prior is the Bayesian equivalent of the Lasso method for performing variable selection and allows for fitting models with a large number of potentially collinear predictors All remaining parameters were given weakly informative priors to ensure that models’ estimates fall within the range of measurable values of the outcome (see https://github.com/josefmana/dbs_longCOG for the R and Stan code).

### Model description and statistical testing

Effects were described by medians and 95% highest density posterior probability intervals (PPIs) of corresponding model parameters. A 95% PPI can be interpreted such that a given parameter lies within this interval with 95% probability. Models were compared via the expected log pointwise predictive density (ELPD) computed via the leave-one-out cross-validation (LOO-CV) as approximated by the Pareto-smoothed importance sampling (PSIS) [@vehtari2015]. The ELPD difference ($ELPD_{dif}$) and its 95% frequentist confidence interval (CI) were used to decide whether predictive performance of compared models statistically significantly differs (i.e., the 95% CI excludes zero). To identify influential observations, we calculated a Pareto-k diagnostic and looked for observations with Pareto-k \> 0.7 which can be considered problematic [@bürkner2020; @vehtari2015].

### Evaluating false positive error rates

To validate the assumption that our analysis provides lower false positive rates than the commonly used two-step procedure we conducted series of simulations with a data set structure equivalent to that observed in our data. Patients’ outcome was generated as a normally distributed random variable with unit standard deviation and mean depending on average annual rate of cognitive decline and patient-specific random deviations. Moreover, for each patient we generated a set of potential predictors including either seven independent variables, twenty-three independent variables or twenty-three covaried variables representing our analysis of the predictive utility of seven latent cognitive factors and twenty-three observed cognitive test scores respectively. Covariance structure in the case of covaried predictors was based on the structure of the battery described above with predictors that represented test measures belonging to the same superordinate task having Pearson’s correlation of 0.7 (thus sharing approximately half of the variance) and zero otherwise (see Figure S5 in Supplementary materials). The simulations were set-up such that there was no effect of any predictor on the outcome. Subsequently, we generated one hundred data sets which were then fitted via the two-step procedure and Bayesian Lasso. For each procedure, the number of statistically significant interactions between time and any of the predictors were recorded to estimate the amount of false positive errors these procedures produce under the null hypothesis.

### Transparency and openness

All GLMMs were fitted using via Stan’s (version 2.21.0) build-in Hamiltonian Monte Carlo sampler accessed via R version 4.2.0 using package “brms” [@bürkner2017; @rsoft; @stan]. Four parallel chains were run each for 2,500 iterations for each GLMM. The first 500 iterations served as a warm-up and were discarded. Convergence was checked numerically by inspection of the R̂s and visually by inspection of trace plots. We used R packages “tidyverse” and “dplyr” for data operations, “tidybayes” for operation with model posteriors, and “DiagrammeR, “ggplot2” and “patchwork” for plotting [@DiagrammeR; @ggplot2; @patchwork]. This study’s design and its analysis were not pre-registered. The data are not publicly available due to privacy or ethical restrictions. The computer code used in our data analysis as well as synthetic data and replicable code for simulations to estimate false positive error rates can be accessed at https://github.com/josefmana/dbs_longCOG.

# Results

```{r}
#| label: import

library(here) # reading & saving files
library(tidyverse) # data wrangling
library(gt) # tables formatting
library(DiagrammeR) # flowchart
library(ggplot2) # general plotting

# clear environment
rm( list = ls() )

# set ggplot theme
theme_set( theme_classic(base_size = 12) )

# create folders for models, figures, and tablesto store results in
# prints TRUE and creates the folder if it was not present
# prints NULL if the folder was already present
#sapply( c("mods", "figs", "tabs"), function(i) if( !dir.exists(i) ) dir.create(i) )

# read the data set and prepare subsets for individual analyses
d0 <- read.csv( here("_data","20220508_dbs_longCOG_data.csv") , sep = "," )
d1 <- d0[ d0$included == 1 , ] # only STN-DBS treated patients with pre- and post-surgery data
d2 <- d1[ d1$ass_type == "pre" , ] # only pre-surgery assessments of included patients

# read a file containing mapping of variables' names used in the script to variables' names for the manuscript
v <- read.csv( here("_data","var_nms.csv") , sep = ";" , row.names = 1 , encoding = "UTF-8")

# IN-HOUSE FUNCTIONS ----

# printing rounded number
rprint <- function( x, dec=2 ) sprintf( paste0("%.",dec,"f"), round( x , dec) )

# upper bound
ubound <- function( x, dec=2 ) ifelse( round(x,dec) > x, rprint(x,dec), rprint( x+1/(10^dec), dec ) )

# read models
mread <- function( files, names ) {
  
  lapply(
    
    setNames(files,names),
    function(i)
      readRDS( here( "mods", paste0(i,".rds") ) )

  )

}

# IN-TEXT STATS ----

itstats <-
  
  with(
    
    d1, list(
      
      # number of patients
    n = c( tot = length( unique(d0$id) ), incl = length( unique(id) ) ),
    
    # duration of follow-up
    fudur =
      
      sapply(
        c("mean","sd","median","min","max"), # stats to compute
        function(i)
          do.call( i, list( time_y[ complete.cases(drs_tot) & ass_type != "pre" ] ) ) %>%
          rprint(2)
      ),
    
    # number of assessments per patient
    nass =
      
      sapply(
        c("median","min","max"),
        function(i) do.call( i, list( table( id[ complete.cases(drs_tot) ] ) ) )
      )
      
    )
  )

```

## Characterizing the sample

A total of `r itstats[['n']][['tot']]` patients with PD who underwent cognitive evaluation for STN DBS between 2000 and 2020 were identified by a retrospective search of local database in General University Hospital in Prague and a total of `r itstats[['n']][['incl']]` patients met inclusion criteria (see @fig-flow). All included patients were Caucasians and were speaking Czech as their primary language. Baseline demographic and clinical characteristics as well as stimulation parameters of the sample are presented in @tbl-base and baseline cognitive characteristics are presented in @tbl-cog. Mean duration of a follow-up after the surgery was `r itstats[['fudur']][['mean']]` years (SD = `r itstats[['fudur']][['sd']]`, median = `r itstats[['fudur']][['median']]`, range = `r itstats[['fudur']][['min']]`–`r itstats[['fudur']][['max']]`) with a median number of `r itstats[['nass']][['median']]` assessments per patient (range = `r itstats[['nass']][['min']]`–`r itstats[['nass']][['max']]`) (see also @fig-dist).

```{r}
#| label: fig1

# check that when selecting only rows containing pre-surgery assessment there ain't no patient duplicated
#with( d0, isTRUE( all.equal( id[ass_type=="pre"], unique(id[ass_type=="pre"]) ) ) )
# TRUE

# print a table summarizing reasons for excluding patients
#table( d0[ d0$ass_type == "pre" , ]$why_excluded )

# packages for saving the results
library(DiagrammeRsvg)
library(rsvg)

# using numbers from t0 create an inclusion/exclusion flowchart
f1 <- " digraph {
  
  /// define nodes which will include numbers reflecting the inclusion/exclusion process
  node [ fontname = Calibri, fontsize = 10, shape = box, style = rounded , width = 2.75 , margin= 0.1 , penwidth = 1 ];
  
  /// create a box for all patients, i.e., sum(t) = 200 patients
  all_pats [ label =<
  <b>200 consecutive<br/>PD patients </b><br/><br/>Local database 2000-2020<br/>General University Hospital<br/>in Prague
  >];
         
  /// create a box for all STN-DBS patients, i.e., sum(t[c(1,4,5,6,7,8,9,11)])) = 173 patients
  all_stn [ label =<
  <b>173 patients </b><br/><br/>implanted with STN-DBS
  >];
  
  /// create a box for all included patients, i.e., t[4] = 126 patients
  all_incl [ label =<
  <b>126 patients </b><br/><br/>followed-up longitudinally
  >];
  
  /// create nodes for exluded patients, specifying only these characteristics that will differ from the nodes above
  node [ fixedsize = T, width = 2.5, height = .75, margin= 0.2 ];
  
  /// create a box for non-STN-DBS patients, i.e., t[c(3,13,2,10,12)] with sum(t[c(3,13,2,10,12)]) = 27 patients
  excl_nostn [ label =<
  <b>27 patients excluded due to</b><br align = 'left'/><br align = 'left'/>
  12 GPi-DBS<br align = 'left'/>
  4 VIM-DBS<br align = 'left'/>
  4 duodopa<br align = 'left'/>
  5 rejected<br align = 'left'/>
  2 suspended<br align = 'left'/>
  >];
  
  /// create a box for STN-DBS excluded patients, i.e., t[c(1,7,9, 8, 6,11, 5)], sum(t[c(1,7,9,8,6,11,5)]) = 47 patients
  excl_stn [ label =<
  <b>47 patients excluded due to</b><br align = 'left'/><br align = 'left'/>
  24 pre-surgery data missing<br align = 'left'/>
  18 follow-up data missing<br align = 'left'/>
  3 unilateral STN-DBS<br align = 'left'/>
  2 not speaking Czech<br align = 'left'/>
  >];
  
  /// create dummy nodes for horizontally forking out of the vertical 'inclusion flow' to excluded sides
  node [ shape = rectangle, width = 0, height = 0, label = '', fill = black ];
  
  /// create directed edges in the inclusion (from dummy/fork vertically to inclusion boxes)
  /// and the exlusion (from forks horizontally to exclusion boxes) parts of the flowchart
  /// first make the arrows bigger
  edge [ arrowsize = .75, penwidth = 1 ]
  
  /// specifiy paths
  fork1 -> all_stn; fork2 -> all_incl;
  
  /// for the horizontal paths use 'rank = same' to ensure their nodes are level
  { rank = same ; fork1 -> excl_nostn }
  { rank = same ; fork2 -> excl_stn }
  
  /// create non-directed edges from the inclusion boxes to dummy/fork boxes (vertically)
  edge [ dir = none, penwidth = 1 ]
  all_pats -> fork1; all_stn -> fork2;

  /// seperate dummy/fork nodes from exclusion boxes by some reasonable distance (in inches)
  nodesep = .75
  }"

# save the flowchart as Fig 1
grViz(f1) %>% export_svg() %>% charToRaw() %>% rsvg_png( here("figs","inclusion_flowchart.png") )

```

![Patients inclusion/exclusion flowchart.](../figs/inclusion_flowchart.png){#fig-flow}

```{r}
#| label: tabs-prep

# function for calculating the stats
dstat <-
  
  function(x,dec1,dec2) {
    
    if (is.numeric(x) ) {
      c( N = sum( !is.na(x) ),
         Md = rprint( median(x,na.rm=T), dec1 ),
         `Min-Max` = paste0( rprint( min(x,na.rm=T), dec1 ),"-",rprint( max(x,na.rm=T), dec1 ) ) ,
         M = rprint( mean(x,na.rm=T), dec2 ),
         SD = rprint( sd(x,na.rm=T), dec2 )
         )
    } else rep( NA, 5 ) # print NAs for non-numeric variables
    
  }

# list all variables for Tab 1 (clinics and stimulation parameters) and Tab 2 (neuropsychology)
nms <-
  
  list(
    dems = names(d2)[which(names(d2)=="age_stim_y"):which(names(d2)=="mds_updrs_iii_med_off")],
    pars = names(d1)[which(names(d1)=="current_r_mA"):which(names(d1)=="frequency_l_Hz")],
    tests = names(d2)[which(names(d2)=="drs_tot"):which(names(d2)=="fp_dr")]
  )

# extract stats for description of the sample
t <-
  
  lapply(
    setNames( names(nms), names(nms) ),
    function(i)
      # stimulation parameters calculated from d1, others from d2
      sapply( nms[[i]], function(j) if ( i == "pars" ) dstat(d1[[j]],1,2) else dstat(d2[[j]],0,2) ) %>% t()
  )

# add count of males
t$dems["sex","N"] <-
  
  paste0(
    table(d2$sex)["male"], " (", # frequency
    sprintf( "%.0f" , round( 100 * ( table(d2$sex)[ "male" ] / sum( table(d2$sex) ) ), 0 ) ), " %)" # percentage, rounded to integers
  )

# fill-in number of patients in each row of stimulation parameters table
t$pars[ ,"N"] <- c( rep(67,2) , rep(59,2) , rep(nrow(d2),4) )


# loop through all variables the pre-tables and change their names accordingly
for ( i in names(t) ) {
  
  t[[i]] <-
    
    t[[i]] %>%
    as.data.frame() %>%
    rownames_to_column( var = "Characteristic" ) %>% # prepare the first column
    mutate( Characteristic = sapply( 1:nrow(.), function(j) v[Characteristic[j], ] ) ) # rename

}

# prepare Table 1 of clinical & stimulation variables
t1 <-
  
  lapply( names(t)[1:2], function(i) t[[i]] %>% mutate( Type = i, .after = 1 ) ) %>% # add type of variable
  do.call( rbind.data.frame, . ) %>%
  mutate( Type = case_when( Type == "dems" ~ "Baseline characteristics", Type == "pars" ~ "Stimulation parameters") ) %>%
  mutate( across( everything(), ~ ifelse( is.na(.x), "-", .x) ) )

# prepare a neuropsychology table
t2 <- t$tests %>% rename( "Test" = "Characteristic" )

# save both of them as .csv
write.table( t1, file = here("tabs","clinical_characteristics.csv"), sep = ",", row.names = F, quote = F )
write.table( t2, file = here("tabs","baseline_neuropsychology.csv"), sep = ",", row.names = F, quote = F )

```

{{< pagebreak >}}

```{r}
#| label: tbl-base
#| tbl-cap: Clinical characteristics of the sample of included patients

# prepare a gt object
t1 <-
  
  gt( t1, rowname_col = "Characteristic", groupname_col = "Type" ) %>%
  cols_align( align = "center", columns = -1 ) %>%
  tab_footnote(
    footnote = "Each measurement of each electrode considered independently. For stimulation parameters, column N indicate number of patients with current/voltage mode of stimulation.",
    locations = cells_row_groups( groups = "Stimulation parameters" )
  ) %>%
  tab_source_note(
    source_note = "M: mean; SD: standard deviation; MDS-UPDRS III: Movement Disorder Society Unified Parkinson’s Disease Rating Scale, motor part; LEDD: levodopa equivalent daily dose; Levodopa test: a percentage change of the MDS-UPDRS III score from medication OFF to medication ON state during the levodopa test as described in the main text; V: Volts; mA: milliampere; μs: microseconds; Hz: Hertz."
  )

# save & print it
gtsave( data = t1, filename = here("tabs","clinical_characteristics.docx") )
t1
```

{{< pagebreak >}}

```{r}
#| label: tbl-cog
#| tbl-cap: Pre-surgery neuropsychological measures of included patients

# prepare a gt object
t2 <-
  
  gt( t2, rowname_col = "Characteristic" ) %>%
  cols_align( align = "center", columns = -1 ) %>%
  tab_source_note(
    source_note = "M: mean; SD: standard deviation; DRS-2: Dementia Rating Scale, second edition; BDI-II: Beck Depression Rating Scale, second edition; STAI-X1: State-Trait Anxiety Inventory, the state version; STAI-X2: State-Trait Anxiety Inventory, the trait version; TMT-A: Trail Making Test, part A; TMT-B: Trail Making Test, part B; DS-F: Digit Span forward; DS-B: Digit Span backward; LNS: letter-number sequencing; SS-F: Spatial Span forward; SS-B: Spatial Span backward; TOL: Tower of London task; PST-D: Prague Stroop Test, dot color naming; PST-W: Prague Stroop Test, word color naming; PST-C: Prague Stroop Test, interference condition; COWAT: Controlled Oral Word Association Test; CFT: category fluency test; Sim.: Similarities; RAVLT-IR: Rey Auditory Verbal Learning Test, immediate recall; RAVLT-B: Rey Auditory Verbal Learning Test, recall of the interference set; RAVLT-DR: Rey Auditory Verbal Learning Test, delayed recall; RAVLT- Rec50: Rey Auditory Verbal Learning Test, delayed recognition from 50 items (15 correct answers + 35 distractors); RAVLT-Rec15: Rey Auditory Verbal Learning Test, delayed recognition, number of correctly identified from 15 items; FP-IR: Family Pictures, immediate recall; FP-DR: Family Pictures, delayed recall; Secs: seconds; Total words: word count in two minutes (one minute per each letter P and K); words/min.: word count in one minute time limit."
  )

# save & print it
gtsave( data = t2, filename = here("tabs","baseline_neuropsychology.docx") )
t2
```

```{r}
#| label: fig2

# patchwork package for glueing plots together
library(patchwork)

# prepare both sub-figures
fig2 <- 
  
  list(
    
    # need to use the complete.cases command because three patients have duplicated rows
    # due to more than one stimulation parameter
    hist =
      d1[ complete.cases(d1$drs_tot) , ] %>% 
      ggplot( aes(x = time_y) ) +
      stat_bin( breaks = seq(-2,12,.5) ) + # creates bars
      stat_bin( breaks = seq(-2,12,.5), geom = "text", aes(label = after_stat(count) ), vjust = -1.0, size = 2.5 ) + # add numbers
      labs( x = "Time from STN-DBS surgery (years)", y = "Number of Assessments" ) +
      scale_y_continuous( expand = c(0, 0), limits = c(0, 107), breaks = seq(0, 100, 10), labels = seq(0, 100, 10) ) +
      scale_x_continuous( limits = c(-2, 12), breaks = seq(-2, 12, 1), labels = seq(-2, 12, 1) ),
    
    # prepare a bin plot showing distribution of the number of assessments per patient (Fig S1b)
    bin =
      table( d1[ complete.cases(d1$drs_tot) , ]$id ) %>%
      as.data.frame() %>%
      ggplot( aes(x = Freq) ) +
      geom_bar( width = .25 ) +
      geom_text( stat = "count", aes(label = after_stat(count) ), vjust = -1.0, size = 2.5 ) +
      scale_y_continuous( expand = c(0, 0), limits = c(0, 65) ) +
      labs( x = "Number of Assessments per Patient", y = "Number of Patients" )
    
  )

# save them
ggsave(
  plot = with( fig2, hist / bin ) +
    plot_annotation( tag_levels = "A" ) &
    theme( plot.tag = element_text(face = "bold") ),
  filename = here("figs","assessments_desc.jpg"),
  dpi = 300
) 

```

![Distribution of assessments. Distribution of (A) follow-up years and (B) number of assessments per patient for N = 126 patients. Negative values on horizontal axis in (A) represent pre-surgery assessments.](../figs/assessments_desc.jpg){#fig-dist width=100% height=90%}

{{< pagebreak >}}

```{r}
#| label: fact-anal

#library(psych) # using psych to read the results

# clear environment
rm( list = ls()[ !ls() %in% c("v","rprint","ubound","mread","nms") ] )

# read the EFA results
efa <- readRDS( here("mods","factanal.rds") )

# choosing 7-factor solution due to good performance indexes,
# and theoretically sound loading patterns across imputed data sets
nf <- 7

# extract number of imputations used
imp <- length(efa)

# list all the domains
doms <-
  
  c(
    "exec_fun", # loaded on primarily by PST, the first factor in 82% data sets
    "epis_mem", # loaded on primarily by RAVLT, the second factor in 79% data sets
    "verb_wm", # loaded on primarily by DS, the third factor in 62% data sets
    "visp_mem", # loaded on primarily by FP, the fourth factor in 45% data sets
    "set_shift", # loaded on primarily by TMT and RAVLT-B, the fifth factor in 28% data sets
    "anxiety", # loaded on primarily by STAI, the sixth factor in 60% data sets
    "visp_wm" # loaded on primarily by SS, the seventh factor in 49% data sets
  )

# extract M and SD of percentage of variance accounted for across imputations for in-text reporting
vaccount <-
  
  sapply(
    
    c("mean","sd"), # loop through summary stats of interest
    function(i)
      
      ( # extract all total cumulative variability accounted for by 7-factor model & calculate summaries
        do.call(
        i,
        list( sapply( 1:length(efa), function(j) max( efa[[j]][[nf-2]]$Vaccounted[ "Cumulative Var", ] ) ) )
        ) * 100 # make it percentages
      ) %>%
      
      rprint(1) %>%
      paste0(.," %")
      
  )

```

## Pre-surgery cognitive profile

Detailed summaries of the fit statistics of all EFA models are presented in the Supplementary material (see Table S1 and Figure S1). Most importantly, raising the number of factors from six to seven resulted in a clear improvement. Out of the one hundred imputed data sets, the six-factor model showed good fit according to RMSEA in 96 cases and it showed good fit according to the TLI in 76 cases. On the other hand, the seven-factor model showed good fit according to RMSEA in 99 cases and good fit according to TLI in 97 cases. Moreover, the seven-factor model was more consistent across imputations. Finally, while the eight-factor resulted in the best fit statistics, factors identified by this model were often substantially loaded on by only a single cognitive test score (with a factor loading above 0.3) which impedes theoretical interpretation of such factors. Consequently, the seven-factor model was retained for subsequent analyses. On average, the seven factors accounted for a total of `r vaccount["mean"]` of variance (SD = `r vaccount["sd"]`) and corresponded to seven cognitive functions: 1) executive functions/attention (EF/Att.) was loaded on primarily by PST tasks, TMT tasks, verbal fluency tests and TOL, 2) episodic memory (EM) was loaded on primarily by indexes of RAVLT except for the recall of interference list (RAVLT-B), 3) verbal working memory (VWM) was loaded on primarily by Digit Span tasks, LNS and Similarities, 4) visuospatial memory (VM) was loaded on primarily by indexes of the Family Pictures test, 5) set shifting (SS) was loaded on primarily by TMT tasks and RAVLT-B, 6) anxiety (An.) was loaded on primarily by STAI, and 7) spatial working memory (SWM) was loaded on primarily by Spatial Span tasks (see @tbl-factanal).

{{< pagebreak >}}

```{r}
#| label: tbl-factanal
#| tbl-cap: Summary of factor loadings

# prepare an array for loading matrices of each imputed EFA
loads <-
  
  # create an empty 25 ( 23 tests + 2 variance accounted) x 7 (factors) x 100 (imputations) array
  array(
    data = NA,
    dim = c(25, nf, imp),
    dimnames = list( c( rownames(efa[[1]][[nf-2]]$loadings) , "Proportion Var", "Cumulative Var" ), doms, 1:imp )
  )

# fill-in all loadings from efa objects prepared above
for( i in 1:imp ) {

  loads[ , ,i] <-
    
    # extract loadings
    efa[[i]][[nf-2]]$loadings %>%
    as.data.frame() %>%
    
    # add proportion of variability accounted for
    bind_rows( efa[[i]][[nf-2]]$Vaccounted[ "Proportion Var", ] ) %>%
    bind_rows( apply( t(efa[[i]][[nf-2]]$Vaccounted[ "Proportion Var", ]), 1 , cumsum ) %>% t() %>% as.data.frame() ) %>%
    
    as.matrix() # re-format
  
}

# prepare the table
t3 <-
  
  sapply(
    
    dimnames(loads)[[1]],
    function(i)
      paste0(
        rprint( colMeans( t(loads[i, , ]) ), 2 ), " (",
        rprint( apply( t(loads[i, , ]) , 2, sd ), 2 ), ")"
      )
    
  ) %>%
  
  t() %>%
  as.data.frame() %>%
  `rownames<-`( sapply( rownames(.), function(i) v[ i, ] ) ) %>%
  `colnames<-`( sapply( dimnames(loads)[[2]], function(i) v[ i, ] ) ) %>%
  rownames_to_column("Test") %>%
  
  gt( rowname_col = "Test" ) %>%
  cols_align( align = "center", columns = -1 ) %>%
  tab_source_note(
    source_note = "Values represent mean (SD) across one hundred imputations. Factor loadings used for interpretation (|loading| > 0.30) are printed in bold. TMT-A: Trail Making Test, part A; TMT-B: Trail Making Test, part B; DS-F: Digit Span forward; DS-B: Digit Span backward; LNS: letter-number sequencing; SS-F: Spatial Span forward; SS-B: Spatial Span backward; TOL: Tower of London task; PST-D: Prague Stroop Test, dot color naming; PST-W: Prague Stroop Test, word color naming; PST-C: Prague Stroop Test, interference condition; COWAT: Controlled Oral Word Association Test; CFT: category fluency test; Sim.: Similarities; RAVLT-IR: Rey Auditory Verbal Learning Test, immediate recall; RAVLT-B: Rey Auditory Verbal Learning Test, recall of the interference set; RAVLT-DR: Rey Auditory Verbal Learning Test, delayed recall; RAVLT-Rec50: Rey Auditory Verbal Learning Test, delayed recognition from 50 items (15 correct answers + 35 distractors); RAVLT-Rec15: Rey Auditory Verbal Learning Test, delayed recognition, number of correctly identified from 15 items; FP-IR: Family Pictures, immediate recall; FP- DR: Family Pictures, delayed recall; STAI-X1: State-Trait Anxiety Inventory, the state version; STAI- X2: State-Trait Anxiety Inventory, the trait version; Secs: seconds; Total words: word count in two minutes (one minute per each letter P and K); words/min.: word count in one minute time limit. Proportion Var: Proportion of variance in data accounted for by each factor (column); Cumulative Var: Cumulative variance accounted for by each factor and factors that preceded it (columns to the left); EF/Att.: Executive functions/Attention; EM: Episodic memory; VWM: Verbal working memory; VM: Visuospatial memory; SS: Set shifting; An: Anxiety; SWM: Spatial working memory."
  ) %>%
  tab_options( quarto.disable_processing = T )

# save & print it
gtsave( data = t3, filename = here("tabs","factanal_loadings.docx") )
t3
```

{{< pagebreak >}}

## Describing post-surgery cognitive decline

```{r}
#| label: long-desc

library(brms) # brms to read the results
library(tidybayes) # tidybayes for posterior manipulations

# clear environment
rm( list = ls()[ !ls() %in% c("v","rprint","ubound","mread","nms","imp") ] )

# read the data and models
for( i in names(readRDS( here("_data","longitudinal_df.rds" ) ) ) ) assign( i, readRDS( here("_data","longitudinal_df.rds" ) )[[i]] )

# read models
m <- mread( c("m0_linear","m0_spline"), c("Linear","Non-linear") )

# extract the highest Rhat for chains convergence and Pareto-k for influential outliers
rhatmax <- round( sapply( names(m) , function(i) max( rhat(m[[i]]), na.rm = T ) ), 3 ) %>% max() %>% ubound(2)
parkmax <- round( sapply( names(m) , function(i) max( loo(m[[i]])$diagnostics$pareto_k, na.rm = T ) ), 3 ) %>% max() %>% ubound(1)

# compare the models via PSIS-LOO
loocomp <-
  
  # extract ELPD_dif and its SE
  with( m, loo_compare(Linear,`Non-linear`)[2,paste0(c("elpd","se"),"_diff") ] ) %>%
  t() %>%
  as.data.frame() %>%
  
  # flip the sign of elpd_diff such that positive means m0_linear had better predictive performance
  mutate( elpd_diff = ifelse( rownames( with( m, loo_compare(Linear,`Non-linear`) ) )[1] == "Linear" , -elpd_diff, elpd_diff ) ) %>%
  
  # add 95% PPI
  mutate(
    ci_low = rprint( qnorm(.025,elpd_diff,se_diff), 2 ),
    ci_hig = rprint( qnorm(.975,elpd_diff,se_diff), 2 ),
    across( ends_with("diff"), ~ rprint(.x,2) ),
    print = paste0( elpd_diff, ", 95% CI [", ci_low,", ", ci_hig, "]" )
  )

# expected cognitive decline in DRS-2 points/year as approximated by the linear model
# i.e., the estimand #1
b <-
  
  spread_draws( m$Linear, `b_.*`, regex = T ) %>% # extract parameter estimates
  
  # calculate model group-level intercept and slope summaries in the correct scale
  median_hdi(
    b_Intecept = with( scl, (b_Intercept * SD$drs ) + M$drs ),
    b_slope = b_time * scl$SD$drs,
    .width = .95
  ) %>%
  
  # prepare a table of parameters the table
  select( starts_with("b_") ) %>%
  mutate( b_slope = abs(b_slope) ) %>% # slope will be reported in absolute value
  mutate_all( rprint, 2 ) %>%
  matrix(
    nrow = 2, ncol = 3, byrow = T,
    dimnames = list( c("intercept","slope"), c("median","ppi_low","ppi_hig") )
  ) %>%
  
  # finishing touches
  as.data.frame() %>%
  mutate( ppi = paste0("[",ppi_low,", ",ppi_hig,"]") )
```

Both descriptive longitudinal GLMMs converged within a specified number of iterations ($\hat{R}s \leq `r rhatmax`$). All observations had Pareto-k below `r parkmax` implying that the results are not likely to be biased by influential outliers.The linear and non-linear models showed tight correspondence up to approximately five years post-surgery after which the non-linear model predicted a slightly faster rate of cognitive decline than the linear model (see @fig-traj). The difference in estimated predictive performance between these models did not reach statistical significance ($ELPD_{dif}$ = `r loocomp$print`). Based on the linear model, there was an average post-surgery decline of `r b["slope","median"]` DRS-2 points/year (95% PPI `r b["slope","ppi"]`) from an average pre-surgery DRS-2 performance of `r b["intercept","median"]` out of 144 points (95% PPI `r b["intercept","ppi"]`).

```{r}
#| label: fig3

# prepare colors to use in graphs (a colorblind-friendly palette)
cbPal <- c( "#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7" )

# plot prediction via Linear vs Non-linear desciptive models
f3 <-
  
  # extract posterior predictions
  lapply(
    
    names(m),
    function(i)
      
      # prepare a data frame for filling predictions in
      data.frame( time_y = seq(-2,12,length.out = 50), id = NA ) %>%
      mutate( time = time_y + scl$Md$time ) %>%
    
      # predicting proper
      add_epred_draws( m[[i]], re_formula = NA ) %>%
      mutate( .epred = with( scl, .epred * SD$drs + M$drs ) ) %>%
      median_hdi( .width = .95 ) %>%
      add_column( Model = factor( i, levels = c("Non-linear","Linear"), ordered = T ) )
    
  ) %>%
  
  # make it a single file
  do.call( rbind.data.frame, . ) %>%
  
  # plotting proper
  ggplot() +
  aes(x = time_y, y = .epred, ymin = .lower, ymax = .upper, color = Model, fill = Model) +
  geom_ribbon( alpha = .2 , color = NA ) +
  geom_line( linewidth = 2 , alpha = .75 ) +
  scale_y_continuous(name = "DRS-2", limits = c(119,145), breaks = seq(120,144,4), labels = seq(120,144,4) ) +
  scale_x_continuous(name = "Time from surgery (years)", limits = c(-2,12), breaks = seq(-2,12,2), labels = seq(-2,12,2) ) +
  scale_color_manual( values = c("black",cbPal[8]) ) +
  scale_fill_manual( values = cbPal[c(1,8)] ) +
  theme( legend.position = c(0.15,0.21), legend.key.width = unit(2.2,"cm"), legend.key.height = unit(1.2,"cm") )

# save it
# save them
ggsave( plot = f3, filename = here("figs","expected_trajectories.jpg"), dpi = 300 )

```

![Comparison of linear versus non-linear models of the longitudinal cognitive trajectory.](../figs/expected_trajectories.jpg){#fig-traj width=100% height=55%}

## Predicting post-surgery cognitive decline

```{r}
#| label: long-pred

#library(brms) # brms to read the results
#library(tidybayes) # tidybayes for posterior manipulations

# clear environment
rm( list = ls()[ !ls() %in% c("d","df","scl","tests","doms","v","rprint","ubound","mread","nms","imp","cbPal") ] )

m <- mread( c("m1_lasso_doms","m2_lasso_tests"), c("Domains","Tests") ) # read models
l <- readRDS( here("mods","lasso_psis_loo.rds") ) %>% `names<-`( names(m) ) # read PSIS-LOO results

# check the highest Rhat for chains convergence
rhatmax <-
  
  sapply( names(m) , function(i) max(m[[i]]$rhats, na.rm = T ) ) %>%
  max() %>%
  ubound(2)

# check the highest Pareto-k for influential outliers
parkmax <-
  
  sapply(
    names(l),
        function(i)
          sapply( 1:imp, function(j) max( l[[i]][[j]]$diagnostics$pareto_k ) )
  ) %>%
  
  apply(., 2, max ) %>%
  max() %>%
  ubound(1)

```

Both predictive longitudinal GLMMs converged within a specified number of iterations ($\hat{R} \le$ `r rhatmax`) with all observations having Pareto-k below `r parkmax`. Patients with lower verbal working memory or set shifting showed relatively impaired pre-surgery performance on DRS-2 while there was no cognitive test that clearly indicated pre-surgery impairment in DRS-2 performance (see Tables S2 and S3 in Supplementary materials).

## Evaluating false positive error rates

# Discussion

# References
