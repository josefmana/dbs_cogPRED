---
title: "Preoperative Cognitive Profile Predictive of Cognitive Decline after Subthalamic Deep Brain Stimulation in Parkinson’s Disease"
shorttitle: "Cognition in PD after STN DBS"
author:
  - name: Josef Mana
    corresponding: false
    orcid: "0000-0002-7817-3978"
    email: "josef.mana@protonmail.com"
    role:
      - Conceptualization
      - Data curation
      - Investigation
      - Formal analysis
      - Methodology
      - Software
      - Visualization
      - Writing - original draft
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Ondrej Bezdicek
    corresponding: true
    orcid: "0000-0002-5108-0181"
    email: "ondrej.bezdicek@gmail.com"
    role:
      - Conceptualization
      - Data curation
      - Investigation
      - Methodology
      - Supervision
      - Writing - original draft
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Andrej Lasica
    corresponding: false
    email: "Andrej.Lasica@vfn.cz"
    role:
      - Investigation
      - Data curation
      - Formal analysis
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Filip Ruzicka
    corresponding: false
    email: "filr@seznam.cz"
    role:
      - Investigation
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Anna Fecikova
    corresponding: false
    email: "Anna.Fecikova@vfn.cz"
    role:
      - Investigation
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Olga Klempirova
    corresponding: false
    email: "novakovaol@seznam.cz"
    role:
      - Investigation
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Tomas Nikolai
    corresponding: false
    email: "nikolai@centrum.cz"
    role:
      - Investigation
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Tereza Uhrova
    corresponding: false
    email: "tereza.uhrova@vfn.cz"
    role:
      - Investigation
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Evzen Ruzicka
    corresponding: false
    email: "eruzi@lf1.cuni.cz"
    role:
      - Conceptualization
      - Funding acquisition
      - Investigation
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Dusan Urgosik
    corresponding: false
    email: "urgosik@gmail.com"
    role:
      - Investigation
    affiliations:
      - id: "NHH"
        name: "Na Homolce Hospital, Prague, Czech Republic"
        department: "Department of stereotactic and radiation neurosurgery"
  - name: Robert Jech
    corresponding: false
    orcid: "0000-0002-9732-8947"
    email: "jech@cesnet.cz"
    role:
      - Conceptualization
      - Data curation
      - Funding acquisition
      - Investigation
      - Resources
      - Supervision
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
abstract: "Cognitive decline represents a severe non-motor symptom of Parkinson’s disease (PD) that can significantly reduce benefits of subthalamic deep brain stimulation (STN DBS). Here, we aimed to identify pre-surgery cognitive profile associated with faster post-surgery cognitive decline in STN DBS treated PD patients to characterize patients who could benefit from more monitoring during treatment course. A retrospective observational study of 126 PD patients treated by STN DBS combined with oral dopaminergic therapy followed for 3.54 years on average (SD = 2.32) with repeated assessments of cognition was conducted. Pre-surgery cognitive profile was obtained via a comprehensive neuropsychological examination. Data were analyzed using exploratory factor analysis for pre-surgery cognitive profile extraction and Bayesian generalized linear mixed models for description of the longitudinal cognitive outcome. Overall, we observed a mild annual cognitive decline of 0.90 points from a total of 144 points in the Mattis Dementia Rating Scale (95% posterior probability interval (PPI) [-1.19, -0.62]). Pre-surgery executive deficit predicted the rate of post-surgery cognitive decline (b = -0.39, 95% PPI [-0.63, -0.15]). The predictive utility of pre-surgery executive deficit resulted from summing small effects of several single test scores. Patients with PD treated with STN DBS experience only mild annual post-surgery cognitive decline. According to our data and models patients with worse long-term cognitive prognosis can be identified via pre-surgery examination of executive functions. Aggregating results from multiple executive tests to estimate cognitive prognosis of PD patients treated with STN DBS is likely superior to examining single test scores."
keywords:
  - Parkinson’s disease
  - deep brain stimulation
  - cognition
  - longitudinal
  - latent variable analysis
format:
 apaquarto-pdf:
   documentmode: man
   a4paper: true
   pdf-engine: lualatex
   floatsintext: false
   keep-tex: false
bibliography: references.bib
warning: false
echo: false
---

{{< include _extensions/wjschne/apaquarto/_apa_title.qmd >}}

# Introduction

Bilateral subthalamic nucleus (STN) deep brain stimulation (DBS) is an advanced symptomatic treatment of Parkinson’s disease (PD) that can successfully reduce motor symptoms and improve patients’ quality of life [@armstrong2020; @bratsos2018]. On the other hand, prior research revealed considerable heterogeneity in cognitive outcomes after STN DBS with a small to moderate post-surgery decline in verbal fluency and equivocal results for other cognitive domains [@combs2015; @mehanna2017; @parsons2006]. The ability to predict which patients are likely to develop post-surgery cognitive decline can thus prove useful for patient selection and for guiding post-surgery patient monitoring. In this article, we aim to describe pre-surgery cognitive profile extractable from clinically available neuropsychological evaluation that indicates higher risk of long-term post-surgery cognitive decline in everyday clinical settings.

Studies addressing the task of predicting post-surgery cognitive decline in STN DBS treated PD patients can be broadly divided to two groups, randomized controlled trials (RCT) and long-term observational studies. In a typical RCT, patients are randomized to treatment and placebo groups and outcomes are compared in a full factorial design (evaluating interactions between group and time of assessment as the estimand of interest). Courtesy of their experimental control RCTs allow for causal inference and are well suited for providing guidelines for patient selection. However, even though RCTs are regarded as a gold standard for causal inference, it is ethically unacceptable to deny DBS treatment for PD patients for longer time intervals than necessary. Long-term (i.e., more than three years after surgery) outcomes can thus be best described by observational studies. While observational studies usually do not allow for causal inference and are not well suited for guiding patient selection due to a lack of proper control group and resulting collider bias [@cinelli2022], they are well suited for description of patients’ long-term outcomes. Longitudinal observational studies can serve as a basis for selecting high-risk STN DBS treated patients that would benefit from increased monitoring.

Previous longitudinal observational studies reported that PD patients treated with STN DBS showing pre-surgery deficit in attention and executive functions are at risk of faster post- surgery cognitive decline or developing dementia [@bove2020; @gruber2019; @kim2014; @kishore2019; @smeding2009]. However, previous studies aimed at identifying any possible pre-surgery predictors of post-surgery cognitive decline accepting high false positive error rates in the process. In this study, we complement prior findings by identifying a sparse solution to the problem of identifying pre-surgery cognitive profile that is predictive of long-term post-surgery cognitive decline in naturalistic clinical settings. In other words, we aim to describe a minimal significant pre-surgery cognitive profile that predicts higher rate of post-surgery cognitive decline in a sample derived from everyday clinical practice.

In a typical observational study aiming to determine pre-surgery risk factors of post- surgery cognitive decline the authors employ the following two-step procedure. In the first step, a series of separate univariate analyses for each potential predictor is conducted to pre-select variables for further analysis. In the second step, predictors that achieved an arbitrary threshold (e.g., p \< 0.05) are used to predict the cognitive decline in a subsequent multiple regression model [@bove2020; @gruber2019; @kim2014; @smeding2009]. This procedure can lead to false positive error rates that are magnitudes higher than the expected nominal five percent. To overcome this shortcoming, we apply to our data the Bayesian Lasso regression, a method developed for identifying small amount of significant predictors out of a larger pool of possible predictors such as results from a comprehensive neuropsychological battery [@park2008].

Another way to achieve sparsity in prediction of post-surgery cognitive decline is to reduce the number of potential predictors. In the context of neuropsychological assessment this can be accomplished straightforwardly via a latent variable approach such as factor analysis that statistically extracts commonalities across several cognitive tasks. Added benefit of employing such a procedure to pre-surgery predictors is that latent variable approaches can reduce the impact of the task impurity problem – the observation that any cognitive task involves several cognitive functions at once [@burgess2014; @whitney2010a].

Overall, in this study we aimed to derive a sparse solution to the task of identifying pre- surgery cognitive profile predictive of long-term post-surgery cognitive decline in STN DBS treated PD patients. In other words, instead of identifying any pre-surgery cognitive variables that can be predictive of post-surgery decline, we aimed to identify only the most likely predictive ones. To this end, we asked the following research questions: *RQ1)* What is the size of expected long-term rate of cognitive decline after STN DBS in PD patients? *RQ2)* What is the pre-surgery cognitive profile that is predictive of long-term post-surgery cognitive decline in STN DBS treated PD? To answer these questions, we analyzed data of retrospectively sampled longitudinally followed STN DBS treated PD patients with a single pre-surgery comprehensive neuropsychological assessment and up to five post-surgery cognitive screening assessments.

# Materials and methods

## Participants

The data of all patients diagnosed with idiopathic PD following United Kingdom Parkinson’s Disease Society Brain Bank Criteria [@hughes1992] that underwent cognitive evaluation for STN DBS treatment at General University Hospital in Prague between years 2000 and 2020 were retrospectively gathered from clinical records and considered for inclusion in the study. Patients with atypical parkinsonian syndromes, dementia, depression at the time of pre- surgery assessment (according to an independent psychiatric evaluation), recurrent psychotic conditions or a gait disorder despite optimal dopaminergic therapy during pre-surgery assessment were not implanted and were thus not included in the study. Furthermore, only patients who underwent pre-surgery and at least one post-surgery assessment were included. All included patients were treated via continuous bilateral STN DBS in conjunction with dopaminergic therapy. Bilateral STN DBS implantation was performed as previously described [@jech2012; @jech2006; @urgosik2011]. All patients provided signed informed consent and the study was approved by the General University Hospital Ethics Committee in Prague, Czech Republic.

## Assessments

All patients underwent a comprehensive pre-surgery assessment including neuropsychological and neurological examinations. The patients were followed up post-surgery with similar examination protocol at varying time intervals according to their options. Post- surgery, patients were first contacted one year after the surgery and every two years afterwards. The pre-surgery assessment was performed with the usual dopaminergic therapy (ON medication). In the post-surgery assessment, patients were examined in the ON medication condition and STN DBS ON with optimal stimulation parameters.

### Pre-surgery neuropsychological measures

The neuropsychological assessment was arranged analogously to the standard International Parkinson and Movement Disorder Society (MDS) neuropsychological battery at Level II for mild cognitive impairment in Parkinson’s disease (PD-MCI) [@bezdicek2017; @litvan2012]. The battery consisted of 10 tests in 5 cognitive domains: (i) attention: Trail Making Test, part A (TMT-A) [@bezdicek2012; @bezdicek2017a; @partington1949] and dot color naming condition from Prague Stroop Test (PST-D) [@bezdicek2015a] for sustained visual attention; (ii) executive functions: Trail Making Test, part B (TMT-B) [@bezdicek2012; @bezdicek2017a; @partington1949] for set shifting, and Tower of London task (TOL) [@michalec2017; @shallice1982] for planning; (iii) language: Similarities (Sim.) from Wechsler Adult Intelligence Scale, third revision (WAIS-III) [@wechsler2010] for conceptualization, and category verbal fluency test (CFT, category Animals) [@nikolai2015] for speeded word production; (iv) working memory: Digit Span backward (DS-B) from WAIS-III [@wechsler2010] and Spatial Span backward (SS-B) from Wechsler Memory Scale, third edition (WMS-III) [@wechsler2011] for auditory and spatial working memory respectively; and (v) memory: Rey Auditory Verbal Learning Test delayed recall (RAVLT-DR) [@bezdicek2014; @frydrychova2018] for explicit verbal learning and memory, and WMS-III Family Pictures delayed recall (FP-DR) for visuo-spatial memory [@wechsler2011]. Furthermore, we administered the following tests beyond the battery: Prague Stroop Test, naming color of neutral words (PST-W) and interference condition (i.e., naming color of contrasting color words, PST-C) for sensitivity to interference [@bezdicek2015a], Controlled Oral Word Association Test (COWAT, letters K + P) [@nikolai2015] for mental flexibility, and WMS-III letter-number sequencing (LNS) [@wechsler2011] for working memory. Finally, anxiety was assessed with the State-Trait Anxiety Inventory for the state (STAI-X1) and trait (STAI-X2) anxiety [@spielberger1983].

### Longitudinal neuropsychological measures

Patients’ longitudinal cognitive state was assessed pre-surgery and post-surgery with MDS battery at Level I using Mattis Dementia Rating Scale, second edition (DRS-2) [@bezdicek2015; @jurica2001]. DRS-2 is a routinely employed cognitive screening measure in PD that has been shown to have acceptable discriminative performance for PD-MCI in Czech population with both sensitivity estimated to be around 0.8 [@bezdicek2015; @mazancova2020]. Furthermore, subjective depressive symptoms were assessed with Beck Depression Inventory, second edition (BDI-II) [@beck1996; @ciharova2020] at each assessment. BDI-II was not used for pre-surgery exclusion due to depression which was instead ascertained by an independent neuropsychiatric evaluation.

### Neurological examination

Patients’ motor state was assessed with part three of the Movement Disorders Society Unified Parkinson's Disease Rating Scale (MDS-UPDRS III) in medication ON and medication OFF state during the pre-surgery levodopa test. Scores of patients who underwent the older version of the Unified Parkinson’s Disease Rating Scale (UPDRS III) were converted to the MDS-UPDRS III scale using the method described by @hentz2015. The levodopa equivalent daily dose (LEDD) was calculated at each assessment time-point according to @tomlinson2010.

## Statistical analysies

### Deriving pre-surgery cognitive profile

Latent cognitive factors were extracted from the data via an exploratory factor analysis (EFA) with varimax rotation using ordinary least squares to find the minimum residual solution [@harman1966]. We opted for the orthogonal varimax rotation because: (i) extracting orthogonal factors can be statistically advantageous in later steps of our analysis due to reducing multicollinearity, and (ii) in the framework of PD-MCI, it is considered desirable to describe patients’ cognitive profile by factors or tests that are independent of each other [@litvan2012].

All pre-surgery cognitive tests listed above were entered into EFA as input variables (see Supplementary Materials for the exact processing pipeline). Missing observations were multiply imputed using a parametric bootstrap via the “missMDA” R package to create one hundred imputed data sets We then computed EFA with three up to eight factors via the “psych” R package [@rsoft; @missMDA; @psych] using each imputed data set. Within each imputed data set, factor scores for each patient were calculated using the regression method [@thomson1951].

We based the number of extracted factors on a combination of the root-mean-square error approximation (RMSEA), Tucker-Lewis Index (TLI), and consistency of each factor model across imputations. TLI is a measure of a goodness-of-fit such that higher values of TLI imply better fit and values exceeding 0.90 are considered to indicate a good model fit. On the other hand, RMSEA is a measure of badness-of-fit such that lower values imply better fit with values less than 0.08 indicating an adequate model fit [@browne1992]. A model was considered consistent if the model identified similar factors across imputed data sets.

### Describing and predicting post-surgery cognitive decline

Longitudinal data were analyzed using Bayesian generalized linear mixed models (GLMMs). Whereas commonly used analysis of change scores in the pre-test/post-test study design [@combs2015; @kim2014; @parsons2006] confounds true change with measurement error [@singer2003], GLMMs overcome this issue by estimating both group-level (i.e., “fixed effect”) as well as patient-level (i.e., “random effect”) parameters. Furthermore, modelling patient-level effects results in partial pooling of parameter estimates (shifting parameter estimates towards each other), which reduces the influence of outliers and facilitates reliable group-level inference [@gelman2012; @tuerlinckx2006].

To describe the rate of post-surgery cognitive decline, we estimated a GLMM with longitudinal DRS-2 performance as an outcome predicted by the time after surgery on the group-level and correlated patient-specific intercepts and slopes on the patient-level. Since the group-level slope of this model represents the expected rate of cognitive decline after STN DBS, it constituted the empirical estimand [@lundberg2021] for *RQ1*. To evaluate suitability of the linear model we compared it to an equivalent non-linear model that estimated post-surgery cognitive trajectory via tensor product smooths [@wood2012]. Both models were fitted using non-informative improper flat priors to ensure that their parameters are informed primarily by the data.

Two GLMMs were estimated to evaluate predictive utility of pre-surgery cognitive profile. The longitudinal DRS-2 performance was predicted on a group-level by post-surgery time slopes varying by either patients’ pre-surgery cognitive tests’ scores (the “test scores” model) or patients’ pre-surgery latent cognitive factors’ scores extracted from the EFA reported above (the “factor scores” model). Both models further included correlated patient-level intercepts and slopes. To check robustness of our findings we compared the results to estimates of GLMMs that also included group-level effects of age, LEDD and BDI-II (and their interaction with the time after surgery) to adjust for potentially confounding effects of aging, dopaminergic medication, and depressive symptoms.

Since previous long-term studies demonstrated that a subset of PD patients treated with STN DBS can develop dementia which may lead to heavy tails in the data distribution of cognitive test scores, we modelled the data distribution with Student-t instead of Gaussian likelihood. Furthermore, because the outcome DRS-2 has a maximum of 144 points which is achieved by a large proportion of healthy people [@bezdicek2015], we used the right-censored version of Student-t to account for the ceiling effect. Models’ likelihoods had following specification:

$$P(DRS_i = DRS_{max}) = 1 - T(\vartheta,\mu_i,\sigma), for DRS_i \in N_{max}, N_{max} = \{i: drs_i = drs_{max}\}$$ $$DRS_i \sim~ t(\vartheta,\mu_i,\sigma), for DRS_i \in N_1, N_1 = \{i: drs_i < drs_{max}\}$$ $$\mu_i = \alpha + \delta_{time}time_i + \sum_{j=1}^{m} (\beta_{predictor[j]}predictor_{[j]i} + \delta_{predictor[j]}time_ipredictor_{[j]i}) + \bar{\alpha}_{id[i]} + \bar{\delta}_{id[i]}time_i$$

*i* = 1…*n*, where *n* is the total number of assessments across all patients, *m* is the total number of pre-surgery predictors, $DRS_{max}$ is the maximal attainable score in DRS-2 (i.e., a raw score of 144), *T()* is the Student-t cumulative distribution function, *t()* is the Student-t probability density function, $time_i$ is the time from surgery at assessment *i*, $predictor_{[j]i}$ is the pre-surgery cognitive score in the predictor (i.e., either a test or latent factor) *j* of the patient evaluated at assessment *i*, and the remaining terms denote model parameters. Empirical estimands relating to *RQ2* comprised of the two sets of $\delta_{predictor[j]}$ representing the expected prognostic value of single pre-surgery cognitive tests and latent cognitive factors.

We specified equivalent prior distributions for model parameters of both the “test scores” and the “factor scores” models. We used the Bayesian Lasso priors for all group-level parameters barring the intercept. This prior is the Bayesian equivalent of the Lasso method for performing variable selection and allows for fitting models with a large number of potentially collinear predictors All remaining parameters were given weakly informative priors to ensure that models’ estimates fall within the range of measurable values of the outcome (see https://github.com/josefmana/dbs_longCOG for the R and Stan code).

### Model description and statistical testing

Effects were described by medians and 95% highest density posterior probability intervals (PPIs) of corresponding model parameters. A 95% PPI can be interpreted such that a given parameter lies within this interval with 95% probability. Models were compared via the expected log pointwise predictive density (ELPD) computed via the leave-one-out cross-validation (LOO-CV) as approximated by the Pareto-smoothed importance sampling (PSIS) [@vehtari2015]. The ELPD difference ($ELPD_{dif}$) and its 95% frequentist confidence interval (CI) were used to decide whether predictive performance of compared models statistically significantly differs (i.e., the 95% CI excludes zero). To identify influential observations, we calculated a Pareto-k diagnostic and looked for observations with Pareto-k \> 0.7 which can be considered problematic [@bürkner2020; @vehtari2015].

### Evaluating false positive error rates

To validate the assumption that our analysis provides lower false positive rates than the commonly used two-step procedure we conducted series of simulations with a data set structure equivalent to that observed in our data. Patients’ outcome was generated as a normally distributed random variable with unit standard deviation and mean depending on average annual rate of cognitive decline and patient-specific random deviations. Moreover, for each patient we generated a set of potential predictors including either seven independent variables, twenty-three independent variables or twenty-three covaried variables representing our analysis of the predictive utility of seven latent cognitive factors and twenty-three observed cognitive test scores respectively. Covariance structure in the case of covaried predictors was based on the structure of the battery described above with predictors that represented test measures belonging to the same superordinate task having Pearson’s correlation of 0.7 (thus sharing approximately half of the variance) and zero otherwise (see Figure S5 in Supplementary materials). The simulations were set-up such that there was no effect of any predictor on the outcome. Subsequently, we generated one hundred data sets which were then fitted via the two-step procedure and Bayesian Lasso. For each procedure, the number of statistically significant interactions between time and any of the predictors were recorded to estimate the amount of false positive errors these procedures produce under the null hypothesis.

### Transparency and openness

All GLMMs were fitted using via Stan’s (version 2.21.0) build-in Hamiltonian Monte Carlo sampler accessed via R version 4.2.0 using package “brms” [@bürkner2017; @rsoft; @stan]. Four parallel chains were run each for 2,500 iterations for each GLMM. The first 500 iterations served as a warm-up and were discarded. Convergence was checked numerically by inspection of the R̂s and visually by inspection of trace plots. We used R packages “tidyverse” and “dplyr” for data operations, “tidybayes” for operation with model posteriors, and “DiagrammeR, “ggplot2” and “patchwork” for plotting [@DiagrammeR; @ggplot2; @patchwork]. This study’s design and its analysis were not pre-registered. The data are not publicly available due to privacy or ethical restrictions. The computer code used in our data analysis as well as synthetic data and replicable code for simulations to estimate false positive error rates can be accessed at https://github.com/josefmana/dbs_longCOG.

# Results

```{r}
#| label: import

library(here) # reading & saving files
library(tidyverse) # data wrangling
library(gt) # tables formatting
library(DiagrammeR) # flowchart
library(DiagrammeRsvg) # saving flowchart
library(rsvg) # saving flowchart
library(ggplot2) # general plotting
library(patchwork) # glueing plots together
library(brms) # model processing
library(tidybayes) # posterior manipulations
library(ggridges) # plotting posteriors

# clear environment
rm( list = ls() )

# set ggplot theme
theme_set( theme_minimal(base_size = 12) )

# read the data set and prepare subsets for individual analyses
d0 <- read.csv( here("_data","20220508_dbs_longCOG_data.csv") , sep = "," )
d1 <- d0[ d0$included == 1 , ] # only STN-DBS treated patients with pre- and post-surgery data
d2 <- d1[ d1$ass_type == "pre" , ] # only pre-surgery assessments of included patients

# read a file containing mapping of variables' names used in the script to variables' names for the manuscript
v <- read.csv( here("_data","var_nms.csv") , sep = ";" , row.names = 1 , encoding = "UTF-8")


# IN-HOUSE FUNCTIONS ----

# printing rounded number
rprint <- function( x, dec=2 ) sprintf( paste0("%.",dec,"f"), round( x , dec) )

# upper bound
ubound <- function( x, dec=2 ) ifelse( round(x,dec) > x, rprint(x,dec), rprint( x+1/(10^dec), dec ) )

# read models
mread <- function( files, names ) {
  
  lapply(
    
    setNames(files,names),
    function(i)
      readRDS( here( "mods", paste0(i,".rds") ) )

  )

}

# IN-TEXT STATS ----

itstats <-
  
  with(
    
    d1, list(
      
      # number of patients
    n = c( tot = length( unique(d0$id) ), incl = length( unique(id) ) ),
    
    # duration of follow-up
    fudur =
      
      sapply(
        c("mean","sd","median","min","max"), # stats to compute
        function(i)
          do.call( i, list( time_y[ complete.cases(drs_tot) & ass_type != "pre" ] ) ) %>%
          rprint(2)
      ),
    
    # number of assessments per patient
    nass =
      
      sapply(
        c("median","min","max"),
        function(i) do.call( i, list( table( id[ complete.cases(drs_tot) ] ) ) )
      )
      
    )
  )

```

## Characterizing the sample

A total of `r itstats[['n']][['tot']]` patients with PD who underwent cognitive evaluation for STN DBS between 2000 and 2020 were identified by a retrospective search of local database in General University Hospital in Prague and a total of `r itstats[['n']][['incl']]` patients met inclusion criteria (see @fig-flow). All included patients were Caucasians and were speaking Czech as their primary language. Baseline demographic and clinical characteristics as well as stimulation parameters of the sample are presented in @tbl-base and baseline cognitive characteristics are presented in @tbl-cog. Mean duration of a follow-up after the surgery was `r itstats[['fudur']][['mean']]` years (SD = `r itstats[['fudur']][['sd']]`, median = `r itstats[['fudur']][['median']]`, range = `r itstats[['fudur']][['min']]`–`r itstats[['fudur']][['max']]`) with a median number of `r itstats[['nass']][['median']]` assessments per patient (range = `r itstats[['nass']][['min']]`–`r itstats[['nass']][['max']]`) (see also @fig-dist).

```{r}
#| label: fig1

# check that when selecting only rows containing pre-surgery assessment there ain't no patient duplicated
#with( d0, isTRUE( all.equal( id[ass_type=="pre"], unique(id[ass_type=="pre"]) ) ) )

# print a table summarizing reasons for excluding patients
#table( d0[ d0$ass_type == "pre" , ]$why_excluded )

# using numbers from t0 create an inclusion/exclusion flowchart
f1 <- " digraph {
  
  /// define nodes which will include numbers reflecting the inclusion/exclusion process
  node [ fontname = Calibri, fontsize = 10, shape = box, style = rounded , width = 2.75 , margin= 0.1 , penwidth = 1 ];
  
  /// create a box for all patients, i.e., sum(t) = 200 patients
  all_pats [ label =<
  <b>200 consecutive<br/>PD patients </b><br/><br/>Local database 2000-2020<br/>General University Hospital<br/>in Prague
  >];
         
  /// create a box for all STN-DBS patients, i.e., sum(t[c(1,4,5,6,7,8,9,11)])) = 173 patients
  all_stn [ label =<
  <b>173 patients </b><br/><br/>implanted with STN-DBS
  >];
  
  /// create a box for all included patients, i.e., t[4] = 126 patients
  all_incl [ label =<
  <b>126 patients </b><br/><br/>followed-up longitudinally
  >];
  
  /// create nodes for exluded patients, specifying only these characteristics that will differ from the nodes above
  node [ fixedsize = T, width = 2.5, height = .75, margin= 0.2 ];
  
  /// create a box for non-STN-DBS patients, i.e., t[c(3,13,2,10,12)] with sum(t[c(3,13,2,10,12)]) = 27 patients
  excl_nostn [ label =<
  <b>27 patients excluded due to</b><br align = 'left'/><br align = 'left'/>
  12 GPi-DBS<br align = 'left'/>
  4 VIM-DBS<br align = 'left'/>
  4 duodopa<br align = 'left'/>
  5 rejected<br align = 'left'/>
  2 suspended<br align = 'left'/>
  >];
  
  /// create a box for STN-DBS excluded patients, i.e., t[c(1,7,9, 8, 6,11, 5)], sum(t[c(1,7,9,8,6,11,5)]) = 47 patients
  excl_stn [ label =<
  <b>47 patients excluded due to</b><br align = 'left'/><br align = 'left'/>
  24 pre-surgery data missing<br align = 'left'/>
  18 follow-up data missing<br align = 'left'/>
  3 unilateral STN-DBS<br align = 'left'/>
  2 not speaking Czech<br align = 'left'/>
  >];
  
  /// create dummy nodes for horizontally forking out of the vertical 'inclusion flow' to excluded sides
  node [ shape = rectangle, width = 0, height = 0, label = '', fill = black ];
  
  /// create directed edges in the inclusion (from dummy/fork vertically to inclusion boxes)
  /// and the exlusion (from forks horizontally to exclusion boxes) parts of the flowchart
  /// first make the arrows bigger
  edge [ arrowsize = .75, penwidth = 1 ]
  
  /// specifiy paths
  fork1 -> all_stn; fork2 -> all_incl;
  
  /// for the horizontal paths use 'rank = same' to ensure their nodes are level
  { rank = same ; fork1 -> excl_nostn }
  { rank = same ; fork2 -> excl_stn }
  
  /// create non-directed edges from the inclusion boxes to dummy/fork boxes (vertically)
  edge [ dir = none, penwidth = 1 ]
  all_pats -> fork1; all_stn -> fork2;

  /// seperate dummy/fork nodes from exclusion boxes by some reasonable distance (in inches)
  nodesep = .75
  }"

# save the flowchart as Fig 1
grViz(f1) %>% export_svg() %>% charToRaw() %>% rsvg_png( here("figs","inclusion_flowchart.png") )

```

![Patients inclusion/exclusion flowchart.](../figs/inclusion_flowchart.png){#fig-flow}

```{r}
#| label: tabs-prep

# function for calculating the stats
dstat <-
  
  function(x,dec1,dec2) {
    
    if (is.numeric(x) ) {
      c( N = sum( !is.na(x) ),
         Md = rprint( median(x,na.rm=T), dec1 ),
         `Min-Max` = paste0( rprint( min(x,na.rm=T), dec1 ),"-",rprint( max(x,na.rm=T), dec1 ) ) ,
         M = rprint( mean(x,na.rm=T), dec2 ),
         SD = rprint( sd(x,na.rm=T), dec2 )
         )
    } else rep( NA, 5 ) # print NAs for non-numeric variables
    
  }

# list all variables for Tab 1 (clinics and stimulation parameters) and Tab 2 (neuropsychology)
nms <-
  
  list(
    dems = names(d2)[which(names(d2)=="age_stim_y"):which(names(d2)=="mds_updrs_iii_med_off")],
    pars = names(d1)[which(names(d1)=="current_r_mA"):which(names(d1)=="frequency_l_Hz")],
    tests = names(d2)[which(names(d2)=="drs_tot"):which(names(d2)=="fp_dr")]
  )

# extract stats for description of the sample
t <-
  
  lapply(
    setNames( names(nms), names(nms) ),
    function(i)
      # stimulation parameters calculated from d1, others from d2
      sapply( nms[[i]], function(j) if ( i == "pars" ) dstat(d1[[j]],1,2) else dstat(d2[[j]],0,2) ) %>% t()
  )

# add count of males
t$dems["sex","N"] <-
  
  paste0(
    table(d2$sex)["male"], " (", # frequency
    sprintf( "%.0f" , round( 100 * ( table(d2$sex)[ "male" ] / sum( table(d2$sex) ) ), 0 ) ), " %)" # percentage, rounded to integers
  )

# fill-in number of patients in each row of stimulation parameters table
t$pars[ ,"N"] <- c( rep(67,2) , rep(59,2) , rep(nrow(d2),4) )


# loop through all variables the pre-tables and change their names accordingly
for ( i in names(t) ) {
  
  t[[i]] <-
    
    t[[i]] %>%
    as.data.frame() %>%
    rownames_to_column( var = "Characteristic" ) %>% # prepare the first column
    mutate( Characteristic = sapply( 1:nrow(.), function(j) v[Characteristic[j], ] ) ) # rename

}

# prepare Table 1 of clinical & stimulation variables
t1 <-
  
  lapply( names(t)[1:2], function(i) t[[i]] %>% mutate( Type = i, .after = 1 ) ) %>% # add type of variable
  do.call( rbind.data.frame, . ) %>%
  mutate( Type = case_when( Type == "dems" ~ "Baseline characteristics", Type == "pars" ~ "Stimulation parameters") ) %>%
  mutate( across( everything(), ~ ifelse( is.na(.x), "-", .x) ) )

# prepare a neuropsychology table
t2 <- t$tests %>% rename( "Test" = "Characteristic" )

# save both of them as .csv
write.table( t1, file = here("tabs","clinical_characteristics.csv"), sep = ",", row.names = F, quote = F )
write.table( t2, file = here("tabs","baseline_neuropsychology.csv"), sep = ",", row.names = F, quote = F )

```

{{< pagebreak >}}

```{r}
#| label: tbl-base
#| tbl-cap: Clinical characteristics of the sample of included patients

# prepare a gt object
t1 <-
  
  gt( t1, rowname_col = "Characteristic", groupname_col = "Type" ) %>%
  cols_align( align = "center", columns = -1 ) %>%
  tab_footnote(
    footnote = "Each measurement of each electrode considered independently. For stimulation parameters, column N indicate number of patients with current/voltage mode of stimulation.",
    locations = cells_row_groups( groups = "Stimulation parameters" )
  ) %>%
  tab_source_note(
    source_note = "N: number of observations; Md: median; M: mean; SD: standard deviation; MDS-UPDRS III: Movement Disorder Society Unified Parkinson’s Disease Rating Scale, motor part; LEDD: levodopa equivalent daily dose; Levodopa test: a percentage change of the MDS-UPDRS III score from medication OFF to medication ON state during the levodopa test as described in the main text; V: Volts; mA: milliampere; μs: microseconds; Hz: Hertz."
  )

# save & print it
gtsave( data = t1, filename = here("tabs","clinical_characteristics.docx") )
t1
```

{{< pagebreak >}}

```{r}
#| label: tbl-cog
#| tbl-cap: Pre-surgery neuropsychological measures of included patients

# prepare a gt object
t2 <-
  
  gt( t2, rowname_col = "Characteristic" ) %>%
  cols_align( align = "center", columns = -1 ) %>%
  tab_source_note(
    source_note = "N: number of observations; Md: median; M: mean; SD: standard deviation; DRS-2: Dementia Rating Scale, second edition; BDI-II: Beck Depression Rating Scale, second edition; STAI-X1: State-Trait Anxiety Inventory, the state version; STAI-X2: State-Trait Anxiety Inventory, the trait version; TMT-A: Trail Making Test, part A; TMT-B: Trail Making Test, part B; DS-F: Digit Span forward; DS-B: Digit Span backward; LNS: letter-number sequencing; SS-F: Spatial Span forward; SS-B: Spatial Span backward; TOL: Tower of London task; PST-D: Prague Stroop Test, dot color naming; PST-W: Prague Stroop Test, word color naming; PST-C: Prague Stroop Test, interference condition; COWAT: Controlled Oral Word Association Test; CFT: category fluency test; Sim.: Similarities; RAVLT-IR: Rey Auditory Verbal Learning Test, immediate recall; RAVLT-B: Rey Auditory Verbal Learning Test, recall of the interference set; RAVLT-DR: Rey Auditory Verbal Learning Test, delayed recall; RAVLT- Rec50: Rey Auditory Verbal Learning Test, delayed recognition from 50 items (15 correct answers + 35 distractors); RAVLT-Rec15: Rey Auditory Verbal Learning Test, delayed recognition, number of correctly identified from 15 items; FP-IR: Family Pictures, immediate recall; FP-DR: Family Pictures, delayed recall; Secs: seconds; Total words: word count in two minutes (one minute per each letter P and K); words/min.: word count in one minute time limit."
  )

# save & print it
gtsave( data = t2, filename = here("tabs","baseline_neuropsychology.docx") )
t2
```

```{r}
#| label: fig2

# prepare both sub-figures
fig2 <- 
  
  list(
    
    # need to use the complete.cases command because three patients have duplicated rows
    # due to more than one stimulation parameter
    hist =
      d1[ complete.cases(d1$drs_tot) , ] %>% 
      ggplot( aes(x = time_y) ) +
      stat_bin( breaks = seq(-2,12,.5) ) + # creates bars
      stat_bin( breaks = seq(-2,12,.5), geom = "text", aes(label = after_stat(count) ), vjust = -0.8, size = 3 ) + # add numbers
      labs( x = "Time from STN-DBS surgery (years)", y = "Number of Assessments" ) +
      scale_y_continuous( expand = c(0, 0), limits = c(0, 107), breaks = seq(0, 100, 10), labels = seq(0, 100, 10) ) +
      scale_x_continuous( limits = c(-2, 12), breaks = seq(-2, 12, 1), labels = seq(-2, 12, 1) ) +
      theme( panel.grid.minor = element_blank() ),
    
    # prepare a bin plot showing distribution of the number of assessments per patient (Fig S1b)
    bin =
      table( d1[ complete.cases(d1$drs_tot) , ]$id ) %>%
      as.data.frame() %>%
      ggplot( aes(x = Freq) ) +
      geom_bar( width = .25 ) +
      geom_text( stat = "count", aes(label = after_stat(count) ), vjust = -0.8, size = 3 ) +
      scale_y_continuous( expand = c(0, 0), limits = c(0, 65), breaks = seq(0,60,10), labels = seq(0,60,10) ) +
      labs( x = "Number of Assessments per Patient", y = "Number of Patients" ) +
      theme( panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank() )
    
  )

# save them
ggsave(
  plot = with( fig2, hist / bin ) +
    plot_annotation( tag_levels = "A" ) &
    theme( plot.tag = element_text(face = "bold") ),
  filename = here("figs","assessments_desc.jpg"),
  dpi = 300,
  width = 7,
  height = 7.8
) 

```

![Distribution of assessments. Distribution of (A) follow-up years and (B) number of assessments per patient for N = 126 patients. Negative values on horizontal axis in (A) represent pre-surgery assessments.](../figs/assessments_desc.jpg){#fig-dist}

{{< pagebreak >}}

```{r}
#| label: fact-anal

# clear environment
rm( list = ls()[ !ls() %in% c("v","itstats","rprint","ubound","mread","nms") ] )

# read EFA-related results
for( i in names( readRDS( here("mods","factanal.rds") ) ) ) assign( i , readRDS( here("mods","factanal.rds") )[[i]] )

# extract M and SD of percentage of variance accounted for across imputations for in-text reporting
vaccount <-
  
  sapply(
    
    c("mean","sd"), # loop through summary stats of interest
    function(i)
      
      ( # extract all total cumulative variability accounted for by 7-factor model & calculate summaries
        do.call(
        i,
        list( sapply( 1:length(efa), function(j) max( efa[[j]][[nf-2]]$Vaccounted[ "Cumulative Var", ] ) ) )
        ) * 100 # make it percentages
      ) %>%
      
      rprint(1) %>%
      paste0(.," %")
      
  )

```

## Pre-surgery cognitive profile

Detailed summaries of the fit statistics of all EFA models are presented in the Supplementary material (see Table S1 and Figure S1). Most importantly, raising the number of factors from six to seven resulted in a clear improvement. Out of the one hundred imputed data sets, the six-factor model showed good fit according to RMSEA in 96 cases and it showed good fit according to the TLI in 76 cases. On the other hand, the seven-factor model showed good fit according to RMSEA in 99 cases and good fit according to TLI in 97 cases. Moreover, the seven-factor model was more consistent across imputations. Finally, while the eight-factor resulted in the best fit statistics, factors identified by this model were often substantially loaded on by only a single cognitive test score (with a factor loading above 0.3) which impedes theoretical interpretation of such factors. Consequently, the seven-factor model was retained for subsequent analyses. On average, the seven factors accounted for a total of `r vaccount['mean']` of variance (SD = `r vaccount['sd']`) and corresponded to seven cognitive functions: 1) executive functions/attention (EF/Att.) was loaded on primarily by PST tasks, TMT tasks, verbal fluency tests and TOL, 2) episodic memory (EM) was loaded on primarily by indexes of RAVLT except for the recall of interference list (RAVLT-B), 3) verbal working memory (VWM) was loaded on primarily by Digit Span tasks, LNS and Similarities, 4) visuospatial memory (VM) was loaded on primarily by indexes of the Family Pictures test, 5) set shifting (SS) was loaded on primarily by TMT tasks and RAVLT-B, 6) anxiety (An.) was loaded on primarily by STAI, and 7) spatial working memory (SWM) was loaded on primarily by Spatial Span tasks (see @tbl-factanal).

{{< pagebreak >}}

```{r}
#| label: tbl-factanal
#| tbl-cap: Summary of factor loadings

# prepare an array for loading matrices of each imputed EFA
loads <-
  
  # create an empty 25 ( 23 tests + 2 variance accounted) x 7 (factors) x 100 (imputations) array
  array(
    data = NA,
    dim = c(25, nf, imp),
    dimnames = list( c( rownames(efa[[1]][[nf-2]]$loadings) , "Proportion Var", "Cumulative Var" ), doms, 1:imp )
  )

# fill-in all loadings from efa objects prepared above
for( i in 1:imp ) {

  loads[ , ,i] <-
    
    # extract loadings
    efa[[i]][[nf-2]]$loadings %>%
    as.data.frame() %>%
    
    # add proportion of variability accounted for
    bind_rows( efa[[i]][[nf-2]]$Vaccounted[ "Proportion Var", ] ) %>%
    bind_rows( apply( t(efa[[i]][[nf-2]]$Vaccounted[ "Proportion Var", ]), 1 , cumsum ) %>% t() %>% as.data.frame() ) %>%
    
    as.matrix() # re-format
  
}

# prepare the table
t3 <-
  
  sapply(
    
    dimnames(loads)[[1]],
    function(i)
      paste0(
        rprint( colMeans( t(loads[i, , ]) ), 2 ), " (",
        rprint( apply( t(loads[i, , ]) , 2, sd ), 2 ), ")"
      )
    
  ) %>%
  
  t() %>%
  as.data.frame() %>%
  `rownames<-`( sapply( rownames(.), function(i) v[ i, ] ) ) %>%
  `colnames<-`( sapply( dimnames(loads)[[2]], function(i) v[ i, ] ) ) %>%
  rownames_to_column("Test") %>%
  
  gt( rowname_col = "Test" ) %>%
  cols_align( align = "center", columns = -1 ) %>%
  tab_source_note(
    source_note = "Values represent mean (SD) across one hundred imputations. Factor loadings used for interpretation (|loading| > 0.30) are printed in bold. TMT-A: Trail Making Test, part A; TMT-B: Trail Making Test, part B; DS-F: Digit Span forward; DS-B: Digit Span backward; LNS: letter-number sequencing; SS-F: Spatial Span forward; SS-B: Spatial Span backward; TOL: Tower of London task; PST-D: Prague Stroop Test, dot color naming; PST-W: Prague Stroop Test, word color naming; PST-C: Prague Stroop Test, interference condition; COWAT: Controlled Oral Word Association Test; CFT: category fluency test; Sim.: Similarities; RAVLT-IR: Rey Auditory Verbal Learning Test, immediate recall; RAVLT-B: Rey Auditory Verbal Learning Test, recall of the interference set; RAVLT-DR: Rey Auditory Verbal Learning Test, delayed recall; RAVLT-Rec50: Rey Auditory Verbal Learning Test, delayed recognition from 50 items (15 correct answers + 35 distractors); RAVLT-Rec15: Rey Auditory Verbal Learning Test, delayed recognition, number of correctly identified from 15 items; FP-IR: Family Pictures, immediate recall; FP- DR: Family Pictures, delayed recall; STAI-X1: State-Trait Anxiety Inventory, the state version; STAI- X2: State-Trait Anxiety Inventory, the trait version; Secs: seconds; Total words: word count in two minutes (one minute per each letter P and K); words/min.: word count in one minute time limit. Proportion Var: Proportion of variance in data accounted for by each factor (column); Cumulative Var: Cumulative variance accounted for by each factor and factors that preceded it (columns to the left); EF/Att.: Executive functions/Attention; EM: Episodic memory; VWM: Verbal working memory; VM: Visuospatial memory; SS: Set shifting; An: Anxiety; SWM: Spatial working memory."
  )

# save & print it
gtsave( data = t3, filename = here("tabs","factanal_loadings.docx") )
t3
```

{{< pagebreak >}}

## Describing post-surgery cognitive decline

```{r}
#| label: long-desc

# clear environment
rm( list = ls()[ !ls() %in% c("v","itstats","rprint","ubound","mread","nms","imp") ] )

# prepare colors to use in graphs (a colorblind-friendly palette)
cbPal <- c( "#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7" )

# read the data
for( i in names(readRDS( here("_data","longitudinal_df.rds" ) ) ) ) assign( i, readRDS( here("_data","longitudinal_df.rds" ) )[[i]] )

# read models
m <- mread( c("m0_linear","m0_spline"), c("Linear","Non-linear") )

# extract the highest Rhat for chains convergence and Pareto-k for influential outliers
rhatmax <- round( sapply( names(m) , function(i) max( rhat(m[[i]]), na.rm = T ) ), 3 ) %>% max() %>% ubound(2)
parkmax <- round( sapply( names(m) , function(i) max( loo(m[[i]])$diagnostics$pareto_k, na.rm = T ) ), 3 ) %>% max() %>% ubound(1)

# compare the models via PSIS-LOO
loocomp <-
  
  # extract ELPD_dif and its SE
  with( m, loo_compare(Linear,`Non-linear`)[2,paste0(c("elpd","se"),"_diff") ] ) %>%
  t() %>%
  as.data.frame() %>%
  
  # flip the sign of elpd_diff such that positive means m0_linear had better predictive performance
  mutate( elpd_diff = ifelse( rownames( with( m, loo_compare(Linear,`Non-linear`) ) )[1] == "Linear" , -elpd_diff, elpd_diff ) ) %>%
  
  # add 95% PPI
  mutate(
    ci_low = rprint( qnorm(.025,elpd_diff,se_diff), 2 ),
    ci_hig = rprint( qnorm(.975,elpd_diff,se_diff), 2 ),
    across( ends_with("diff"), ~ rprint(.x,2) ),
    print = paste0( elpd_diff, ", 95% CI [", ci_low,", ", ci_hig, "]" )
  )

# expected cognitive decline in DRS-2 points/year as approximated by the linear model, i.e., the estimand #1
b <-
  
  spread_draws( m$Linear, `b_.*`, regex = T ) %>% # extract parameter estimates
  
  # calculate model group-level intercept and slope summaries in the correct scale
  median_hdi(
    b_Intecept = with( scl, (b_Intercept * SD$drs ) + M$drs ),
    b_slope = b_time * scl$SD$drs,
    .width = .95
  ) %>%
  
  # prepare a table of parameters the table
  select( starts_with("b_") ) %>%
  mutate( b_slope = abs(b_slope) ) %>% # slope will be reported in absolute value
  mutate_all( rprint, 2 ) %>%
  matrix(
    nrow = 2, ncol = 3, byrow = T,
    dimnames = list( c("intercept","slope"), c("median","ppi_low","ppi_hig") )
  ) %>%
  
  # finishing touches
  as.data.frame() %>%
  mutate( ppi = paste0("[",ppi_low,", ",ppi_hig,"]") )


# post-minus-pre contrast for one year post for fixed only and fixed + random effects
contr <-
  
  lapply(
    
    c("Fixed effects","Fixed + Random effects"),
    function(i)
      
      data.frame( id = "sub000", time_y = c( -0.3, seq(1,5,1) ) ) %>%
      mutate( time = time_y + scl$Md$time ) %>%
      add_epred_draws( object = m$Linear, newdata = . , allow_new_levels = T, if (i == "Fixed effects") { re_formula = NA }, seed = 87542 ) %>%
      mutate( .epred = scl$M$drs + scl$SD$drs * .epred ) %>%
      ungroup() %>%
      select( id, time_y, .draw, .epred ) %>%
      pivot_wider( names_from = time_y, names_prefix = "Y", values_from = .epred ) %>%
      mutate( across( all_of( paste0("Y", seq(1,5,1) ) ), ~ .x - `Y-0.3`, .names = "{col}-minus-Pre" ) ) %>%
      pivot_longer( cols = -c("id",".draw"), names_to = "Contrast" ) %>%
      group_by(Contrast) %>%
      summarise( md = median(value), ppi_low = hdi(value)[1], ppi_hig = hdi(value)[2] ) %>%
      mutate( `Generated by: ` = i, .before = 1 )
    
  ) %>%
  
  do.call( rbind.data.frame, . ) %>%
  filter( grepl("-",Contrast) ) %>%
  mutate( Contrast = ifelse( Contrast == "Y-0.3", "Pre-surgery", Contrast ) )

# table it for main text
t4 <-
  
  contr %>%
  mutate( out = paste0( rprint(md,2), " [", rprint(ppi_low,2), ", ", rprint(ppi_hig,2), "]" ) ) %>%
  select( `Generated by: `, Contrast, out ) %>%
  pivot_wider( names_from = `Generated by: `, values_from = out )

# plot it for supplemental material
f5 <-
  
  contr %>%
  filter( Contrast != "Pre-surgery" ) %>%
  ggplot() +
  aes( x = Contrast, y = md, ymin = ppi_low, ymax = ppi_hig, colour = `Generated by: ` ) +
  geom_pointrange( linewidth = 5, position = position_dodge(width = .25), alpha = .4 ) +
  geom_point( size = 5, position = position_dodge(width = .25) ) +
  geom_hline( yintercept = 0, linewidth = 1, linetype = "dashed", colour = "navyblue" ) +
  labs( x = NULL, y = parse( text = "Delta~`DRS-2`" ) ) +
  scale_y_continuous( breaks = seq(-15,5,1), labels = seq(-15,5,1) ) +
  theme( panel.grid.minor = element_blank(), axis.text.x = element_text( angle = 25 ), legend.position = "bottom" ) +
  scale_colour_manual( values = cbPal[c(1,8)] )

# save the plot
ggsave( plot = f5, filename = here("figs","expectation_contrasts.jpg"), dpi = 300, width = 7.8, height = 5.5 )

```

Both descriptive longitudinal GLMMs converged within a specified number of iterations ($\hat{R}s \leq `r rhatmax`$). All observations had Pareto-k below `r parkmax` implying that the results are not likely to be biased by influential outliers.The linear and non-linear models showed tight correspondence up to approximately five years post-surgery after which the non-linear model predicted a slightly faster rate of cognitive decline than the linear model (see @fig-traj). The difference in estimated predictive performance between these models did not reach statistical significance ($ELPD_{dif}$ = `r loocomp$print`). Based on the linear model, there was an average post-surgery decline of `r b['slope','median']` DRS-2 points/year (95% PPI `r b['slope','ppi']`) from an average pre-surgery DRS-2 performance of `r b['intercept','median']` out of 144 points (95% PPI `r b['intercept','ppi']`).

```{r}
#| label: fig3

# plot prediction via Linear vs Non-linear desciptive models
f3 <-
  
  # extract posterior predictions
  lapply(
    
    names(m),
    function(i)
      
      # prepare a data frame for filling predictions in
      data.frame( time_y = seq(-2,12,length.out = 50), id = NA ) %>%
      mutate( time = time_y + scl$Md$time ) %>%
    
      # predicting proper
      add_epred_draws( m[[i]], re_formula = NA ) %>%
      mutate( .epred = with( scl, .epred * SD$drs + M$drs ) ) %>%
      median_hdi( .width = .95 ) %>%
      add_column( Model = factor( i, levels = c("Non-linear","Linear"), ordered = T ) )
    
  ) %>%
  
  # make it a single file
  do.call( rbind.data.frame, . ) %>%
  
  # plotting proper
  ggplot() +
  aes(x = time_y, y = .epred, ymin = .lower, ymax = .upper, color = Model, fill = Model) +
  geom_ribbon( alpha = .2 , color = NA ) +
  geom_line( linewidth = 2 , alpha = .75 ) +
  scale_y_continuous(name = "DRS-2", limits = c(119,145), breaks = seq(120,144,4), labels = seq(120,144,4) ) +
  scale_x_continuous(name = "Time from surgery (years)", limits = c(-2,12), breaks = seq(-2,12,2), labels = seq(-2,12,2) ) +
  scale_color_manual( values = c("black",cbPal[8]) ) +
  scale_fill_manual( values = cbPal[c(1,8)] ) +
  theme( legend.position = c(0.15,0.21), legend.key.width = unit(2.2,"cm"), legend.key.height = unit(1.2,"cm") )

# save them
ggsave( plot = f3, filename = here("figs","expected_trajectories.jpg"), dpi = 300, width = 7, height = 4.16 )

```

![Comparison of linear versus non-linear models of the longitudinal cognitive trajectory.](../figs/expected_trajectories.jpg){#fig-traj}
```{r}
#| label: tbl-contr
#| tbl-cap: "Posterior prediction of DRS-2 changes after "

# prepare the table
t4 <-
  
  t4 %>%
  gt() %>%
  cols_align( -1, align = "center" ) %>%
  cols_label( Contrast ~ "" ) %>%
  
  tab_footnote(
    locations = cells_column_labels("Fixed effects"),
    footnote = "Contrasts predicted by mu[i] ~ alpha + delta_time[i] * time[i]"
  ) %>%
  tab_footnote(
    locations = cells_column_labels(`Fixed + Random effects`),
    footnote = "Contrasts predicted by mu[i] ~ alpha + delta_time[i] * time[i] + alpha_id[i] + delta_id[i] * time[i]"
  ) %>%
  tab_footnote(
    locations = cells_body(columns = Contrast, rows = 1 ),
    footnote = "The row represents expactation of patients' performance at pre-surgery assessment, i.e., 0.3 years before surgery based on our data"
  ) %>%
  tab_footnote(
    locations = cells_body(columns = `Fixed + Random effects`, rows = 1 ),
    footnote = "Note that since presented are estimates of the (latent) true score mu, the results represent expectation of patient's performance before censoring because of the ceiling effect in Dementia Rating Scale"
  ) %>%
  opt_footnote_marks(marks = "letters") %>%
  
  tab_source_note(
    source_note = "Values represent median [95% posterior predictive interval] of each row's estimate; Y[i]: assessment i years post-surgery."
  )

# save & print it
gtsave( data = t4, filename = here("tabs","expectation_contrasts.docx") )
#t4

```

## Predicting post-surgery cognitive decline

```{r}
#| label: long-pred

# clear environment
rm( list = ls()[ !ls() %in% c("d","df","scl","tests","doms","v","itstats","rprint","ubound","mread","nms","imp","cbPal","b") ] )

m <- mread( c("m1_lasso_doms","m2_lasso_tests"), c("factor scores","test scores") ) # read models
l <- readRDS( here("mods","lasso_psis_loo.rds") ) %>% `names<-`( names(m) ) # read PSIS-LOO results


# MODEL CHECKS ----

# check the highest Rhat for chains convergence
rhatmax <-
  
  sapply( names(m) , function(i) max(m[[i]]$rhats, na.rm = T ) ) %>%
  max() %>%
  ubound(2)

# check the highest Pareto-k for influential outliers
parkmax <-
  
  sapply(
    names(l),
        function(i)
          sapply( 1:imp, function(j) max( l[[i]][[j]]$diagnostics$pareto_k ) )
  ) %>%
  
  apply( ., 2, max ) %>%
  max() %>%
  ubound(1)


# POSTERIORS ----

# extract draws
drws <-
  
  lapply(
    
    setNames( names(m), names(m) ),
    function(i)
      
      m[[i]] %>%
      spread_draws( `b_.*`, regex = T ) %>% # extract all "fixed-effect" parameters
      select( contains("b_") ) %>% # get rid of the info about chains
      
      # re-scale to DRS-2 raw scale
      mutate(
        b_Intercept = ( b_Intercept * scl$SD$drs ) + scl$M$drs,
        across( !b_Intercept, function(x) { x * scl$SD$drs } )
      ) %>%
      
      relocate( b_time, .after = ifelse( i == "factor scores", "b_visp_wm", "b_sc_staix2") )

  )

# extract and summarize posteriors of the "fixed-effects"
post <-
  
  lapply(
    
    setNames( names(drws), names(drws) ),
    function(i)
      
      drws[[i]] %>%
      
      # calculate median posterior, 95% PPI and probability of being negative
      apply( . , 2 , function(x) { c(b = median(x), PPI = hdi(x,.width =.95), pd = sum(x<0)/length(x) ) } ) %>%
      t() %>%
      as.data.frame() %>%
      rownames_to_column( var = "Parameter" )

  )

# pre-format draws
drws <- 
  
  lapply(
    
    names(drws),
    function(i)
        drws[[i]] %>%
        select( contains("time") ) %>%
        pivot_longer( cols = everything() ) %>%
        mutate( mod = case_when( i == "factor scores" ~ "Factor scores model", i == "test scores" ~ "Test scores model") )
  
    ) %>%
    
    do.call( rbind.data.frame, . ) %>%
    mutate( name = sub( "time:", "", name ) %>% sapply( ., function(x) v[x, ] ) ) # this line takes some time to compute

# prepare the figure
f4 <-
  
  drws %>%
  ggplot() +
  aes( x = value, y = reorder(name, value, decreasing = T), fill = stat(x) ) +
  geom_density_ridges_gradient( scale = 1.5, rel_min_height = 0.001 ) +
  scale_fill_viridis_c( option = "turbo", direction = -1 ) +
  geom_vline( xintercept = 0, linewidth = .75, linetype = "solid", color = "black" ) +
  geom_vline( xintercept = -as.numeric(b["slope","median"]), linewidth = .75, linetype = "dashed", color = "navyblue" ) +
  labs( x = expression(Delta*"DRS-2 (points per year)"), y = NULL ) +
  scale_x_continuous( limits = c(-1.25,.75) ) +
  scale_y_discrete( labels = function(x) parse( text = paste0( "delta[", x, "]" ) ) ) + # add predictor parameter names
  facet_wrap( ~ mod, scales = "free_y" ) +
  theme_minimal( base_size = 11 ) +
  theme( legend.position = "none" )

# save the plots
ggsave(
  plot = f4,
  filename = here("figs","posterior_distributions.jpg"),
  dpi = 300,
  width = 7,
  height = 7.7
)

# extract statistically clear result for in-text reporting
delta_ef <-
  
  with(
    post$`factor scores`,
    c(
      b = rprint( abs(b[Parameter == "b_time:exec_fun"] ) ), # absolute value of the estimate due to semantics
      PPI =
        paste0(
        "[", rprint( PPI1[Parameter == "b_time:exec_fun"] ),
        ", ", rprint( PPI2[Parameter == "b_time:exec_fun"] ), "]"
        )
    )
  )

```

Both predictive longitudinal GLMMs converged within a specified number of iterations ($\hat{R} \le$ `r rhatmax`) with all observations having Pareto-k below `r parkmax`. Patients with lower verbal working memory or set shifting showed relatively impaired pre-surgery performance on DRS-2 while there was no cognitive test that clearly indicated pre-surgery impairment in DRS-2 performance (see Tables S2 and S3 in Supplementary materials). Patients with lower pre-surgery executive functions/attention performance showed faster post-surgery cognitive decline (see @fig-postdist). Pre-surgery executive functions/attention performance that was one standard deviation below sample average was associated with additional `r delta_ef[['b']]` DRS-2 points post-surgery annual decline (95% PPI `r delta_ef[['PPI']]`). There was no single cognitive test that clearly indicated faster-than-average post-surgery cognitive decline (all 95% PPIs included zero). Notably, both models generated similar predictions for majority of included patients (see Figure S2 in Supplementary material). The only difference in terms of model predictions was that the “cognitive tests” model showed marginally better fit to outlying observations which coupled with the fact that it also showed marginally higher Pareto-k values (see Figure S6 in Supplementary material) indicates that the “cognitive tests” model exhibited less regularization than the “cognitive functions” model. Adding group-level effects of age, LEDD and BDI-II did not reveal any substantial deviation from these results (see Figures S3 and S4 in Supplementary material).

![Interaction terms of the “test scores” (A) and the “factor scores” (B) models predicting post-surgery cognitive decline. Acronyms are explained in the text.](../figs/posterior_distributions.jpg){#fig-postdist}

## Evaluating false positive error rates

```{r}
#| label: sims

rm( list = ls()[ !ls() %in% "itstats" ] ) # clear environment

# summarise of false positives conditional on null hypothesis
falsepos <-
  
  # extract numbers of simulations with at least one false positive
  read.csv( here("mods","sims_fp.csv"), sep = "," ) %>%
  filter( meth == "t0" & fp != 0 ) %>%
  pivot_wider( names_from = "fp", values_from = "Freq") %>%
  select( where( is.numeric ) ) %>%
  rowSums()

```

Results of simulations used to estimate false positive rates of the two-step procedure and the Bayesian Lasso are summarised in Supplementary Materials Figure S6. Overall, the Bayesian Lasso showed almost no false positives across simulation settings whereas the false positive rates of the two-step procedure ranged from `r min(falsepos)` to `r max(falsepos)` of analyses including at least one false positive. In the case of our data structure, the false positive rates were attenuated when all twenty-three predictors covaried or when we reduced the number of predictors to seven independent variables.

# Discussion

In the present study, we analyzed retrospectively sampled data of longitudinally followed `r itstats[['n']][['incl']]` PD patients after STN DBS surgery and described their post-surgery cognitive performance. We observed a mild post-surgery cognitive decline (*RQ1*) that was faster in patients with lower pre-surgery executive functions/attention (*RQ2*) compared to the rest of the sample. Instead of aiming to identify any pre-surgery cognitive variables that can be potentially predictive of post-surgery cognitive decline, we aimed to identify only these variables that are the most likely to be truly predictive. To achieve this goal, we applied the Bayesian Lasso and factor analysis to decrease false positive error rates of our analysis.

According to our data and model, the expected average annual rate of cognitive decline after STN DBS in PD assessed via DRS-2 reaches 0.90 from a total of 144 points which represents slower rate than in previous reports [@castrioto2022; @gruber2019; @schupbach2005; @smeding2009]. These differences can stem from study-specific variables such distinct demographic and clinical characteristic of investigated cohorts, details of selection process for STN DBS or the number of patients followed. However, the results generally correspond with prior findings of gradual but rather mild cognitive decline in PD patients after STN DBS. The effect decreased in size but persisted after adjusting for age, LEDD and depressive symptoms implying that neither withdrawal of dopaminergic medication nor cognitive symptoms associated with depression are likely candidates for explaining away all observed post-surgery cognitive decline.

In the present study, lower performance on the latent factor of executive functions/attention (EF/Att.) was reliably predictive of post-surgery cognitive decline. Similarly, previous studies suggested that patients with executive deficit (operationalized as a performance on tasks such as Stroop test, TMT, Wisconsin Card Sorting Test and verbal fluency test) are at a high risk of developing dementia and experiencing fast cognitive decline after STN DBS surgery [@bove2020; @kishore2019; @smeding2009]. On the other hand, unlike previous studies which singled out pre-surgery test scores that ought to be the most predictive of post-surgery cognitive decline, our findings indicate that it is the combination of small predictive utilities of several test scores that provides the best prognostic value for cognitive decline after STN DBS. The predictive performance of test-level pre-surgery cognitive profile likely results from a combination of small effects of the test scores that also happen to load on the executive function latent factor (compare @fig-postdist and @tbl-factanal). Aggregating results from multiple executive tests to gauge cognitive prognosis of STN DBS patients is therefore likely be superior to interpreting each test score independently [compare to @miyake2000].

## Constraints on Generality

Following contemporary best practices of psychological science we next discuss generalizability of our findings [@simons2017]. Compared to previous research our models allow for broader generalizations of the findings across STN DBS treated PD patients because GLMMs account for interindividual heterogeneity and intraindividual homogeneity [@gelman2012; @yarkoni2020]. However, several constraints of generality still apply to our findings.

Due to a lack of a control group, we cannot discern the causal effect of DBS from the effect of disease progression. Consequently, we limit our conclusions to STN DBS treated patients that were selected for treatment using similar exclusion criteria as those applied in this study (see exclusion criteria above). The lack of control group also limits application of our findings for selection purposes. Since our sample comprised of patients already selected for STN DBS treatment, the estimates could exhibit distortion due to the collider bias if generalized to a larger population of PD patients [@cinelli2022]. We thus advise against using our findings as a basis for patient selection for STN DBS. Instead, practitioners should base their decision for STN DBS treatment on the current best practices [@armstrong2020] and use our findings to single out patients who could benefit from more monitoring.

Another generality constraint stems from the selection of measures used in the current study. Most importantly, there was a lack of visuo-spatial tasks in pre-surgery examination. Moreover, the cognitive outcome was evaluated by DRS-2 which although suitable for cognitive screening of global cognition does not appear to have utility in evaluating single cognitive functions in PD [@lopez2021].

Finally, the results of the EFA analysis can be disputed from several points of view. The EF/Att. factor was loaded on by timed test scores and could thus be better characterized as processing speed instead. We decided to follow the naming convention established in the methods section of our article, however, the lack of time-independent executive tests constitutes a clear limitation of our data set. Moreover, several latent factors identified by the EFA were test-specific (e.g., the visuospatial memory was specific to the Family Pictures test). This issue was most pronounced in the case of verbal working memory factor which was loaded on not only by the prototypical measures of working memory capacity but also by Similarities test of WAIS-III. Some of the identified latent factors can thus represent test-specific commonalities instead of latent cognitive functions. Incidentally, these shortcomings seem to affect the EF/Att. factor the least. Notably, all three of these limitations were also observed in other recent studies that applied latent variable approach to clinically used comprehensive neuropsychological batteries in PD [@chung2021; @specketer2019]. The phenomena observed in EFA results of our study may thus at least partially stem from the contemporary practice of building neuropsychological batteries according to expert consensus and warrant further investigation of a latent structure of such batteries.

## Limitations and future directions

A major limitation of our study is the moderate number of missing values. To alleviate this limitation, we applied a multiple imputation technique with high number of imputations which has been shown to provide reasonable interval estimates in the Bayesian models. However, missing data still lowered estimation precision of effects of those latent cognitive factors that were identified less consistently across imputed datasets (set shifting and spatial working memory). Another way missing data might have influenced our findings is the survivorship bias which could have led to overly optimistic estimates of the post-surgery cognitive decline rate.

Next, our results are limited to evaluating pre-surgery cognitive profile predictive of post-surgery cognitive decline. While we adopted this approach for parsimony’s sake, other non-cognitive features such as demographic or clinical characteristics will likely significantly improve prediction. On the other hand, several recent studies claimed that cognitive outcomes of STN DBS are influenced by the location of stimulating electrode in STN [@john2021; @petry-schmelzer2019; @reich2022]. Further research investigating causal effect of electrode placement on longitudinal cognitive outcome will add a level of explanation that is missing from the current study.

Despite these limitations, our results provide actionable information about the PD patients who are selected for STN DBS treatment based on current best practices. Based on our results, clinicians can preferentially monitor patients with a pre-surgery executive functions/attention deficit. Moreover, the cognitive profile identified in our study can serve to select within STN DBS treated patients suitable candidates for prospective clinical trials investigating effects of strategies to mitigate cognitive decline such as cognitive training, reprogramming of stimulation parameters or further DBS using a secondary target [@cappon2022].

## Conclusions

Our findings imply that STN DBS in combination with oral dopaminergic therapy is a safe treatment option from a cognitive standpoint as it was associated with only mild annual post-surgery cognitive decline. Pre-surgery executive functions/attention deficit appears to have a prognostic value for risk stratification with regards to development of the post-surgery cognitive decline. Based on our models and data, we recommend considering aggregated pre-surgery results from multiple executive tests to estimate cognitive prognosis of PD patients treated with STN DBS rather than evaluating single test scores separately. Future studies may follow-up by evaluating alternatives to factor analysis for estimating the aggregate executive score in everyday clinical practice.

{{< pagebreak >}}

# Acknowledgements

This work was supported by the Czech Ministry of Health under Grant AZV NV19-04-00233; Grant Agency of Charles University under Grant GA UK 254121; EU Joint Programme on Neurodegenerative Disease Research under Grant JPND 733051123; and by The project National Institute for Neurological Research (Programme EXCELES, ID Project No. LX22NPO5107). We further wish to thank all the patients, family members and staff from all the units that participated in the study. In particular, we wish to thank Markéta Fialová, Radka Steinbachová and Anna Rezková for their management of data collection and patient care as well as Petra Balabánová for her assistance with neuropsychological assessments.

# Conflict of interest

Nothing to report.

# Ethical statement

The study was approved by the General University Hospital Ethics Committee in Prague, Czech Republic. All Participants provided informed consent. 

# Data availability
The data that support the findings of this study are available on request from the corresponding author. The data are not publicly available due to privacy or ethical restrictions. The computer code used in our analysis as well as supplementary presentation of our results can be accessed at https://github.com/josefmana/dbs_longCOG.

{{< pagebreak >}}

# References
