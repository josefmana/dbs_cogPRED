---
title: "Preoperative Cognitive Profile Predictive of Cognitive Decline after Subthalamic Deep Brain Stimulation in Parkinson’s Disease"
shorttitle: "Cognition in PD after STN DBS"
author:
  - name: Josef Mana
    corresponding: false
    orcid: "0000-0002-7817-3978"
    email: "josef.mana@protonmail.com"
    role:
      - Conceptualization
      - Data curation
      - Investigation
      - Formal analysis
      - Methodology
      - Software
      - Visualization
      - Writing - original draft
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Ondrej Bezdicek
    corresponding: true
    orcid: "0000-0002-5108-0181"
    email: "ondrej.bezdicek@gmail.com"
    role:
      - Conceptualization
      - Data curation
      - Investigation
      - Methodology
      - Supervision
      - Writing - original draft
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Andrej Lasica
    corresponding: false
    email: "Andrej.Lasica@vfn.cz"
    role:
      - Investigation
      - Data curation
      - Formal analysis
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Filip Ruzicka
    corresponding: false
    email: "filr@seznam.cz"
    role:
      - Investigation
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Anna Fecikova
    corresponding: false
    email: "Anna.Fecikova@vfn.cz"
    role:
      - Investigation
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Olga Klempirova
    corresponding: false
    email: "novakovaol@seznam.cz"
    role:
      - Investigation
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Tomas Nikolai
    corresponding: false
    email: "nikolai@centrum.cz"
    role:
      - Investigation
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Tereza Uhrova
    corresponding: false
    email: "tereza.uhrova@vfn.cz"
    role:
      - Investigation
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Evzen Ruzicka
    corresponding: false
    email: "eruzi@lf1.cuni.cz"
    role:
      - Conceptualization
      - Funding acquisition
      - Investigation
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Dusan Urgosik
    corresponding: false
    email: "urgosik@gmail.com"
    role:
      - Investigation
    affiliations:
      - id: "NHH"
        name: "Na Homolce Hospital, Prague, Czech Republic"
        department: "Department of stereotactic and radiation neurosurgery"
  - name: Robert Jech
    corresponding: false
    orcid: "0000-0002-9732-8947"
    email: "jech@cesnet.cz"
    role:
      - Conceptualization
      - Data curation
      - Funding acquisition
      - Investigation
      - Resources
      - Supervision
      - Writing - review & editing
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
abstract: "Cognitive decline represents a severe non-motor symptom of Parkinson’s disease (PD) that can significantly reduce benefits of subthalamic deep brain stimulation (STN DBS). Here, we aimed to **describe expected post-surgery cognitive decline and** identify pre-surgery cognitive profile associated with faster post-surgery cognitive decline in STN DBS treated PD patients. A retrospective observational study of 126 PD patients treated by STN DBS combined with oral dopaminergic therapy followed for 3.54 years on average (SD = 2.32) with repeated assessments of cognition was conducted. Pre-surgery cognitive profile was obtained via a comprehensive neuropsychological examination. Data were analyzed using exploratory factor analysis for pre-surgery cognitive profile extraction and Bayesian generalized linear mixed models for description of the longitudinal cognitive outcome. Overall, we observed a mild annual cognitive decline of 0.90 points from a total of 144 points in the Mattis Dementia Rating Scale (95% posterior probability interval (PPI) [-1.19, -0.62]). Pre-surgery executive deficit predicted the rate of post-surgery cognitive decline (b = -0.39, 95% PPI [-0.63, -0.15]). The predictive utility of pre-surgery executive deficit resulted from summing small effects of several single test scores. **Exploratory analysis of electrode localisation did not yield any statistically clear results. Overall, our data imply that mild average annual post-surgery cognitive decline in PD patients treated with STN DBS with high inter-individual variability. However, patients with worse long-term cognitive prognosis can be reliably identified via pre-surgery examination of executive functions.**"
keywords:
  - Parkinson’s disease
  - deep brain stimulation
  - cognition
  - longitudinal
  - latent variable analysis
format:
 apaquarto-pdf:
   documentmode: man
   a4paper: true
   pdf-engine: lualatex
   floatsintext: false
   keep-tex: false
bibliography: references.bib
warning: false
echo: false
---

{{< include _extensions/wjschne/apaquarto/_apa_title.qmd >}}

# Introduction

Bilateral subthalamic nucleus (STN) deep brain stimulation (DBS) is an advanced symptomatic treatment of Parkinson’s disease (PD) that can successfully reduce motor symptoms and improve patients’ quality of life [@armstrong2020; @bratsos2018]. On the other hand, prior research revealed considerable heterogeneity in cognitive outcomes after STN DBS with a small to moderate post-surgery decline in verbal fluency and equivocal results for other cognitive domains [@combs2015; @mehanna2017; @parsons2006]. The ability to predict which patients are likely to develop post-surgery cognitive decline can thus prove useful for patient selection and for guiding post-surgery patient monitoring. In this article, we aim to describe **annual rate of long-term post-surgery cognitive decline after STN DBS in PD as well as** pre-surgery cognitive profile extractable from clinically available neuropsychological evaluation that **predicts faster post-surgery decline**.

**When describing longitudinal post-surgery cognitive decline, the majority of prior studies employed pre-test/post-design with change scores as their dependent variable [@gruber2019; @kim2014] or estimated dementia-free survival time [@barbosa2024; @bove2020; @kishore2019]. When conversion to dementia is an outcome, studies do not estimate annual rate of post-surgery decline but the time it takes to reach clinically salient cognitive deficit. On the other hand change scores have a drawback of confounding true change with measurement error [@singer2003]. Furthermore, the focus on change scores allows researchers to estimate group-level post-surgery changes describing their sample but ignores patient-level variability which is necessary to generalize findings beyond the sample [@yarkoni2020]. In this study, we leverage the fact that our data set includes three or more observations in large enough number of patients to estimate both group-level post-surgery cognitive decline to describe our sample as well as patient-level variability to provide predictions for other similar samples.**

**With regards to predicting post-surgery cognitive decline from patients' pre-surgery cognitive profile, s**tudies addressing th**is** task can be broadly divided to two groups, randomized controlled trials (RCT*s*) and long-term observational studies. In a typical RCT, patients are randomized to treatment and placebo groups and outcomes are compared in a full factorial design (**representing the estimand of interest** as interactions between group and time of assessment) [@schupbach2007]. Courtesy of their experimental control RCTs allow for causal inference and are well suited for providing guidelines for patient selection. However, even though RCTs are regarded as a gold standard for causal inference, it is ethically unacceptable to deny DBS treatment for PD patients for longer time intervals than necessary. Long-term (i.e., more than three years after surgery) outcomes can thus be best described by observational studies. While observational studies usually do not allow for causal inference and are not well suited for guiding patient selection due to a lack of proper control group and resulting collider bias [@cinelli2022], they are well suited for description of patients’ long-term outcomes. Longitudinal observational studies can serve as a basis for selecting high-risk STN DBS treated patients that would benefit from increased monitoring.

Previous longitudinal observational studies reported that PD patients treated with STN DBS showing pre-surgery deficit in executive functions **or poorer memory** are at risk of faster post-surgery cognitive decline or developing dementia [@bove2020; @gruber2019; @kim2014; @kishore2019; @smeding2009; @jahanshahi2022]. However, previous studies aimed at identifying any possible pre-surgery predictors of post-surgery cognitive decline accepting high false positive error rates **and effect sizes inflation** in the process. In this study, we complement prior findings by identifying a sparse solution to the problem of identifying pre-surgery cognitive profile that is predictive of long-term post-surgery cognitive decline in naturalistic clinical settings. In other words, we aim to describe a minimal significant pre-surgery cognitive profile that predicts higher rate of post-surgery cognitive decline in a sample derived from everyday clinical practice.

In a typical observational study aiming to determine pre-surgery risk factors of post-surgery cognitive decline the authors employ the following two-step procedure. In the first step, a series of separate univariate analyses for each potential predictor is conducted to pre-select variables for further analysis. In the second step, predictors that achieved an arbitrary threshold (e.g., p \< 0.05) are used to predict the cognitive decline in a subsequent multiple regression model [@bove2020; @gruber2019; @kim2014; @smeding2009]. This procedure **was named "univariable screening" in biomedical statistics literature and was shown to systematically overestimate effect sizes [@vanzwet2019; @vanzwet2021]. In this article, we show that it** can **also** lead to false positive error rates that are magnitudes higher than the expected nominal five percent.

**One way to** overcome shortcoming**s of univariable screening is to use partially pooling estimators of the effects associated with each predictor. This can be achieved via regularizition of multiple regression coefficients [@vanzwet2019]. In this, regularizing technique of choice is** the Bayesian Lasso regression, a method developed for identifying small amount of significant predictors out of a larger pool of possible predictors such as results from a comprehensive neuropsychological battery [@park2008].

Another way to achieve sparsity in prediction of post-surgery cognitive decline is to reduce the number of potential predictors. In the context of neuropsychological assessment this can be accomplished straightforwardly via a latent variable approach such as factor analysis that statistically extracts commonalities across several cognitive tasks. Added benefit of employing such a procedure to pre-surgery predictors is that latent variable approaches can reduce the impact of the task impurity problem – the observation that any cognitive task involves several cognitive functions at once [@burgess2014; @whitney2010a].

Overall, in this study we aimed to **describe annual post-surgery cognitive decline on group- and patient-level as well as** derive a sparse solution to the task of identifying pre-surgery cognitive profile predictive of long-term post-surgery cognitive decline in STN DBS treated PD patients. In other words, instead of identifying any pre-surgery cognitive variables that can be predictive of post-surgery decline, we aimed to identify only the most likely predictive ones. To this end, we asked the following research questions: *RQ1)* What is the size of expected long-term rate of cognitive decline after STN DBS in PD patients? *RQ2)* What is the pre-surgery cognitive profile that is predictive of long-term post-surgery cognitive decline in STN DBS treated PD? To answer these questions, we analyzed data of retrospectively sampled longitudinally followed STN DBS treated PD patients with a single pre-surgery comprehensive neuropsychological assessment and up to five post-surgery cognitive screening assessments.

# Materials and methods

## Participants

The data of all patients diagnosed with idiopathic PD following United Kingdom Parkinson’s Disease Society Brain Bank Criteria [@hughes1992] that underwent cognitive evaluation for STN DBS treatment at General University Hospital in Prague between years 2000 and 2020 were retrospectively gathered from clinical records and considered for inclusion in the study. **Patients were selected for DBS treatment via criteria mirroring the CAPSIT protocol [@defer1999], consequently p**atients with atypical parkinsonian syndromes, dementia, depression at the time of pre-surgery assessment (according to an independent psychiatric evaluation), recurrent psychotic conditions or a gait disorder despite optimal dopaminergic therapy during pre-surgery assessment were not implanted and were thus not included in the study. Furthermore, only patients who underwent pre-surgery and at least one post-surgery assessment were included. All included patients were treated via continuous bilateral STN DBS in conjunction with dopaminergic therapy. Bilateral STN DBS implantation was performed as previously described [@jech2012; @jech2006; @urgosik2011]. All patients provided signed informed consent and the study was approved by the General University Hospital Ethics Committee in Prague, Czech Republic.

## Assessments

All patients underwent a comprehensive pre-surgery assessment including neuropsychological and neurological examinations. The patients were followed up post-surgery with similar examination protocol at varying time intervals according to their options. Post-surgery, patients were first contacted one year after the surgery and every two years afterwards. The pre-surgery assessment was performed with the usual dopaminergic therapy (ON medication). In the post-surgery assessment, patients were examined in the ON medication condition and STN DBS ON with optimal stimulation parameters.

### Pre-surgery neuropsychological measures

The neuropsychological assessment was arranged analogously to the standard International Parkinson and Movement Disorder Society (MDS) neuropsychological battery at Level II for mild cognitive impairment in Parkinson’s disease (PD-MCI) [@bezdicek2017; @litvan2012]. The battery consisted of 10 tests in 5 cognitive domains: (i) attention: Trail Making Test, part A (TMT-A) [@bezdicek2012; @bezdicek2017a; @partington1949] and dot color naming condition from Prague Stroop Test (PST-D) [@bezdicek2015a] for sustained visual attention; (ii) executive functions: Trail Making Test, part B (TMT-B) [@bezdicek2012; @bezdicek2017a; @partington1949] for set shifting, and Tower of London task (TOL) [@michalec2017; @shallice1982] for planning; (iii) language: Similarities (Sim.) from Wechsler Adult Intelligence Scale, third revision (WAIS-III) [@wechsler2010] for conceptualization, and category verbal fluency test (CFT, category Animals) [@nikolai2015] for speeded word production; (iv) working memory: Digit Span backward (DS-B) from WAIS-III [@wechsler2010] and Spatial Span backward (SS-B) from Wechsler Memory Scale, third edition (WMS-III) [@wechsler2011] for auditory and spatial working memory respectively; and (v) memory: Rey Auditory Verbal Learning Test delayed recall (RAVLT-DR) [@bezdicek2014; @frydrychova2018] for explicit verbal learning and memory, and WMS-III Family Pictures delayed recall (FP-DR) for visuo-spatial memory [@wechsler2011]. Furthermore, we administered the following tests beyond the battery: Prague Stroop Test, naming color of neutral words (PST-W) and interference condition (i.e., naming color of contrasting color words, PST-C) for sensitivity to interference [@bezdicek2015a], Controlled Oral Word Association Test (COWAT, letters K + P) [@nikolai2015] for mental flexibility, and WMS-III letter-number sequencing (LNS) [@wechsler2011] for working memory. Finally, anxiety was assessed with the State-Trait Anxiety Inventory for the state (STAI-X1) and trait (STAI-X2) anxiety [@spielberger1983].

### Longitudinal neuropsychological measures

Patients’ longitudinal cognitive state was assessed pre-surgery and post-surgery with MDS battery at Level I using Mattis Dementia Rating Scale, second edition (DRS-2) [@bezdicek2015; @jurica2001]. DRS-2 is a routinely employed cognitive screening measure in PD that has been shown to have acceptable discriminative performance for PD-MCI in Czech population with both sensitivity estimated to be around 0.8 [@bezdicek2015; @mazancova2020]. Furthermore, subjective depressive symptoms were assessed with Beck Depression Inventory, second edition (BDI-II) [@beck1996; @ciharova2020] at each assessment. BDI-II was not used for pre-surgery exclusion due to depression which was instead ascertained by an independent neuropsychiatric evaluation.

### Neurological examination

Patients’ motor state was assessed with part three of the Movement Disorders Society Unified Parkinson's Disease Rating Scale (MDS-UPDRS III) in medication ON and medication OFF state during the pre-surgery levodopa test. Scores of patients who underwent the older version of the Unified Parkinson’s Disease Rating Scale (UPDRS III) were converted to the MDS-UPDRS III scale using the method described by @hentz2015. The levodopa equivalent daily dose (LEDD) was calculated at each assessment time-point according to @tomlinson2010.

## Theoretical and empirical estimands

**Following the framework of @lundberg2021, in this section we link our research questions to explicit targets of inference (i.e., theoretical estimands) and to observable data (i.e., empirical estimads). Within this framework, the theoretical estimand consists of two components, a unit-specific quantity and the target population. Regarding our** ***RQ1*****, the patient-specific quantity of interest is the difference between expected post-surgery cognitive performance and expected cognitive performance** ***k*** **years before where** ***k*** **can be any positive real number. We aimed to describe this quantity on two levels: (i) the current sample and (ii) a population of patients selected for DBS treatment via the CAPSIT-protocol criteria. To allow for generalization beyond our sample as per the second version of this theoretical estimand, we assume exchangeability between patients selected via CAPSIT criteria to the extend that can be quantified by patient-level variance estimated from our sample [see @yarkoni2020]. The patient-specific quantity for** ***RQ2*** **is the difference between expected post-surgery cognitive decline of a patient with fixed level of pre-surgery performance across all cognitive variables and expected post-surgery cognitive decline of patients with performance that is one unit smaller in a single cognitive variable but equal to this patient's performance otherwise. This quantity was described for the sample only. Empirical estimands were the same quantities, conditional on patient being selected for the study (based on geographical and exclusion criteria described above). Importantly, all three estimands are descriptive, not causal.**

## Statistical analyses

### Deriving pre-surgery cognitive profile

Latent cognitive factors were extracted from the data via an exploratory factor analysis (EFA) with varimax rotation using ordinary least squares to find the minimum residual solution [@harman1966]. We opted for the orthogonal varimax rotation because: (i) extracting orthogonal factors can be statistically advantageous in later steps of our analysis due to reducing multicollinearity, and (ii) in the framework of PD-MCI, it is considered desirable to describe patients’ cognitive profile by factors or tests that are independent of each other [@litvan2012].

All pre-surgery cognitive tests listed above were entered into EFA as input variables (see **the** Supplementary material for the exact processing pipeline). Missing observations were multiply imputed using a parametric bootstrap via the “missMDA” R package to create one hundred imputed data sets We then computed EFA with three up to eight factors via the “psych” R package [@rsoft; @missMDA; @psych] using each imputed data set. Within each imputed data set, factor scores for each patient were calculated using the regression method [@thomson1951].

We based the number of extracted factors on a combination of the root-mean-square error approximation (RMSEA), Tucker-Lewis Index (TLI), and consistency of each factor model across imputations. TLI is a measure of a goodness-of-fit such that higher values of TLI imply better fit and values exceeding 0.90 are considered to indicate a good model fit. On the other hand, RMSEA is a measure of badness-of-fit such that lower values imply better fit with values less than 0.08 indicating an adequate model fit [@browne1992]. A model was considered consistent if the model identified similar factors across imputed data sets.

### Describing and predicting post-surgery cognitive decline

Longitudinal data were analyzed using Bayesian generalized linear mixed models (GLMMs). GLMMs overcome th**e** issue **of confounding measurement error with true change plaguing change scores** by estimating both group-level (i.e., “fixed effect”) as well as patient-level (i.e., “random effect”) parameters. Furthermore, modelling patient-level effects results in partial pooling of parameter estimates (shifting parameter estimates towards each other), which reduces the influence of outliers and facilitates reliable group-level inference [@gelman2012; @tuerlinckx2006].

To describe the rate of post-surgery cognitive decline, we estimated a GLMM with longitudinal DRS-2 performance as an outcome predicted by the time after surgery on the group-level and correlated patient-specific intercepts and slopes on the patient-level. Since the group-level slope of this model represents the expected rate of cognitive decline after STN DBS, it constituted the **statistical estimate of the sample version of our empirical** estimand for *RQ1* **(i.e., the expected annual cognitive decline in the sample). To arrive at the statistical estimate of the population version of our empirical estimand for** ***RQ1*** **(i.e., the expected annual cognitive decline in a population of patients selected for surgery using CAPSIT-protocol criteria) we used the model to predict expected post-surgery cognitive decline at one year post-surgery intervals compared to a pre-surgery assessment ca 0.3 years before surgery using both group- and patient-level parameters. We** evaluate**d** suitability of the linear model **by** compar**ing** it to an **otherwise** equivalent non-linear model that estimated post-surgery cognitive trajectory via tensor product smooths [@wood2012]. Both models were fitted using non-informative improper flat priors **for group-level parameters** to ensure that their parameters are informed primarily by the data.

T**o evaluate predictive utility of pre-surgery cognitive profile, **w**e estimated further two** GLMMs. **L**ongitudinal DRS-2 performance was predicted on a group-level by post-surgery time slopes varying by either patients’ pre-surgery cognitive tests’ scores (the “test scores” model) or patients’ pre-surgery latent cognitive factors’ scores extracted from the EFA reported above (the “factor scores” model). Both models further included correlated patient-level intercepts and slopes. To check robustness of our findings we compared the results to estimates of GLMMs that also included group-level effects of age, LEDD and BDI-II (and their interaction with time after surgery).

Since previous long-term studies demonstrated that a subset of PD patients treated with STN DBS can develop dementia which may lead to heavy tails in the data distribution of cognitive test scores, we **used a ** Student-t instead of Gaussian **measurement error model**. Furthermore, because the outcome DRS-2 has a maximum of 144 points which is achieved by a large proportion of healthy people [@bezdicek2015], we used the right-censored version of Student-t to account for the ceiling effect. Models’ likelihoods had following specification:

$$P(DRS_i = DRS_{max}) = 1 - T(\vartheta,\mu_i,\sigma), for DRS_i \in N_{max}, N_{max} = \{i: drs_i = drs_{max}\}$$ $$DRS_i \sim~ t(\vartheta,\mu_i,\sigma), for DRS_i \in N_1, N_1 = \{i: drs_i < drs_{max}\}$$ $$\mu_i = \alpha + \delta_{time}time_i + \sum_{j=1}^{m} (\beta_{predictor[j]}predictor_{[j]i} + \delta_{predictor[j]}time_ipredictor_{[j]i}) + z_{id[i]}\tau_{\alpha} + x_{id[i]}\tau_{\delta}time_i$$

*i* = 1…*n*, where *n* is the total number of assessments across all patients, *m* is the total number of pre-surgery predictors, $DRS_{max}$ is the maximal attainable score in DRS-2 (i.e., a raw score of 144), *T()* is the Student-t cumulative distribution function, *t()* is the Student-t probability density function, $time_i$ is the time from surgery at assessment *i*, $predictor_{[j]i}$ is the pre-surgery cognitive score in the predictor (i.e., either a test or latent factor) *j* of the patient evaluated at assessment *i*, **$\tau$ parameters represent patient-level variance, $z_k$ and $x_k$ represent standardized patient-level effects for** ***k^th^*** **patient, $\mu_i$ represents true score estimate of ***k^th^*** **patient's cognitive performance on assessment at $time_i$**, and remaining terms denote model parameters. E**mpirical e**stimands relating to *RQ2* comprised of the two sets of $\delta_{predictor[j]}$ representing the expected prognostic value of single pre-surgery cognitive tests and latent cognitive factors.

We specified equivalent prior distributions for model parameters of both the “test scores” and the “factor scores” models. We used the Bayesian Lasso priors for all group-level parameters barring the intercept. This prior is the Bayesian equivalent of the Lasso method for performing variable selection and allows for fitting models with a large number of potentially collinear predictors All remaining parameters were given weakly informative priors to ensure that models’ estimates fall within the range of measurable values of the outcome.

### Exploring association of stimulated STN site with cognitive decline

**Although our primary goals relate to the purely descriptive task of predicting post-surgery cognitive decline, further studies might want to ask causal questions about possible interventions to change the rate of this decline. A straightforward way to possibly affect cognitive performance after STN DBS surgery is to change active stimulation contacts such that volume of affected tissue (VAT) overlaps with motor component of STN while avoiding associative and limbic STN components because high frequency stimulation that improves motor symptoms can result in adverse cognitive side effects [@david2020]. Even though our retrospective sample did not contain enough  high-quality data that would be needed to reliably evaluate association between STN sites affected by DBS and post-surgery cognitive decline, we provide an exploratory analysis that can provide pointers for future investigations.**

**For this analysis, we used a subsample of patients for whom we were able to retrospectively obtain (i) pre-surgery magnetic resonance image (MRI) for STN localization, (ii) post-surgery MRI for electrode localization, and (iii) stimulation parameters at the time of MRI assessment for VAT computation. Lead-DBS software [@horn2015; @horn2019] was utilized to determine the position of DBS leads and active contacts with DISTAL subcortical atlas for STN compartmentalization [@ewert2018]. The overlap of the VAT and the entire STN as well as its motor, associative, and limbic components separately was calculated, providing four overlap volumes for each side. For each patient with VAT available, only one set of overlaps was estimated which corresponded to the time of MRI acquisition, not the time of cognitive assessment as these were not always aligned. We then explored the association between VAT overlaps with STN components and post-surgery cognitive decline using a model analogous to the predictive GLMMs described above. For more detailed information about MRI acquisition parameters and modelling choices regarding this analysis see the Supplementary material.**

### Model description and statistical testing

**Estimates** were described by **full posterior distributions,** medians and 95% highest density posterior probability intervals (PPIs) of corresponding model parameters **or predictions as appropriate**. A 95% PPI can be interpreted **as the narrowest interval** such that a given parameter **or prediction lies within this interval with 95% probability.** **In one case, when presenting results for the second version of our** ***RQ1*** **estimand, we report medians and 90% equal-tailed posterior probability intervals (ETIs) instead. A 90% ETI can be interpreted such that a given parameter or prediction lies with 5% probability above its upper bound and with 5% probability below its lower bound.**

Models were compared via the expected log pointwise predictive density (ELPD) computed via the leave-one-out cross-validation (LOO-CV) as approximated by the Pareto-smoothed importance sampling (PSIS) [@vehtari2015]. The ELPD difference ($ELPD_{dif}$) and its 95% frequentist confidence interval (CI) were used to decide whether predictive performance of compared models statistically significantly differs (i.e., the 95% CI excludes zero). To identify influential observations, we calculated a Pareto-k diagnostic and looked for observations with Pareto-k \> 0.7 which can be considered problematic [@bürkner2020; @vehtari2015].

### Evaluating false positive error rates

To validate the assumption that our analysis provides lower false positive rates than the commonly used **univariable screening** procedure we conducted **a** series of simulations with data set structure equivalent to that observed in our data. Patients’ outcome was generated as a normally distributed random variable with unit standard deviation and mean depending on average annual rate of cognitive decline and patient-specific random deviations. Moreover, for each patient we generated a set of potential predictors including either seven independent variables, twenty-three independent variables or twenty-three covaried variables representing our analysis of the predictive utility of seven latent cognitive factors and twenty-three observed cognitive test scores respectively. Covariance structure in the case of covaried predictors was based on the structure of the battery described above with predictors that represented test measures belonging to the same superordinate task having Pearson’s correlation of 0.7 (thus sharing approximately half of the variance) and zero otherwise (see Figure S**11** in **the** Supplementary material). The simulations were set-up such that there was no effect of any predictor on the outcome. Subsequently, we generated one hundred data sets which were then fitted via the **univariable screening** procedure and **the** Bayesian Lasso. For each procedure, number of statistically significant interactions between time and any of the predictors were recorded to estimate the amount of false positive errors.

### Transparency and openness

All GLMMs were fitted using via Stan’s (version 2.21.0) build-in Hamiltonian Monte Carlo sampler accessed via R version **`r with( version, paste(major,minor,sep=".") )`** using package “brms” [@bürkner2017; @rsoft; @stan]. Four parallel chains were run each for 2,500 iterations for each GLMM. The first 500 iterations served as a warm-up and were discarded. Convergence was checked numerically by inspection of the R̂s and visually by inspection of trace plots. We used R packages “tidyverse” and “dplyr” for data operations, “tidybayes” for operation with model posteriors, and “DiagrammeR, “ggplot2” and “patchwork” for plotting [@DiagrammeR; @ggplot2; @patchwork]. This study’s design and its analysis were not pre-registered. The data are not publicly available due to privacy or ethical restrictions. The computer code used in our data analysis as well as synthetic data and rep**roducible** code for simulations to estimate false positive error rates can be accessed at **[https://github.com/josefmana/dbs_cogPRED](https://github.com/josefmana/dbs_cogPRED)**.

# Results

```{r}
#| label: import

library(here) # reading & saving files
library(tidyverse) # data wrangling
library(gt) # tables formatting
library(DiagrammeR) # flowchart
library(DiagrammeRsvg) # saving flowchart
library(rsvg) # saving flowchart
library(patchwork) # glueing plots together
library(brms) # model processing
library(tidybayes) # posterior manipulations
library(ggridges) # plotting posteriors
library(english) # number to text conversion

# clear environment
rm( list = ls() )

# set ggplot theme
theme_set( theme_minimal(base_size = 12) )

# read the data set and prepare subsets for individual analyses
d0 <- read.csv( here("_data","20220508_dbs_longCOG_data.csv") , sep = "," )
d1 <- d0[ d0$included == 1 , ] # only STN-DBS treated patients with pre- and post-surgery data
d2 <- d1[ d1$ass_type == "pre" , ] # only pre-surgery assessments of included patients

# read a file containing mapping of variables' names used in the script to variables' names for the manuscript
v <- read.csv( here("_data","var_nms.csv") , sep = ";" , row.names = 1 , encoding = "UTF-8")


# IN-HOUSE FUNCTIONS ----

# printing rounded number
rprint <- function( x, dec=2 ) sprintf( paste0("%.",dec,"f"), round( x , dec) )

# upper bound
ubound <- function( x, dec=2 ) ifelse( round(x,dec) > x, rprint(x,dec), rprint( x+1/(10^dec), dec ) )

# read models
mread <- function( files, names ) {
  
  lapply(
    
    setNames(files,names),
    function(i)
      readRDS( here( "mods", paste0(i,".rds") ) )

  )

}

# IN-TEXT STATS ----

itstats <-
  
  with(
    
    d1, list(
      
      # number of patients
    n = c( tot = length( unique(d0$id) ), incl = length( unique(id) ) ),
    
    # duration of follow-up
    fudur =
      
      sapply(
        c("mean","sd","median","min","max"), # stats to compute
        function(i)
          do.call( i, list( time_y[ complete.cases(drs_tot) & ass_type != "pre" ] ) ) %>%
          rprint(2)
      ),
    
    # number of assessments per patient
    nass =
      
      sapply(
        c("median","min","max"),
        function(i) do.call( i, list( table( id[ complete.cases(drs_tot) ] ) ) )
      )
      
    )
  )

```

## Characterizing the sample

A total of `r itstats[['n']][['tot']]` patients with PD who underwent cognitive evaluation for STN DBS between 2000 and 2020 were identified by a retrospective search of local database in General University Hospital in Prague and a total of `r itstats[['n']][['incl']]` patients met inclusion criteria (see @fig-flow). All included patients were Caucasians and were speaking Czech as their primary language. Baseline demographic and clinical characteristics as well as stimulation parameters of the sample are presented in @tbl-base and baseline cognitive characteristics are presented in @tbl-cog. Mean duration of a follow-up after the surgery was `r itstats[['fudur']][['mean']]` years (SD = `r itstats[['fudur']][['sd']]`, median = `r itstats[['fudur']][['median']]`, range = `r itstats[['fudur']][['min']]`–`r itstats[['fudur']][['max']]`) with a median number of `r itstats[['nass']][['median']]` assessments per patient (range = `r itstats[['nass']][['min']]`–`r itstats[['nass']][['max']]`) (see also @fig-dist).

```{r}
#| label: fig1

# check that when selecting only rows containing pre-surgery assessment there ain't no patient duplicated
#with( d0, isTRUE( all.equal( id[ass_type=="pre"], unique(id[ass_type=="pre"]) ) ) )

# print a table summarizing reasons for excluding patients
#table( d0[ d0$ass_type == "pre" , ]$why_excluded )

# using numbers from t0 create an inclusion/exclusion flowchart
f1 <- " digraph {
  
  /// define nodes which will include numbers reflecting the inclusion/exclusion process
  node [ fontname = Calibri, fontsize = 10, shape = box, style = rounded , width = 2.75 , margin= 0.1 , penwidth = 1 ];
  
  /// create a box for all patients, i.e., sum(t) = 200 patients
  all_pats [ label =<
  <b>200 consecutive<br/>PD patients </b><br/><br/>Local database 2000-2020<br/>General University Hospital<br/>in Prague
  >];
         
  /// create a box for all STN-DBS patients, i.e., sum(t[c(1,4,5,6,7,8,9,11)])) = 173 patients
  all_stn [ label =<
  <b>173 patients </b><br/><br/>implanted with STN-DBS
  >];
  
  /// create a box for all included patients, i.e., t[4] = 126 patients
  all_incl [ label =<
  <b>126 patients </b><br/><br/>followed-up longitudinally
  >];
  
  /// create nodes for exluded patients, specifying only these characteristics that will differ from the nodes above
  node [ fixedsize = T, width = 2.5, height = .75, margin= 0.2 ];
  
  /// create a box for non-STN-DBS patients, i.e., t[c(3,13,2,10,12)] with sum(t[c(3,13,2,10,12)]) = 27 patients
  excl_nostn [ label =<
  <b>27 patients excluded due to</b><br align = 'left'/><br align = 'left'/>
  12 GPi-DBS<br align = 'left'/>
  4 VIM-DBS<br align = 'left'/>
  4 duodopa<br align = 'left'/>
  5 rejected<br align = 'left'/>
  2 suspended<br align = 'left'/>
  >];
  
  /// create a box for STN-DBS excluded patients, i.e., t[c(1,7,9, 8, 6,11, 5)], sum(t[c(1,7,9,8,6,11,5)]) = 47 patients
  excl_stn [ label =<
  <b>47 patients excluded due to</b><br align = 'left'/><br align = 'left'/>
  24 pre-surgery data missing<br align = 'left'/>
  18 follow-up data missing<br align = 'left'/>
  3 unilateral STN-DBS<br align = 'left'/>
  2 not speaking Czech<br align = 'left'/>
  >];
  
  /// create dummy nodes for horizontally forking out of the vertical 'inclusion flow' to excluded sides
  node [ shape = rectangle, width = 0, height = 0, label = '', fill = black ];
  
  /// create directed edges in the inclusion (from dummy/fork vertically to inclusion boxes)
  /// and the exlusion (from forks horizontally to exclusion boxes) parts of the flowchart
  /// first make the arrows bigger
  edge [ arrowsize = .75, penwidth = 1 ]
  
  /// specifiy paths
  fork1 -> all_stn; fork2 -> all_incl;
  
  /// for the horizontal paths use 'rank = same' to ensure their nodes are level
  { rank = same ; fork1 -> excl_nostn }
  { rank = same ; fork2 -> excl_stn }
  
  /// create non-directed edges from the inclusion boxes to dummy/fork boxes (vertically)
  edge [ dir = none, penwidth = 1 ]
  all_pats -> fork1; all_stn -> fork2;

  /// seperate dummy/fork nodes from exclusion boxes by some reasonable distance (in inches)
  nodesep = .75
  }"

# save the flowchart as Fig 1
grViz(f1) %>% export_svg() %>% charToRaw() %>% rsvg_png( here("figs","inclusion_flowchart.png") )

```

![Patients inclusion/exclusion flowchart.](../figs/inclusion_flowchart.png){#fig-flow}
```{r}
#| label: tabs-prep

# function for calculating the stats
dstat <-
  
  function(x,dec1,dec2) {
    
    if (is.numeric(x) ) {
      c( N = sum( !is.na(x) ),
         Md = rprint( median(x,na.rm=T), dec1 ),
         `Min-Max` = paste0( rprint( min(x,na.rm=T), dec1 ),"-",rprint( max(x,na.rm=T), dec1 ) ) ,
         M = rprint( mean(x,na.rm=T), dec2 ),
         SD = rprint( sd(x,na.rm=T), dec2 )
         )
    } else rep( NA, 5 ) # print NAs for non-numeric variables
    
  }

# list all variables for Tab 1 (clinics and stimulation parameters) and Tab 2 (neuropsychology)
nms <-
  
  list(
    dems = names(d2)[which(names(d2)=="age_stim_y"):which(names(d2)=="mds_updrs_iii_med_off")],
    pars = names(d1)[which(names(d1)=="current_r_mA"):which(names(d1)=="frequency_l_Hz")],
    tests = names(d2)[which(names(d2)=="drs_tot"):which(names(d2)=="fp_dr")]
  )

# extract stats for description of the sample
t <-
  
  lapply(
    setNames( names(nms), names(nms) ),
    function(i)
      # stimulation parameters calculated from d1, others from d2
      sapply( nms[[i]], function(j) if ( i == "pars" ) dstat(d1[[j]],1,2) else dstat(d2[[j]],0,2) ) %>% t()
  )

# add count of males
t$dems["sex","N"] <-
  
  paste0(
    table(d2$sex)["male"], " (", # frequency
    sprintf( "%.0f" , round( 100 * ( table(d2$sex)[ "male" ] / sum( table(d2$sex) ) ), 0 ) ), " %)" # percentage, rounded to integers
  )

# fill-in number of patients in each row of stimulation parameters table
t$pars[ ,"N"] <- c( rep(67,2) , rep(59,2) , rep(nrow(d2),4) )


# loop through all variables the pre-tables and change their names accordingly
for ( i in names(t) ) {
  
  t[[i]] <-
    
    t[[i]] %>%
    as.data.frame() %>%
    rownames_to_column( var = "Characteristic" ) %>% # prepare the first column
    mutate( Characteristic = sapply( 1:nrow(.), function(j) v[Characteristic[j], ] ) ) # rename

}

# prepare Table 1 of clinical & stimulation variables
t1 <-
  
  lapply( names(t)[1:2], function(i) t[[i]] %>% mutate( Type = i, .after = 1 ) ) %>% # add type of variable
  do.call( rbind.data.frame, . ) %>%
  mutate( Type = case_when( Type == "dems" ~ "Baseline characteristics", Type == "pars" ~ "Stimulation parameters") ) %>%
  mutate( across( everything(), ~ ifelse( is.na(.x), "-", .x) ) )

# prepare a neuropsychology table
t2 <- t$tests %>% rename( "Test" = "Characteristic" )

# save both of them as .csv
write.table( t1, file = here("tabs","clinical_characteristics.csv"), sep = ",", row.names = F, quote = F )
write.table( t2, file = here("tabs","baseline_neuropsychology.csv"), sep = ",", row.names = F, quote = F )

```

```{r}
#| label: tbl-base
#| tbl-cap: Clinical characteristics of the sample of included patients

# prepare a gt object
t1 <-
  
  gt( t1, rowname_col = "Characteristic", groupname_col = "Type" ) %>%
  cols_align( align = "center", columns = -1 ) %>%
  tab_footnote(
    footnote = "Each measurement of each electrode considered independently. For stimulation parameters, column N indicate number of patients with current/voltage mode of stimulation.",
    locations = cells_row_groups( groups = "Stimulation parameters" )
  ) %>%
  tab_source_note(
    source_note = "N: number of observations; Md: median; M: mean; SD: standard deviation; MDS-UPDRS III: Movement Disorder Society Unified Parkinson’s Disease Rating Scale, motor part; LEDD: levodopa equivalent daily dose; Levodopa test: a percentage change of the MDS-UPDRS III score from medication OFF to medication ON state during the levodopa test as described in the main text; V: Volts; mA: milliampere; μs: microseconds; Hz: Hertz."
  )

# save & print it
gtsave( data = t1, filename = here("tabs","clinical_characteristics.docx") )
t1
```

```{r}
#| label: tbl-cog
#| tbl-cap: Pre-surgery neuropsychological measures of included patients

# prepare a gt object
t2 <-
  
  gt( t2, rowname_col = "Characteristic" ) %>%
  cols_align( align = "center", columns = -1 ) %>%
  tab_source_note(
    source_note = "N: number of observations; Md: median; M: mean; SD: standard deviation; DRS-2: Dementia Rating Scale, second edition; BDI-II: Beck Depression Rating Scale, second edition; STAI-X1: State-Trait Anxiety Inventory, the state version; STAI-X2: State-Trait Anxiety Inventory, the trait version; TMT-A: Trail Making Test, part A; TMT-B: Trail Making Test, part B; DS-F: Digit Span forward; DS-B: Digit Span backward; LNS: letter-number sequencing; SS-F: Spatial Span forward; SS-B: Spatial Span backward; TOL: Tower of London task; PST-D: Prague Stroop Test, dot color naming; PST-W: Prague Stroop Test, word color naming; PST-C: Prague Stroop Test, interference condition; COWAT: Controlled Oral Word Association Test; CFT: category fluency test; Sim.: Similarities; RAVLT-IR: Rey Auditory Verbal Learning Test, immediate recall; RAVLT-B: Rey Auditory Verbal Learning Test, recall of the interference set; RAVLT-DR: Rey Auditory Verbal Learning Test, delayed recall; RAVLT- Rec50: Rey Auditory Verbal Learning Test, delayed recognition from 50 items (15 correct answers + 35 distractors); RAVLT-Rec15: Rey Auditory Verbal Learning Test, delayed recognition, number of correctly identified from 15 items; FP-IR: Family Pictures, immediate recall; FP-DR: Family Pictures, delayed recall; Secs: seconds; Total words: word count in two minutes (one minute per each letter P and K); words/min.: word count in one minute time limit."
  )

# save & print it
gtsave( data = t2, filename = here("tabs","baseline_neuropsychology.docx") )
t2
```

```{r}
#| label: fig2

# prepare both sub-figures
fig2 <- 
  
  list(
    
    # need to use the complete.cases command because three patients have duplicated rows
    # due to more than one stimulation parameter
    hist =
      d1[ complete.cases(d1$drs_tot) , ] %>% 
      ggplot( aes(x = time_y) ) +
      stat_bin( breaks = seq(-2,12,.5) ) + # creates bars
      stat_bin( breaks = seq(-2,12,.5), geom = "text", aes(label = after_stat(count) ), vjust = -0.8, size = 3 ) + # add numbers
      labs( x = "Time from STN-DBS surgery (years)", y = "Number of Assessments" ) +
      scale_y_continuous( expand = c(0, 0), limits = c(0, 107), breaks = seq(0, 100, 10), labels = seq(0, 100, 10) ) +
      scale_x_continuous( limits = c(-2, 12), breaks = seq(-2, 12, 1), labels = seq(-2, 12, 1) ) +
      theme( panel.grid.minor = element_blank() ),
    
    # prepare a bin plot showing distribution of the number of assessments per patient (Fig S1b)
    bin =
      table( d1[ complete.cases(d1$drs_tot) , ]$id ) %>%
      as.data.frame() %>%
      ggplot( aes(x = Freq) ) +
      geom_bar( width = .25 ) +
      geom_text( stat = "count", aes(label = after_stat(count) ), vjust = -0.8, size = 3 ) +
      scale_y_continuous( expand = c(0, 0), limits = c(0, 65), breaks = seq(0,60,10), labels = seq(0,60,10) ) +
      labs( x = "Number of Assessments per Patient", y = "Number of Patients" ) +
      theme( panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank() )
    
  )

# save them
ggsave(
  plot = with( fig2, hist / bin ) +
    plot_annotation( tag_levels = "A" ) &
    theme( plot.tag = element_text(face = "bold") ),
  filename = here("figs","assessments_desc.jpg"),
  dpi = 300,
  width = 7,
  height = 7.8
) 

```

![Distribution of assessments. Distribution of (A) follow-up years and (B) number of assessments per patient for N = 126 patients. Negative values on horizontal axis in (A) represent pre-surgery assessments.](../figs/assessments_desc.jpg){#fig-dist}

```{r}
#| label: fact-anal

# clear environment
rm( list = ls()[ !ls() %in% c("v","itstats","rprint","ubound","mread","nms") ] )

# read EFA-related results
for( i in names( readRDS( here("mods","factanal.rds") ) ) ) assign( i , readRDS( here("mods","factanal.rds") )[[i]] )

# extract M and SD of percentage of variance accounted for across imputations for in-text reporting
vaccount <-
  
  sapply(
    
    c("mean","sd"), # loop through summary stats of interest
    function(i)
      
      ( # extract all total cumulative variability accounted for by 7-factor model & calculate summaries
        do.call(
        i,
        list( sapply( 1:length(efa), function(j) max( efa[[j]][[nf-2]]$Vaccounted[ "Cumulative Var", ] ) ) )
        ) * 100 # make it percentages
      ) %>%
      
      rprint(1) %>%
      paste0(.," %")
      
  )

```

## Pre-surgery cognitive profile

Detailed summaries of the fit statistics of all EFA models are presented in the Supplementary material (see Table S1 and Figure S1). Most importantly, raising the number of factors from six to seven resulted in a clear improvement. Out of the one hundred imputed data sets, the six-factor model showed good fit according to RMSEA in 96 cases and it showed good fit according to the TLI in 76 cases. On the other hand, the seven-factor model showed good fit according to RMSEA in 99 cases and good fit according to TLI in 97 cases. Moreover, the seven-factor model was more consistent across imputations. Finally, while the eight-factor resulted in the best fit statistics, factors identified by this model were often substantially loaded on by only a single cognitive test score (with a factor loading above 0.3) which impedes theoretical interpretation of such factors. Consequently, the seven-factor model was retained for subsequent analyses. On average, the seven factors accounted for a total of `r vaccount['mean']` of variance (SD = `r vaccount['sd']`) and corresponded to seven cognitive functions: 1) executive functions/attention (EF/Att.) was loaded on primarily by PST tasks, TMT tasks, verbal fluency tests and TOL, 2) episodic memory (EM) was loaded on primarily by indexes of RAVLT except for the recall of interference list (RAVLT-B), 3) verbal working memory (VWM) was loaded on primarily by Digit Span tasks, LNS and Similarities, 4) visuospatial memory (VM) was loaded on primarily by indexes of the Family Pictures test, 5) set shifting (SS) was loaded on primarily by TMT tasks and RAVLT-B, 6) anxiety (An.) was loaded on primarily by STAI, and 7) spatial working memory (SWM) was loaded on primarily by Spatial Span tasks (see @tbl-factanal).

```{r}
#| label: tbl-factanal
#| tbl-cap: Summary of factor loadings

# prepare an array for loading matrices of each imputed EFA
loads <-
  
  # create an empty 25 ( 23 tests + 2 variance accounted) x 7 (factors) x 100 (imputations) array
  array(
    data = NA,
    dim = c(25, nf, imp),
    dimnames = list( c( rownames(efa[[1]][[nf-2]]$loadings) , "Proportion Var", "Cumulative Var" ), doms, 1:imp )
  )

# fill-in all loadings from efa objects prepared above
for( i in 1:imp ) {

  loads[ , ,i] <-
    
    # extract loadings
    efa[[i]][[nf-2]]$loadings %>%
    as.data.frame() %>%
    
    # add proportion of variability accounted for
    bind_rows( efa[[i]][[nf-2]]$Vaccounted[ "Proportion Var", ] ) %>%
    bind_rows( apply( t(efa[[i]][[nf-2]]$Vaccounted[ "Proportion Var", ]), 1 , cumsum ) %>% t() %>% as.data.frame() ) %>%
    
    as.matrix() # re-format
  
}

# prepare the table
t3 <-
  
  sapply(
    
    dimnames(loads)[[1]],
    function(i)
      paste0(
        rprint( colMeans( t(loads[i, , ]) ), 2 ), " (",
        rprint( apply( t(loads[i, , ]) , 2, sd ), 2 ), ")"
      )
    
  ) %>%
  
  t() %>%
  as.data.frame() %>%
  `rownames<-`( sapply( rownames(.), function(i) v[ i, ] ) ) %>%
  `colnames<-`( sapply( dimnames(loads)[[2]], function(i) v[ i, ] ) ) %>%
  rownames_to_column("Test") %>%
  
  gt( rowname_col = "Test" ) %>%
  cols_align( align = "center", columns = -1 ) %>%
  tab_source_note(
    source_note = "Values represent mean (SD) across one hundred imputations. Factor loadings used for interpretation (|loading| > 0.30) are printed in bold. TMT-A: Trail Making Test, part A; TMT-B: Trail Making Test, part B; DS-F: Digit Span forward; DS-B: Digit Span backward; LNS: letter-number sequencing; SS-F: Spatial Span forward; SS-B: Spatial Span backward; TOL: Tower of London task; PST-D: Prague Stroop Test, dot color naming; PST-W: Prague Stroop Test, word color naming; PST-C: Prague Stroop Test, interference condition; COWAT: Controlled Oral Word Association Test; CFT: category fluency test; Sim.: Similarities; RAVLT-IR: Rey Auditory Verbal Learning Test, immediate recall; RAVLT-B: Rey Auditory Verbal Learning Test, recall of the interference set; RAVLT-DR: Rey Auditory Verbal Learning Test, delayed recall; RAVLT-Rec50: Rey Auditory Verbal Learning Test, delayed recognition from 50 items (15 correct answers + 35 distractors); RAVLT-Rec15: Rey Auditory Verbal Learning Test, delayed recognition, number of correctly identified from 15 items; FP-IR: Family Pictures, immediate recall; FP- DR: Family Pictures, delayed recall; STAI-X1: State-Trait Anxiety Inventory, the state version; STAI- X2: State-Trait Anxiety Inventory, the trait version; Secs: seconds; Total words: word count in two minutes (one minute per each letter P and K); words/min.: word count in one minute time limit. Proportion Var: Proportion of variance in data accounted for by each factor (column); Cumulative Var: Cumulative variance accounted for by each factor and factors that preceded it (columns to the left); EF/Att.: Executive functions/Attention; EM: Episodic memory; VWM: Verbal working memory; VM: Visuospatial memory; SS: Set shifting; An: Anxiety; SWM: Spatial working memory."
  )

# save & print it
gtsave( data = t3, filename = here("tabs","factanal_loadings.docx") )
t3
```

## Describing post-surgery cognitive decline

```{r}
#| label: long-desc

# clear environment
rm( list = ls()[ !ls() %in% c("v","itstats","rprint","ubound","mread","nms","imp") ] )

# prepare colors to use in graphs (a colorblind-friendly palette)
cbPal <- c( "#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7" )

# read the data
for( i in names(readRDS( here("_data","longitudinal_df.rds" ) ) ) ) assign( i, readRDS( here("_data","longitudinal_df.rds" ) )[[i]] )

# read models
m <- mread( c("m0_linear","m0_spline"), c("Linear","Non-linear") )

# extract the highest Rhat for chains convergence and Pareto-k for influential outliers
rhatmax <- round( sapply( names(m) , function(i) max( rhat(m[[i]]), na.rm = T ) ), 3 ) %>% max() %>% ubound(2)
parkmax <- round( sapply( names(m) , function(i) max( loo(m[[i]])$diagnostics$pareto_k, na.rm = T ) ), 3 ) %>% max() %>% ubound(1)

# compare the models via PSIS-LOO
loocomp <-
  
  # extract ELPD_dif and its SE
  with( m, loo_compare(Linear,`Non-linear`)[2,paste0(c("elpd","se"),"_diff") ] ) %>%
  t() %>%
  as.data.frame() %>%
  
  # flip the sign of elpd_diff such that positive means m0_linear had better predictive performance
  mutate( elpd_diff = ifelse( rownames( with( m, loo_compare(Linear,`Non-linear`) ) )[1] == "Linear" , -elpd_diff, elpd_diff ) ) %>%
  
  # add 95% PPI
  mutate(
    ci_low = rprint( qnorm(.025,elpd_diff,se_diff), 2 ),
    ci_hig = rprint( qnorm(.975,elpd_diff,se_diff), 2 ),
    across( ends_with("diff"), ~ rprint(.x,2) ),
    print = paste0( elpd_diff, ", 95% CI [", ci_low,", ", ci_hig, "]" )
  )

# expected cognitive decline in DRS-2 points/year as approximated by the linear model
b <-
  
  spread_draws( m$Linear, `b_.*`, regex = T ) %>% # extract parameter estimates
  
  # calculate model group-level intercept and slope summaries in the correct scale
  median_hdi(
    b_Intecept = with( scl, (b_Intercept * SD$drs ) + M$drs ),
    b_slope = b_time * scl$SD$drs,
    .width = .95
  ) %>%
  
  # prepare a table of parameters the table
  select( starts_with("b_") ) %>%
  mutate( b_slope = abs(b_slope) ) %>% # slope will be reported in absolute value
  mutate_all( rprint, 2 ) %>%
  matrix(
    nrow = 2, ncol = 3, byrow = T,
    dimnames = list( c("intercept","slope"), c("median","ppi_low","ppi_hig") )
  ) %>%
  
  # finishing touches
  as.data.frame() %>%
  mutate( ppi = paste0("[",ppi_low,", ",ppi_hig,"]") )


# post-minus-pre contrast for one year post for fixed only and fixed + random effects
contr <-
  
  lapply(
    
    c("Group-level parameters","Group- & Patient-level parameters"),
    function(i)
      
      # prepare data
      data.frame( id = "sub000", time_y = c( -0.3, 0.7, seq(1,5,1) ) ) %>%
      mutate( time = time_y + scl$Md$time ) %>%
      
      # extract predictions
      add_epred_draws(
        object = m$Linear,
        newdata = . ,
        allow_new_levels = T,
        if ( i == "Group-level parameters" ) { re_formula = NA },
        seed = 87542
      ) %>%
      
      # post-process
      mutate( pred = scl$M$drs + scl$SD$drs * .epred ) %>%
      mutate( pred = case_when( pred > 144 ~ 144, pred < 0 ~ 0, .default = pred) ) %>%
      ungroup() %>%
      select( id, time_y, .draw, pred ) %>%
      pivot_wider( names_from = time_y, names_prefix = "Y", values_from = pred ) %>%
      mutate( across( all_of( paste0("Y", c( .7, seq(1,5,1) ) ) ), ~ .x - `Y-0.3`, .names = "{col}-minus-Pre" ) ) %>%
      pivot_longer( cols = -c("id",".draw"), names_to = "Contrast" ) %>%
      group_by(Contrast) %>%
      summarise(
        md = median(value),
        eti_low = qi(value,.width=.9)[1],
        eti_hig = qi(value,.width=.9)[2],
        rci_1 = paste0( rprint( 100 * sum( value < -6 ) / length(value), 0 ), "%"),
        rci_2 = paste0( rprint( 100 * sum( value < -7 ) / length(value), 0 ), "%")
      ) %>%
      mutate( `Generated by: ` = i, .before = 1 )
    
  )

# extract predictive contrast of one year post-minus-pre assessments
contr$`Full Model` <-
  
  data.frame( id = "sub000", time_y = c( -0.3, 0.7, seq(1,5,1) ) ) %>%
  mutate( time = time_y + scl$Md$time ) %>%
  add_predicted_draws( object = m$Linear, newdata = . , allow_new_levels = T, re_formula = NA, seed = 87542 ) %>%
  mutate( pred = scl$M$drs + scl$SD$drs * .prediction ) %>%
  mutate( pred = case_when( pred > 144 ~ 144, pred < 0 ~ 0, .default = pred ) ) %>%
  ungroup() %>%
  select( id, time_y, .draw, pred ) %>%
  pivot_wider( names_from = time_y, names_prefix = "Y", values_from = pred ) %>%
  mutate( across( all_of( paste0("Y", c( .7, seq(1,5,1) ) ) ), ~ .x - `Y-0.3`, .names = "{col}-minus-Pre" ) ) %>%
  pivot_longer( cols = -c("id",".draw"), names_to = "Contrast" ) %>%
      group_by(Contrast) %>%
      summarise(
        md = median(value),
        eti_low = qi(value,.width=.9)[1],
        eti_hig = qi(value,.width=.9)[2],
        rci_1 = paste0( rprint( 100 * sum( value < -6 ) / length(value), 0 ), "%"),
        rci_2 = paste0( rprint( 100 * sum( value < -7 ) / length(value), 0 ), "%")
      ) %>%
      mutate( `Generated by: ` = "Full Model", .before = 1 )

# put it together
contr <-
  
  contr %>%
  do.call( rbind.data.frame, . ) %>%
  filter( grepl("-",Contrast) ) %>%
  mutate(
    Contrast =
      case_when(
        Contrast == "Y-0.3" ~ "Intercept",
        grepl( "Y0.7", Contrast ) ~ "Slope",
        .default = Contrast
      )
  )

# table it
t4 <-
  
  contr %>%
  select( -starts_with("rci") ) %>%
  mutate( out = paste0( rprint(md,2), " [", rprint(eti_low,2), ", ", rprint(eti_hig,2), "]" ) ) %>%
  select( `Generated by: `, Contrast, out ) %>%
  pivot_wider( names_from = `Generated by: `, values_from = out ) %>%
  mutate( block = ifelse( grepl("minus",Contrast), "Contrasts", "Yearly decline" ) )

```

Both descriptive longitudinal GLMMs converged within a specified number of iterations ($\hat{R}s \leq `r rhatmax`$). All observations had Pareto-k below `r parkmax` implying that the results are not likely to be biased by influential outliers. The linear and non-linear models showed tight correspondence up to approximately five years post-surgery after which the non-linear model predicted a slightly faster rate of cognitive decline than the linear model (see @fig-traj). The difference in estimated predictive performance between these models did not reach statistical significance ($ELPD_{dif}$ = `r loocomp$print`). Based on the linear model, there was an average post-surgery decline of `r b['slope','median']` DRS-2 points/year (95% PPI `r b['slope','ppi']`) from an average pre-surgery DRS-2 performance of `r b['intercept','median']` out of 144 points (95% PPI `r b['intercept','ppi']`).

```{r}
#| label: fig3

# plot prediction via Linear vs Non-linear desciptive models
f3 <-
  
  # extract posterior predictions
  lapply(
    
    names(m),
    function(i)
      
      # prepare a data frame for filling predictions in
      data.frame( time_y = seq(-2,12,length.out = 50), id = NA ) %>%
      mutate( time = time_y + scl$Md$time ) %>%
    
      # predicting proper
      add_epred_draws( m[[i]], re_formula = NA ) %>%
      mutate( .epred = with( scl, .epred * SD$drs + M$drs ) ) %>%
      median_hdi( .width = .95 ) %>%
      add_column( Model = factor( i, levels = c("Non-linear","Linear"), ordered = T ) )
    
  ) %>%
  
  # make it a single file
  do.call( rbind.data.frame, . ) %>%
  
  # plotting proper
  ggplot() +
  aes(x = time_y, y = .epred, ymin = .lower, ymax = .upper, color = Model, fill = Model) +
  geom_ribbon( alpha = .2 , color = NA ) +
  geom_line( linewidth = 2 , alpha = .75 ) +
  scale_y_continuous(name = "DRS-2", limits = c(119,145), breaks = seq(120,144,4), labels = seq(120,144,4) ) +
  scale_x_continuous(name = "Time from surgery (years)", limits = c(-2,12), breaks = seq(-2,12,2), labels = seq(-2,12,2) ) +
  scale_color_manual( values = c("black",cbPal[8]) ) +
  scale_fill_manual( values = cbPal[c(1,8)] ) +
  theme( legend.position = c(0.15,0.21), legend.key.width = unit(2.2,"cm"), legend.key.height = unit(1.2,"cm") )

# save them
ggsave( plot = f3, filename = here("figs","expected_trajectories.jpg"), dpi = 300, width = 7, height = 4.16 )

```

![Comparison of linear versus non-linear models of the longitudinal cognitive trajectory. The figure shows expected true scores in Mattis Dementia Rating Scale (DRS-2) as estimated by the descriptive linear (pink line) and  non-linear (black line) models with their 95% posterior probability intervals (shades).](../figs/expected_trajectories.jpg){#fig-traj}

**In @tbl-contr we present expected true score differences as well as models prediction for new observations at five yearly post-surgery assessment times compared to pre-surgery assessment derived from group-level parameters only (reflecting the sample version of our** ***RQ1*** **estimand), both group- and patient-level parameters (reflecting the population version of our** ***RQ1*** **estimand), and the full model with both true score and residual noise. Although median expected post-surgery cognitive decline was similar across versions, the ETIs of the population estimates and full model's predictions indicate that a large proportion of observed variability in post-surgery cognitive decline is due to inter-individual heterogeneity and measurement error respectively (see also Figures S3 and S4 in the Supplementary material).**

```{r}
#| label: tbl-contr
#| tbl-cap: "Posterior predictions of cognitive changes after surgery"

# prepare the table
t4 <-
  
  t4 %>%
  gt( groupname_col = "block" ) %>%
  cols_align( -1, align = "center" ) %>%
  cols_label( Contrast ~ "", `Full Model` ~ "Observed scores predictions" ) %>%
    
  tab_spanner( label = "True score predictions", columns = starts_with("Group-"), gather = F ) %>%
    
  tab_footnote(
    locations = cells_column_labels("Group-level parameters"),
    footnote = md("Contrasts for the sample version *RQ1* estimand predicted by $\\mu_i$ ~ $\\alpha$ + $\\delta_{time}$*time~i~*")
  ) %>%
  
  tab_footnote(
    locations = cells_column_labels(`Group- & Patient-level parameters`),
    footnote = md("Contrasts for the population version *RQ1* estimand predicted by $\\mu_i$ ~ $\\alpha$ + $\\delta_{time}$*time~i~* + $\\alpha_{id[i]}$ + $\\delta_{id[i]}$*time~i~*")
  ) %>%
  
  tab_footnote(
    locations = cells_column_labels(`Full Model`),
    footnote = md("Contrasts for model's prediction of the raw score sampled from *t(* $\\vartheta$, $\\mu_i$, $\\sigma$*)*")
  ) %>%
  
  tab_footnote(
    locations = cells_row_groups( groups = "Yearly decline" ),
    footnote = "The rows represents expactation of patients' performance at pre-surgery assessment, i.e., 0.3 years before surgery (Intercept), and expected annual Dementia Rating Scale decline (Slope)."
  ) %>%
  
  opt_footnote_marks(marks = "letters") %>%
  
  tab_source_note(
    source_note = "Yi: assessment i years post-surgery; Values represent posterior prediction median [90% equal tailed interval (ETI)]; We used 90% ETI instead of the 95% highest density posterior predictive intervals (PPIs) used elsewhere in the article because 90% ETI can be interprated such that there is 5% probability of observing value smaller than its lower bound and 5% probability of observing value bigger than its upper bound which may not hold for PPIs; all values were calculated by first generating predcitions from the linear desciptive models using parameters specified above and then censoring values above 144 or below 0 before calculating medians and 90% ETIs."
  )

# save & print it
gtsave( data = t4, filename = here("tabs","expectation_contrasts.docx") )
t4

```

## Predicting post-surgery cognitive decline

```{r}
#| label: long-pred

# clear environment
rm( list = ls()[ !ls() %in% c("d","df","scl","tests","doms","v","itstats","rprint","ubound","mread","nms","imp","cbPal","b","contr","predcon") ] )

m <- mread( c("m1_lasso_doms","m2_lasso_tests"), c("factor scores","test scores") ) # read models
l <- readRDS( here("mods","lasso_psis_loo.rds") ) %>% `names<-`( names(m) ) # read PSIS-LOO results


# MODEL CHECKS ----

# check the highest Rhat for chains convergence
rhatmax <-
  
  sapply( names(m) , function(i) max(m[[i]]$rhats, na.rm = T ) ) %>%
  max() %>%
  ubound(2)

# check the highest Pareto-k for influential outliers
parkmax <-
  
  sapply(
    names(l),
        function(i)
          sapply( 1:imp, function(j) max( l[[i]][[j]]$diagnostics$pareto_k ) )
  ) %>%
  
  apply( ., 2, max ) %>%
  max() %>%
  ubound(1)


# POSTERIORS ----

# extract draws
drws <-
  
  lapply(
    
    setNames( names(m), names(m) ),
    function(i)
      
      m[[i]] %>%
      spread_draws( `b_.*`, regex = T ) %>% # extract all "fixed-effect" parameters
      select( contains("b_") ) %>% # get rid of the info about chains
      
      # re-scale to DRS-2 raw scale
      mutate(
        b_Intercept = ( b_Intercept * scl$SD$drs ) + scl$M$drs,
        across( !b_Intercept, function(x) { x * scl$SD$drs } )
      ) %>%
      
      relocate( b_time, .after = ifelse( i == "factor scores", "b_visp_wm", "b_sc_staix2") )

  )

# extract and summarize posteriors of the "fixed-effects"
post <-
  
  lapply(
    
    setNames( names(drws), names(drws) ),
    function(i)
      
      drws[[i]] %>%
      
      # calculate median posterior, 95% PPI and probability of being negative
      apply( . , 2 , function(x) { c(b = median(x), PPI = hdi(x,.width =.95), pd = sum(x<0)/length(x) ) } ) %>%
      t() %>%
      as.data.frame() %>%
      rownames_to_column( var = "Parameter" )

  )

# pre-format draws
drws <- 
  
  lapply(
    
    names(drws),
    function(i)
      drws[[i]] %>%
      select( contains("time") ) %>%
      pivot_longer( cols = everything() ) %>%
      mutate( mod = case_when( i == "factor scores" ~ "Factor scores model", i == "test scores" ~ "Test scores model") ) %>%
      mutate( mod = factor( mod, levels = paste0( c("Test","Factor"), " scores model" ), ordered = T ) )

    ) %>%
    
    do.call( rbind.data.frame, . ) %>%
    mutate( name = sub( "time:", "", name ) %>% sapply( ., function(x) v[x, ] ) ) # this line takes some time to compute

# prepare the figure
f4 <-
  
  drws %>%
  ggplot() +
  aes( x = value, y = reorder(name, value, decreasing = T), fill = stat(x) ) +
  geom_density_ridges_gradient( scale = 1.5, rel_min_height = 0.001 ) +
  scale_fill_viridis_c( option = "turbo", direction = -1 ) +
  geom_vline( xintercept = 0, linewidth = .75, linetype = "solid", color = "black" ) +
  geom_vline( xintercept = -as.numeric(b["slope","median"]), linewidth = .75, linetype = "dashed", color = "navyblue" ) +
  labs( x = expression(Delta*"DRS-2 (points per year)"), y = NULL ) +
  scale_x_continuous( limits = c(-1.25,.75) ) +
  scale_y_discrete( labels = function(x) parse( text = paste0( "delta[", x, "]" ) ) ) + # add predictor parameter names
  facet_wrap( ~ mod, scales = "free_y" ) +
  theme_minimal( base_size = 11 ) +
  theme( legend.position = "none" )

# save the plots
ggsave(
  plot = f4,
  filename = here("figs","posterior_distributions.jpg"),
  dpi = 300,
  width = 7,
  height = 7.7
)

# extract statistically clear result for in-text reporting
delta_ef <-
  
  with(
    post$`factor scores`,
    c(
      b = rprint( abs(b[Parameter == "b_time:exec_fun"] ) ), # absolute value of the estimate due to semantics
      PPI =
        paste0(
        "[", rprint( PPI1[Parameter == "b_time:exec_fun"] ),
        ", ", rprint( PPI2[Parameter == "b_time:exec_fun"] ), "]"
        )
    )
  )

```

Both predictive longitudinal GLMMs converged within a specified number of iterations ($\hat{R} \le$ `r rhatmax`) with all observations having Pareto-k below `r parkmax`. **Including either pre-surgery cognitive tests or pre-surgery cognitive factors as predictors notably decreased patient-level inter-individual heterogeneity compared to the time only model even though all three models generated similar predictions for majority of included patients (see Figures S2 and S4 in the Supplementary material)**

Patients with lower verbal working memory or set shifting showed relatively impaired pre-surgery **DRS-2** performance while there was no cognitive test that clearly indicated pre-surgery **DRS-2** impairment performance (see Tables S2 and S3 in **the** Supplementary material). Patients with lower pre-surgery executive functions/attention performance showed faster post-surgery cognitive decline (see @fig-postdist). Pre-surgery executive functions/attention performance that was one standard deviation below sample average was associated with additional `r delta_ef[['b']]` DRS-2 points post-surgery annual decline (95% PPI `r delta_ef[['PPI']]`). There was no single cognitive test that clearly indicated faster-than-average post-surgery cognitive decline (all 95% PPIs included zero**, see Table S2**). Adding group-level effects of age, LEDD and BDI-II did not reveal any substantial deviation from these results (see Figures S**5** and S**6** in **the** Supplementary material).

![Interaction terms of the “test scores” (left column) and the “factor scores” (right column) models predicting post-surgery cognitive decline. Each density represents full posterior estimate of additive predictive value of the cognitive variable (test or factor) listed on the ordinate. All cognitive predictors were scaled such that negative values mean negative effect of pre-surgery deficit on prediction of longitudinal cognitive trajectory. Vertical lines represent zero (no effect, solid black line) and average post-surgery decline in our sample accroding to the descriptive linear model predictive before (blue dashed line). Acronyms are explained in the text.](../figs/posterior_distributions.jpg){#fig-postdist}

## Electrode localization exploration

```{r}
#| label: elloc

rm( list = ls()[ !ls() %in% c("itstats","rprint","contr","predcon") ] ) # clear environment

# read the data
for( i in names(readRDS( here("_data","vatplus_df.rds" ) ) ) ) assign( i, readRDS( here("_data","vatplus_df.rds" ) )[[i]] )

# extract inclusion/exclusion stats
incl <-
  
  d0 %>%
  filter( post == 0 ) %>%
  select(elloc_miss) %>%
  table( useNA = "always" )

```

**Total of `r incl[length(names(incl))]` patients was included into analysis (see the Supplementary material Figure S7 for electrode localization visualization, and Tables S4 and S5 for description of this subsample). Patients included in this analysis were marginally younger with less pre-surgery anxiety, less depressive symptoms and better performance in some measures of attention and executive functions (Tower of London task, Category Fluency Test and Trail Making Test part A) compared to patients excluded from this analysis (see Figure S8 in the Supplementary material).**

**Overall, there was no statistically clear evidence that proportions of STN components affected by DBS are associated with the degree of post-surgery cognitive decline in our sample (see Figure S9 and Table S6 in the Supplementary material). However, some patterns can be observed in our results. Although associations of post-surgery cognitive decline with proportion of affected motor and limbic STN components were all centred around zero, there was clearly more uncertainty in estimates regarding limbic STN compared to motor STN. Moreover, there was specifically higher (negative) posterior collinearity of limbic STN components time-dependent parameters with other time-dependent parameters (see Figure S10 in the Supplementary material). Finally, our results show weak trend towards potential association between proportion of affected right associative STN and post-surgery cognitive decline. According to our model and data, there was almost 80% probability that higher proportion of affected right associative STN is associated with a faster decline in post-surgery cognitive performance.**

## Evaluating false positive error rates

```{r}
#| label: sims

# summarise false positives conditional on null hypothesis
falsepos <-
  
  read.csv( here("mods","sims_fp.csv"), sep = "," ) %>% # extract numbers of simulations with at least one false positive
  filter( meth == "t0" & fp != 0 ) %>%
  pivot_wider( names_from = "fp", values_from = "Freq") %>%
  select( where( is.numeric ) ) %>%
  rowSums()

```

Results of simulations used to estimate false positive rates of the **univariable screening** procedure and the Bayesian Lasso are summarised in **the** Supplementary material Figure S**12**. Overall, the Bayesian Lasso showed almost no false positives across simulation settings whereas the false positive rates of the **univariable screening** procedure ranged from `r min(falsepos)` to `r max(falsepos)` of analyses including at least one false positive. In the case of our data structure, the false positive rates were attenuated when all twenty-three predictors covaried or when we reduced the number of predictors to seven independent variables.

# Discussion

In the present study, we analyzed retrospectively sampled data of longitudinally followed `r itstats[['n']][['incl']]` PD patients after STN DBS surgery and described their post-surgery cognitive performance. We observed a mild **average** post-surgery cognitive decline **with considerable inter-individual variability** (*RQ1*) **. The post-surgery decline** was faster in patients with lower pre-surgery executive functions/attention (*RQ2*) compared to the rest of the sample. **Our exploratory analysis of association between affected proportion of STN components and post-surgery cognitive decline did not yield any clear results, however some patterns of our data can be used to guide further research.**

## Description of post-surgery cognitive decline

```{r}
#| label: rci-comp

rci <-
  
  contr %>%
  select( `Generated by: `, Contrast, starts_with("rci") ) %>%
  filter( Contrast %in% c("Y1-minus-Pre","Y2-minus-Pre") ) %>%
  pivot_wider( values_from = starts_with("rci"), names_from = "Contrast" ) %>%
  select( `Generated by: `, `rci_1_Y1-minus-Pre`, `rci_2_Y2-minus-Pre` )

```

**E**xpected average annual rate of cognitive decline after STN DBS in **our sample of** PD **patients** reache**d** 0.90 from a total of 144 points **in DRS-2. Whereas the sample estimate was tightly clustered around this circa one point a year post-surgery decline, generalization to a population of patients selected via the CAPSIT protocol criteria resulted in estimates of annual post-surgery change ranging from 2.5 points decline to 0.5 points improvement with 90% certainty (@tbl-contr). For European Americans, @pedraza2007 reported values of 6 and 7 DRS-2 points decline as reliable change cutoffs based on 90% predictive intervals for approximately one- and two-years re-tests respectively. As both our sample and population true score change estimates fall above these cut-offs with high level of certainty, we may conclude that STN DBS seems to be relatively safe from cognitive point of view at least up to two years post-surgery.^[Based on the descriptive linear model's predictions summarized in @tbl-contr, posterior probability of seeing a patient with DRS-2 score change lower than these reliable change cut-offs was respectively `r rci[1,2]`, `r rci[2,2]` and `r rci[3,2]` for the sample true score, population true score and observed score predictions one year after surgery, and `r rci[1,3]`, `r rci[2,3]` and `r rci[3,3]` for the sample true score, population true score and observed score predictions two years after surgery.]**

```{r}
#| label: other-comp

# # Reich et al. (2022) data (from Fig 4B)
reichd <- -c( rep(-3,2), -2, rep(-1,2), rep(0,6), rep(1,4), rep(2,7), rep(3,3), rep(4,2), 6, 8, 11, 13, 14 )

# prepare an array with previous studies data for CI calculations
prev <-
  
  # extract data from Smeding et al. (2009) and Gruber et al. (2019)
  # Smeding et al. (2009): Table 2 (mean change score and its SD) and N from "Results: Group characteristics"
  # Gruber et al. (2019): p. 313, the third paragraph (mean change score and its SD), N from Fig. 2b,c
  data.frame(
    diff = c( -2.4, -1.6, mean(reichd) ),
    sd = c( 7.5, 3.8, sd(reichd) ),
    n = c( 105, 32, length(reichd) )
  ) %>%
  `rownames<-`( c("smeding2009","gruber2019","reich2022") ) %>%
  
  # compute 90% CIs for their difference scores
  mutate(
    abs_diff = rprint( abs(diff), 1 ),
    sem = sd / sqrt(n),
    lb = qt( .05, df = n-1 ), ub = qt( .95, df = n-1 ),
    CI = paste0( "[", rprint( diff + sem * lb ), ", ", rprint( diff + sem * ub ), "]" )
  )

```

**The estimate of an average annual cognitive change from our study** represents **somewhat** slower rate **of decline** than previous reports. **For example, @gruber2019 reported `r prev['gruber2019','abs_diff']` DRS-2 points/year decline (90% CI `r prev['gruber2019','CI']`) based on change scores of `r prev['gruber2019','n']` patients assessed pre-surgery and at various time points post-surgery (compare to the "Slope" row of @tbl-contr). Additionaly, @smeding2009 and @reich2022 calculated one year post-surgery change scores of `r prev['smeding2009','n']` and `r prev['reich2022','n']` patients and reported declines of `r prev['smeding2009','abs_diff']` (90% CI `r prev['smeding2009','CI']`) and `r prev['reich2022','abs_diff']` (90% CI `r prev['reich2022','CI']` DRS-2 points respectively (compare to the "Y1-minus-Pre" row of @tbl-contr). Other studies [@schupbach2005; @boel2016; @castrioto2022] appear to observe post-surgery decline similar to or larger than our estimate, however, since they report neither cognitive decline parameter estimates, nor raw change scores, the (dis)similarity between their and our observations could not have been ascertained numerically.**

## Using our model for interpretation of other results

```{r}
#| label: reich-comp

# proportion of Reich et al.'s (2022) patients who had change score lower than minimum true score/predicted score expectation at 90% ETI from the descriptive linear model
bottom5percent <-
  
  sapply(
    
    c("Group- & Patient-level parameters","Full Model"),
    function(i)
      
      paste0(
        sum( reichd < with( contr, eti_low[ `Generated by: ` == i & grepl("Y1",Contrast) ] ) ), "/", length(reichd), " (",
    rprint( 100 * sum( reichd < with( contr, eti_low[ `Generated by: ` == i & grepl("Y1",Contrast) ] ) ) / ( length(reichd) ), 0 ), "%)"
    
)
    
  )

# population-level lower bound data are being compared to
lbound <- rprint( -contr[ with( contr, grepl("&",`Generated by: `) & grepl("Y1",Contrast) ), "eti_low"], 1 )

```

**Next we demonstrate how our linear descriptive model can be used to inform decisions in future studies by comparing its predictions directly to data reported in @reich2022. We have selected this article because it represents a prototypical pre-surgery/post-surgery study design for assessing cognition in PD patients treated by STN-DBS, it uses DRS-2 as its outcome, and the raw data (change scores) analyzed for purposes of the article can be readily identified from Figure 4B therein.**

**To decide whether data such as those evaluated by @reich2022 constitute true score changes (as is assumed by change scores analysis) or whether there is appreciable measurement error, we can compare the data distribution with the population true score estimate of our model (@tbl-contr, second column). The model implies that not more than 5% of the sample should fall below `r lbound` DRS-2 points decline at year one post-surgery assessment if all we observed were true score changes. Inspected data set contains `r bottom5percent["Group- & Patient-level parameters"]` patients who fall below this thresholds. On the other hand, only `r bottom5percent["Full Model"]` patients fall below our model's bottom 5% expectation based on prediction of true score with added measurement error (@tbl-contr, third column).^[As the data set we are inspecting contains only `r prev['reich2022','n']` patients, small percentage predictions might easily be misaligned between model predictions and observed sample. However, the general observation that the sample contains significant amount of outliers with respect to true score change model predictions but not for raw score model predictions holds in our case even for larger intervals such as 80% ETIs (i.e., inspecting bottom 10% instead of 5%) and the conclusion of this section thus seem valid.]**

**Comparison of inspected data set with our model's predictions thus leaves researchers with two main takeaways: (i) the data could have come from a distribution well approximated by the model because its raw score predictions align well with the data, and (ii) high amount of change score variance can be attributed to measurement error because we observed significantly larger proportion of extreme values than predicted by the model with measurement error removed. Such an analysis will provide researchers with useful information they can act upon by increasing sample size to offset lost efficiency due to measurement error or adopt analysis procedure that accounts for measurement error explicitly [see e.g., @gelman2021]. Alternatively, researchers can hypothesize that the discrepancy between model and observed data is not due to measurement error but rather reflects differences between populations. This line of reasoning could motivate researchers to account for population differences via procedures such as post-stratification to improve their estimates [@deffner2022]. Finally, researchers can surmise that our model is inappropriate for describing their data set. If this was the conclusion researchers made, they can easily use our model to generate predictions for their sample using model's full posteriors we share in a plain text format on article's repository ([https://github.com/josefmana/dbs_cogPRED](https://github.com/josefmana/dbs_cogPRED)) and attempt to falsify it.**

## Predictive pre-surgery cognitive profile

**When predicting post-surgery cognitive decline via pre-surgery cognitive profile, we aimed to identify a sparse solution including only these pre-surgery cognitive variables that are the most likely to be truly predictive. To achieve this goal, we applied the Bayesian Lasso and factor analysis to decrease false positive error rates of our analysis and validated effectiveness of these procedures via a set of simulations.**

In **our sample**, lower performance on the latent factor of executive functions/attention (EF/Att.) was reliably predictive of post-surgery cognitive decline. Similarly, previous studies suggested that patients with executive deficit (operationalized as performance on tasks such as Stroop test, TMT, Wisconsin Card Sorting Test and verbal fluency test) are at a high risk of developing dementia and experiencing fast cognitive decline after STN DBS surgery [@bove2020; @kishore2019; @smeding2009]. **On the other hand, recent meta-analysis [@jahanshahi2022] identified both pre-surgery executive dysfunction as well as poorer pre-surgery memory to be predictive of post-surgery cognitive decline, the latter of which was not replicated in our study.**

**Although there is a large body of evidence showing that pre-surgery executive deficit is predictive of post-surgery cognitive decline, it is unclear which executive functions components provide the most information. In our study, the EF/Att. factor was loaded on primarily by timed test scores and could be specific for processing speed component of executive functions. Conversely, the set shifting factor which represent another executive functions' component did not clearly predict post-surgery cognitive decline above and beyond the remaining pre-surgery cognitive variables in our data set. However, the set shifting factor component of our** ***RQ2*** **estimand showed less consistency across imputation in its derivation (see high standard deviations in @tbl-factanal) and high variability in its predictive value (see @fig-postdist). We thus cannot give any firm conclusion regarding set shifting's role for post-surgery cognitive decline prediction. Future studies could benefit from further differentiating executive functions to identify the best predictive executive components.**

## The role of STN sites affected by DBS

**Our exploratory analysis of post-surgery cognitive decline prediction by proportions of STN components being affected by DBS yielded equivocal results. As our data sampling design was not optimized for evaluation of direct stimulation outcomes' effect on post-surgery cognitive decline, this estimation inefficiency likely reflects several sources of noise that could be better controlled for in future studies. On top of the outcome measurement error discussed above, these noise sources include alignment between time of cognitive assessment and electrode localization, and reliability of localization itself. In our study, only a single electrode localization was derived for each patient and the time gap between MRI acquisition and cognitive assessment differed between patients and assessment times. Our results would thus be most accurate under the unrealistic assumption that proportion of STN being affected by DBS is time-invariant across patients. This assumption can be relaxed by gathering repeated MRI data for electrode localization at times corresponding to patients' cognitive evaluations data. Furthermore, although electrode localization via Lead-DBS has been shown to be relatively reliable and comparable across raters and modalities [@lofredi2022; @xu2023], using data from several raters and employing post-surgery computational tomography instead of MRI may increase precision of electrode localization estimates.**

## Constraints on Generality

**Several constraints of generality still apply to our findings.** Due to a lack of a control group, we cannot discern the causal effect of DBS from the effect of disease progression. Consequently, we limit our conclusions to STN DBS treated patients that were selected for treatment using similar exclusion criteria as those applied in this study (**i.e., the CAPSIT protocol criteria or their equivalent**, see exclusion criteria above). The lack of control group also limits application of our findings for selection purposes. Since our sample comprised of patients already selected for STN DBS treatment, the estimates could exhibit distortion due to the collider bias if generalized to a larger population of PD patients [@cinelli2022]. We thus advise against using our findings as a basis for patient selection for STN DBS. Instead, practitioners should base their decision for STN DBS treatment on the current best practices [@armstrong2020; @defer1999] and use our findings to single out patients who could benefit from more monitoring.

Another generality constraint stems from the selection of measures used in the current study. Most importantly, there was a lack of visuo-spatial tasks in pre-surgery examination. Moreover, the cognitive outcome was evaluated by DRS-2 which although suitable for cognitive screening of global cognition does not appear to have utility in evaluating single cognitive functions in PD [@lopez2021]. **Exploiting model predictions for research decisions as described in the** ***Using our model for interpretation of other results*** **section is constrained to outcomes in terms of DRS-2 scores as well. Even though in principle it is possible to convert DRS-2 scores predicted by our models to other cognitive screening tests' scales via regression equations derived from population-specific normative studies, this conversion comes with additional estimation error.**

Finally, the results of the EFA analysis can be disputed from several points of view. **As discussed above, t**he EF/Att. factor was loaded on by timed test scores and could thus be better characterized as processing speed instead. We decided to follow the naming convention established in the methods section of our article, however, the lack of time-independent executive tests constitutes a clear limitation of our data set. Moreover, several latent factors identified by the EFA were test-specific (e.g., the visuospatial memory was specific to the Family Pictures test). This issue was most pronounced in the case of verbal working memory factor which was loaded on not only by the prototypical measures of working memory capacity but also by Similarities test of WAIS-III. Some of the identified latent factors can thus represent test-specific commonalities instead of latent cognitive functions. Incidentally, these shortcomings seem to affect the EF/Att. factor the least. Notably, all three of these limitations were also observed in other recent studies that applied latent variable approach to clinically used comprehensive neuropsychological batteries in PD [@chung2021; @specketer2019]. The phenomena observed in EFA results of our study may thus at least partially stem from the contemporary practice of building neuropsychological batteries according to expert consensus and warrant further investigation of a latent structure of such batteries.

## Limitations and future directions

A major limitation of our study is the moderate number of missing values. To alleviate this limitation, we applied a multiple imputation technique with high number of imputations which has been shown to provide reasonable interval estimates in the Bayesian models. However, missing data still lowered estimation precision of effects of those latent cognitive factors that were identified less consistently across imputed datasets (set shifting and spatial working memory). Another way missing data might have influenced our findings is the survivorship bias which could have led to overly optimistic estimates of the post-surgery cognitive decline rate.

Next, our results are limited to evaluating pre-surgery cognitive profile predictive of post-surgery cognitive decline. While we adopted this approach for parsimony’s sake, other non-cognitive features such as demographic or clinical characteristics will likely significantly improve prediction. **Moreover, the descriptive nature of our study could be enhanced by applying effect transfer methodologies such as post-stratification to arrive at more precise prediction for other populations [@deffner2022]**

Despite these limitations, our results provide actionable information about the PD patients who are selected for STN DBS treatment based on current best practices. Based on our results, clinicians can preferentially monitor patients with a pre-surgery executive functions/attention deficit. Moreover, the cognitive profile identified in our study can serve to select within STN DBS treated patients suitable candidates for prospective clinical trials investigating effects of strategies to mitigate cognitive decline such as cognitive training, reprogramming of stimulation parameters or further DBS using a secondary target [@cappon2022]. **Finally, as demonstrated above, our results can be used as a framing device for future studies investigating cognitive change in PD patients after STN DBS helping to sort out true cognitive change and measurement error.**

## Conclusions

Our findings imply that STN DBS in combination with oral dopaminergic therapy is a **relatively** safe treatment option from a cognitive standpoint as it was associated with only mild annual post-surgery cognitive decline **with low probability of exceeding published reliable change cut-offs**. Pre-surgery executive functions/attention deficit appears to have a prognostic value for risk stratification with regards to development of the post-surgery cognitive decline. Based on our models and data, we recommend considering aggregated pre-surgery results from multiple executive tests to estimate cognitive prognosis of PD patients treated with STN DBS.

# Acknowledgements

This work was supported by the Czech Ministry of Health under Grant AZV NV19-04-00233; Grant Agency of Charles University under Grant GA UK 254121; EU Joint Programme on Neurodegenerative Disease Research under Grant JPND 733051123; and by The project National Institute for Neurological Research (Programme EXCELES, ID Project No. LX22NPO5107). We further wish to thank all the patients, family members and staff from all the units that participated in the study. In particular, we wish to thank Markéta Fialová, Radka Steinbachová and Anna Rezková for their management of data collection and patient care**,** Petra Balabánová for her assistance with neuropsychological assessments**, and Martina Kvapilová for reading and commenting on later versions of this article**.

# Conflict of interest

Nothing to report.

# Ethical statement

The study was approved by the General University Hospital Ethics Committee in Prague, Czech Republic. All Participants provided informed consent.

# Data availability

**The data that support the findings of this study are not currently publicly available due institutional regulations protecting patient clinical data but are available from the corresponding author on request (may require data use agreements to be developed).** The data that support the findings of this study are available on request from the corresponding author. The data are not publicly available due to privacy or ethical restrictions. The computer code used in our analysis as well as supplementary presentation of our results can be accessed at **[https://github.com/josefmana/dbs_cogPRED](https://github.com/josefmana/dbs_cogPRED)**.

# References
