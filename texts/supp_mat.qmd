---
title: 'Supplementary material for "Preoperative Cognitive Profile Predictive of Cognitive Decline after Subthalamic Deep Brain Stimulation in Parkinson’s Disease"'
shorttitle: "Cognition in PD after STN DBS"
author:
  - name: Josef Mana
    corresponding: true
    email: "josef.mana@protonmail.com"
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Ondrej Bezdicek
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  
  - name: Filip Ruzicka
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Andrej Lasica
    corresponding: false
    email: "Andrej.Lasica@vfn.cz"
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Anna Smidova
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Olga Klempirova
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Tomas Nikolai
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Tereza Uhrova
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Evzen Ruzicka
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
  - name: Dusan Urgosik
    affiliations:
      - id: "NHH"
        name: "Na Homolce Hospital, Prague, Czech Republic"
        department: "Department of stereotactic and radiation neurosurgery"
  - name: Robert Jech
    affiliations:
      - id: "1FM"
        name: "First Faculty of Medicine and General University Hospital in Prague, Charles University, Czech Republic"
        department: "Department of Neurology and Centre of Clinical Neuroscience"
format:
 apaquarto-pdf:
   documentmode: man
   a4paper: true
   docx-engine: lualatex
   floatsintext: false
   keep-tex: false
bibliography: references.bib
warning: false
echo: false
---

{{< include _extensions/wjschne/apaquarto/_apa_title.qmd >}}

```{r}
#| label: import

library(here) # reading & saving files
library(tidyverse) # data wrangling
library(gt) # tables formatting
library(ggridges) # density plots
library(ggcorrplot) # multicollinearity plots
library(patchwork) # organising plots
library(brms) # read stan results
library(tidybayes) # posterior manipulations
library(reshape2) # melting correlation matrix
library(english) # number to text conversion
#library(rsvg) # reading electrodes picture

rm( list = ls() ) # clear environment
theme_set( theme_minimal(base_size = 12) ) # set ggplot theme

# prepare colors to use in graphs (a colorblind-friendly palette)
cbPal <- c( "#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7" )


# IN-HOUSE FUNCTIONS ----

# printing rounded number
rprint <- function( x, dec=2 ) sprintf( paste0("%.",dec,"f"), round( x , dec) )

# upper bound
ubound <- function( x, dec=2 ) ifelse( round(x,dec) > x, rprint(x,dec), rprint( x+1/(10^dec), dec ) )

# print percentages of columns in a data.frame
percprint <-
  
  function( input, thres, more, less, denom ) {
    
    input %>%
    as.data.frame() %>%
    mutate( across( everything() , ~ case_when( .x > thres ~ more, .x < thres ~ less ) ) ) %>%
    colSums() * 100 / denom
    
  }

```


In this supplementary material we present additional information to the article *“Preoperative Cognitive Profile Predictive of Cognitive Decline after Subthalamic Deep Brain Stimulation in Parkinson’s Disease”* including further presentation of results that was not included in the main text due to space constraints. All procedures described in this supplementary material are accompanied by R code used to implement the steps described herein and Stan code for Bayesian generalized linear mixed models (GLMMs) fitted during this project. The R code and Stan models as well as raw files containing all images and tables are available at **[https://github.com/josefmana/dbs_cogPRED](https://github.com/josefmana/dbs_cogPRED)**. Since the data used for model fitting in our study contain medical records of included patients, they are not publicly available for privacy reasons. Moreover, because GLMMs reported in this article are exceedingly large for purposes of online storage (> 2 GB each), only the R and Stan codes are included.

# Pre-surgery cross-sectional exploratory factor analysis

## Data pre-processing

For exploratory factor analyses (EFAs) we first log transformed all response time-based tasks (i.e., Trail Making Test and Stroop test), then standardized (i.e., mean-centered and scaled by their in-sample standard deviation) all variables before applying multiple imputations for missing values. EFA was then fitted on each imputed data set via ordinary least squares to find the minimal residual solution. This procedure was repeated for three up to eight factor solutions.

## Supplementary presentation of results

```{r}
#| label: fact-anal

# read EFA-related results
for( i in names( readRDS( here("mods","factanal.rds") ) ) ) assign( i , readRDS( here("mods","factanal.rds") )[[i]] )

# prepare a table for performance indexes of each solution for each imputed data set
fat <-
  
  # create an empty 6 (factor solutions) x 5 (performance indexes) x 100 (imputations) array
  array(
    
    data = NA, dim = c( length( efa[[1]] ), 5, imp ),
    
    # add dimension names
    dimnames =
      list(
        paste0( 1:length(efa[[1]])+2, "-factor" ), # number of factors
        c("TLI", "RMSEA", "RMSEA_90_CI_low", "RMSEA_90_CI_upp", "var_account"), # performance indexes
        1:imp # number of imputed data set
      )

  )

# loop through the array and gather all performance indexes
for ( i in 1:imp ) {
  for ( j in 1:length(efa[[i]]) ) {
    
    fat[ j , , i ] <-
      
      c(
        efa[[i]][[j]]$TLI, # Tucker-Lewis Index, TLI > 0.9 is considered good
        efa[[i]][[j]]$RMSEA[1], # Root-Mean Square Error of Approximation, RMSEA < 0.08 is considered good
        efa[[i]][[j]]$RMSEA[2], # 90% CI RMSEA, lower boundary
        efa[[i]][[j]]$RMSEA[3], # 90% CI RMSEA, upper boundary (ideally should be less than 0.08)
        max( efa[[i]][[j]]$Vaccounted["Cumulative Var",] ) # total variance "accounted for" by all included factors (i.e., the highest one from "Cumulative Var")
      )

  }
}

```

Supplementary EFA results are presented in @tbl-perf and @fig-perf (see below). @tbl-perf presents numerical summary of fit indexes of each three to eight factor solutions across one hundred imputations. Note that Tucker-Lewis Index (TLI) was above the threshold implying good fit (TLI > 0.9) in only three **fourths of** six-factor models, but it was above this threshold in all but three out of one hundred seven-factor models. Similar information is visually presented in @fig-perf which depicts density plots of TLI and upper 90% confidence interval bound of root-mean-square-error approximation (RMSEA) of all models across imputations. This clear improvement in fit of seven- compared to six-factor model, only modest improvement of eight- compared to seven-factor model, and overall theoretical plausibility of factors identified by the seven-factor model led us to retain seven factors for further analyses.

```{r}
#| label: tbl-perf
#| tbl-cap: Summary of fit indexes of the exploratory factor analysis across one hundred imputed datasets

# prepare a table with performance indexes
t1 <-
  
  data.frame( Model = paste0( 3:8, "-factor"), TLI = NA, RMSEA = NA, RMSEA_90_CI_upp = NA, var_account = NA ) %>%
  
  # add indexes
  mutate(
    
    # present mean (SD) for each index
    across(
      !contains("Model"),
      ~ sapply(
        Model, # loop through model names
        function(i)
          paste0( rprint( mean(fat[ i, cur_column(), ]) )," (",rprint( sd(fat[ i, cur_column(), ]) ),")" )
      )
    ),
    
    # extract percentages of 'good' RMSEA and TLI
    `upper bound RMSEA < 0.08 (%)` = percprint( t( fat[ , "RMSEA_90_CI_upp" , ] ), .08, 0, 1, imp ),
    `TLI > 0.90 (%)` = percprint( t( fat[ , "TLI" , ] ), .9, 1, 0, imp )
    
  ) %>%
  
  
  gt() %>%
  cols_align( align = "center", columns = -1 ) %>%
  cols_label(
    "RMSEA_90_CI_upp" = "RMSEA 90% CI (upper bound)",
    "var_account" = "Total variance accounted for"
  ) %>%
  
  tab_source_note( source_note = "Values represent mean (SD) or percentages if indicated in brackets." ) %>%
  tab_source_note( source_note = "TLI Tucker-Lewis Index. RMSEA root-mean-square-error approximation. CI confidence interval" ) %>%
  tab_options( quarto.disable_processing = T )

# save & print it
gtsave( data = t1, filename = here("tabs","factanal_performance.docx") )
t1

```

```{r}
#| label: fig1

# prepare plots of model performance indexes
f1 <-
  
  lapply(
    
    setNames( c("TLI","RMSEA_90_CI_upp"), c("TLI","RMSEA_90_CI_upp") ),
    function(i)
      
      fat[ , i , ] %>%
      
      # re-format the table for plotting
      t() %>%
      as.data.frame() %>%
      pivot_longer( everything(), names_to = "Model" , values_to = i ) %>%
      rename( "index" = i ) %>%
      
      # plotting proper
      ggplot( aes( x = index , fill = Model) ) +
      geom_density( alpha = .4 , color = NA ) +
      scale_fill_manual( values = cbPal[3:8] ) + # use colorblind-friendly palette
      geom_vline( linetype = "dashed", size = 1.2, xintercept = case_when( i == "TLI" ~ .9, i == "RMSEA_90_CI_upp" ~ .08 ) ) + # add a vertical line depicting good performance heuristics
    labs( y = "Density", x = case_when( i == "TLI" ~ "TLI", i == "RMSEA_90_CI_upp" ~ "RMSEA (upper 90% CI)" ) ) +
    scale_x_continuous(
      limits = case_when( i == "TLI" ~ c(0.6,1.05), i == "RMSEA_90_CI_upp" ~ c(0.03, 0.12) ),
      breaks = case_when( i == "TLI" ~ seq(.6,1,.1), i == "RMSEA_90_CI_upp" ~ seq(.04,.12,.02) ),
      labels = case_when(
        i == "TLI" ~ sprintf( "%.1f", round( seq(.6, 1, .1), 1) ),
        i == "RMSEA_90_CI_upp" ~ sprintf( "%.2f", round( seq(.04,.12,.02), 2) )
      )
    )

  )

# align and save the plots
ggsave(
  plot =
    ( f1$TLI / f1$RMSEA_90_CI_upp ) +
    plot_layout( guides = "collect" ) +
    plot_annotation( tag_levels = "A" ) &
    theme( plot.tag = element_text(face = "bold") ),
  filename = here("figs","factanal_performance.jpg"),
  dpi = 300,
  width = 9.9,
  height = 5.88
)

```

![Factor analyses fit indexes. Density plots of (A) Tucker-Lewis Index (TLI) and (B) upper bound of 90% confidence interval (CI) of the root-mean-square-error approximation for three- to eight-factor solutions of factor analysis of pre-surgery cognitive profile. Density plots are taken over one hundred imputed datasets. Vertical lines represent boundaries of good fit according to TLI (i.e., TLI > 0.9) and RMSEA (i.e., RMSEA < 0.08).](../figs/factanal_performance.jpg){#fig-perf}

# Longitudinal generalized linear mixed models

## Data pre-processing

```{r}
#| label: md-time

# extract median time before surgery of included patients
mdt <-
  
  read.csv( here("_data","20220508_dbs_longCOG_data.csv") , sep = "," ) %>%
  filter( included == 1 & ass_type == "pre" ) %>%
  select(time_y) %>%
  abs() %>%
  unlist() %>%
  median() %>%
  rprint(2)

```

To simplify the process of choosing appropriate prior distributions and minimize multicollinearity, all variables were standardized (i.e., mean-centered and scaled by their in-sample standard deviation) before the analyses. The only variable that was not pre-processed this way was time after surgery. This variable was entered into all models **o**n its raw scale (i.e., years after surgery) shifted forward by a median time of pre-surgery assessment (i.e., `r mdt` years). Consequently, model intercepts represent estimates of patients’ cognitive performance in Mattis Dementia Rating Scale (DRS-2) at pre-surgery assessment (`r mdt` years before surgery) and time slopes represent DRS-2 annual post-surgery cognitive decline. Before they were entered into the models, all pre-surgery cognitive factors and test scores were coded such that higher values indicated poorer performance. Parameters associated with these variables (see @fig-robtest, @fig-robfact, @tbl-posttest, @tbl-postfact as well as Figure 4 in the main text) thus represent an effect of a (relative) pre-surgery deficit in **the** corresponding latent cognitive factor or manifest cognitive test score on prediction of pre-surgery DRS-2 (the $\beta$ parameters) and post-surgery annual decline in DRS-2 (the $\delta$ parameters). Negative parameter values imply that pre-surgery cognitive deficit unfavorably affects the outcome and vice versa for positive parameter values.

```{r}
#| label: posteriors
#| cache: true

rm( list = ls()[ !ls() %in% c("rprint","ubound","imp","cbPal") ] ) # clear environment
v <- read.csv( here("_data","var_nms.csv") , sep = ";" , row.names = 1 , encoding = "UTF-8") # read variable mappings

# read the data
for( i in names(readRDS( here("_data","longitudinal_df.rds" ) ) ) ) assign( i, readRDS( here("_data","longitudinal_df.rds" ) )[[i]] )


# POSTERIOR DRAWS ----

## variance of patient-level parameters (i.e., the 'random effects') ----
# extracting for linear time only model and the main in-text predictive models
reff <-

  lapply(
    
    c("m0_linear","m0_lasso","m1_lasso_doms","m2_lasso_tests"),
    function(i)
      readRDS( here( "mods", paste0(i,".rds") ) ) %>%
      as_draws_df() %>%
      select( starts_with("sd_id"), cor_id__Intercept__time ) %>%
      mutate( across( all_of( starts_with("sd_") ), ~ . * scl$SD$drs ) ) %>%
      pivot_longer( everything(), names_to = "Parameter", values_to = "Posterior" ) %>%
      mutate( model = i )
    
  ) %>%
  
  do.call( rbind.data.frame, . ) %>% # pull the posteriors to a single file

  # format it
  mutate(
        
        Parameter =
            case_when(
                grepl("cor",Parameter) ~ "corr",
                Parameter == "sd_id__time" ~ "slope",
                Parameter == "sd_id__Intercept" ~ "intercept"
            ) %>% factor(
                levels = c("intercept","slope","corr"),
                ordered = T
            ),
        
        `Model: ` =
            case_when(
                grepl("m0_linear",model) ~ "time only (default)",
                grepl("m0_lasso",model) ~ "time only (Lasso)",
                grepl("m1",model) ~ "factor scores",
                grepl("m2",model) ~ "test scores"
            ) %>% factor(
                levels = c("time only (default)","time only (Lasso)","test scores","factor scores"),
                ordered = T
            )
        
    )


## post-minus-pre contrast of linear descriptive model ----
# prepare data
d_seq <-
  
  data.frame( id = "sub000", time_y = c( -.3, seq(.5,5,1/12) ) ) %>%
  mutate( time = time_y + scl$Md$time )

# contrast for the true score
contr <-
  
  lapply(
    
    c("fixed","random"),
    function(i)
      
      # extract predictions
      d_seq %>%
      add_epred_draws(
        object = readRDS( here("mods","m0_linear.rds") ),
        newdata = . ,
        allow_new_levels = T,
        if ( i == "fixed" ) { re_formula = NA },
        seed = 87542
      ) %>%
      
      # post-process
      mutate( pred = scl$M$drs + scl$SD$drs * .epred ) %>%
      mutate( pred = case_when( pred > 144 ~ 144, pred < 0 ~ 0, .default = pred) ) %>%
      ungroup() %>%
      select( id, time_y, .draw, pred ) %>%
      pivot_wider( names_from = time_y, values_from = pred ) %>%
      mutate( across( all_of( as.character( d_seq$time_y ) ), ~ .x-`-0.3` ) ) %>%
      pivot_longer( cols = -c("id",".draw"), names_to = "contrast" ) %>%
      group_by(contrast) %>%
      summarise( md = median(value), eti_low = qi(value,.width=.9)[1], eti_hig = qi(value,.width=.9)[2] ) %>%
      mutate( model = i, .before = 1 )
    
  )

# extract predictive contrast of one year post-minus-pre assessments
contr$all <-
  
  d_seq %>%
  add_predicted_draws( object = readRDS( here("mods","m0_linear.rds") ), newdata = . , allow_new_levels = T, re_formula = NA, seed = 87542 ) %>%
  mutate( pred = scl$M$drs + scl$SD$drs * .prediction ) %>%
  mutate( pred = case_when( pred > 144 ~ 144, pred < 0 ~ 0, .default = pred ) ) %>%
  ungroup() %>%
  select( id, time_y, .draw, pred ) %>%
  pivot_wider( names_from = time_y, values_from = pred ) %>%
  mutate( across( all_of( as.character( d_seq$time_y ) ), ~ .x - `-0.3` ) ) %>%
  pivot_longer( cols = -c("id",".draw"), names_to = "contrast" ) %>%
  group_by(contrast) %>%
  summarise( md = median(value), eti_low = qi(value,.width=.9)[1], eti_hig = qi(value,.width=.9)[2] ) %>%
  mutate( model = "all", .before = 1 )

# put it together
contr <-
  
  contr %>%
  do.call( rbind.data.frame, . ) %>%
  filter( !grepl("-",contrast) ) %>%
  pivot_wider( names_from = model, values_from = c("md","eti_low","eti_hig") ) %>%
  mutate( contrast = as.numeric(contrast) )


## posterior draws of fixed effects of all prediction models ----
post <-
  
  lapply(
    
    setNames(
      c("m1_lasso_doms","m2_lasso_tests","m3_doms_cov","m4_tests_cov"),
      c("factor scores","test scores","factor scores (with covariates)","test scores (with covariates)")
    ),
    
    function(i)
      
      readRDS( here( "mods", paste0(i,".rds") ) ) %>%
      as_draws_df() %>%
      `colnames<-` ( gsub("_drs","",names(.) ) ) %>% # rename parameters in covariate models to appropriate format
      select( starts_with( c("b_","bsp_") ) & !starts_with( c("b_bdi","b_led","bsp_bdi") ) ) %>% # keep only fixed-effects
      
      # back-transform posteriors to raw DRS-2 (or DRS-2 per year) scale
      mutate(
        b_Intercept = ( b_Intercept * scl$SD$drs ) + scl$M$drs,
        across( !b_Intercept, function(x) { x * scl$SD$drs } )
      ) %>%
      
      # calculate summaries
      apply(
        2 , function(x) {
          c(
            b = median(x), # posterior median
            PPI = hdci(x, .width = .95), # 95% PPI
            pdir = sum(x<0)/length(x) # Pr(b<0)
          )
        }
      ) %>%
      t() %>%
      as.data.frame() %>%
      rownames_to_column("Parameter") %>%
      
      # flag parameter group
      mutate(
        Group =
          case_when(
            Parameter == "b_Intercept" ~ "alpha", # global intercept
            grepl( "time|bdi:time|led:time", Parameter ) ~ "delta", # time varying effects
            .default = "beta" # pre-surgery associations
          )
      )

  ) %>%
  
  # pull both "cognitive functions" and "cognitive tests" models together
  do.call( rbind.data.frame, . ) %>%
  rownames_to_column("Predicted by:") %>%
  mutate( `Predicted by:` = sub( "\\..*" , "", `Predicted by:` ) )


# IN-TEXTS ----

itext <-
  
  reff %>%
  group_by( Parameter, `Model: ` ) %>%
  summarise(
    Md = rprint( median(Posterior), 2 ),
    PPI = paste0( "[", rprint( hdi(Posterior)[1], 2 ), ", ", rprint( hdi(Posterior)[2], 2 ), "]" )
  )


# TABLES ----

t2 <-
  
  lapply(
    
    setNames( c("factor","test"), c("factor","test") ),
    function(i)
      
      post[ post$`Predicted by:` == paste0(i," scores"), ] %>%
    
      # prepare variables
      mutate(
        Parameter = sapply( Parameter, function(j) v[ j, "name" ] ), # get publication-ready names
        `95% PPI` = paste0( "[", rprint(PPI1,2), ", ", rprint(PPI2,2),"]" ), # prepare 95% PPI bracket
        b = rprint( b, 2 ), # round median posterior
        pdir = rprint(pdir,3), # round Pr(b<0)
      ) %>%
      
      # finish the table
      select( Parameter, b, `95% PPI`, pdir, Group ) %>%
      arrange(Group) %>%
      
      # gt (pre-)formatting
      gt( groupname_col = "Group" ) %>%
      cols_align( columns = -1, align = "center" ) %>%
      cols_label( b ~ "{{*b*}}", pdir ~ "Pr({{*b*}}<0)" ) %>%
      text_transform(
        locations = cells_row_groups(),
        fn = function(x) case_when(
            x == "alpha" ~ "Global intercept (α)",
            x == "beta" ~ "Baseline correlates (β) ",
            x == "delta" ~ "Time-dependent parameters (𝛿)"
        )

    )
    
  )


# FIGURES ----

## patient-level variability ----
f2 <-
  
  reff %>%
  ggplot( aes(x = Posterior, y = Parameter, fill = `Model: ` ) ) +
  geom_density_ridges( rel_min_height = 0.01, linewidth = .75 ) +
  scale_y_discrete( labels = NULL ) +
  labs( y = NULL ) +
  scale_fill_manual( values = alpha( c( "gray89", cbPal[c(1,3,2)] ), .5 ) ) +
  theme_minimal( base_size = 10 ) +
  theme( legend.position = "bottom", strip.text = element_text(size = 9) ) +
  facet_wrap(
    ~ Parameter,
    ncol = 1,
    scales = "free",
    labeller =
      as_labeller(
        c( intercept = "SD(alpha[id])",
           slope = "SD(delta[id])",
           corr = "r(alpha[id],delta[id])"
        ),
        label_parsed
      )
  )

# save it
ggsave( plot = f2, file = here("figs","reff_variability.jpg"), dpi = 300, width = 6.6, height = 8 )


## contrast predictions ----
f3 <-
  
  contr %>%
  ggplot() +
  aes( y = contrast, x = md_fixed ) +
    
  # add lines and points
  geom_linerange( data = contr, aes(xmin = eti_low_all, xmax = eti_hig_all), linewidth = 5, colour = cbPal[8], alpha = .4 ) +
  geom_linerange( data = contr, aes(xmin = eti_low_random, xmax = eti_hig_random), linewidth = 5, colour = cbPal[8], alpha = .6 ) +
  geom_linerange( data = contr, aes(xmin = eti_low_fixed, xmax = eti_hig_fixed), linewidth = 5, colour = cbPal[8], alpha = 1 ) +
  geom_point( size = 5, colour = "black" ) +
    
  # finish it
  geom_vline( xintercept = 0, linewidth = 1, linetype = "dashed", colour = "navyblue" ) +
  labs( y = "Years post-surgery", x = parse( text = "Delta~`DRS-2`" ) ) +
  scale_x_continuous( breaks = seq(-15,5,1), labels = seq(-15,5,1) ) +
  coord_flip( xlim = c(-14,3) )

# save it
ggsave( plot = f3, file = here("figs","expectation_contrasts.jpg"), dpi = 300, width = 9.66, height = 5.5 )


## robustness check ----
f4 <-
  
  lapply(
    
    setNames( c("factor","test"), c("factor","test") ),
    function(i)
      
      lapply(
        
        setNames( c("alpha","beta","delta"), c("alpha","beta","delta") ),
        function(j)
          
          post %>%
          filter( grepl(i,`Predicted by:`) & Group == j ) %>%
          
          # prepare the labels
          mutate(
            
            title =
              case_when(
                j == "alpha" ~ "Global intercept",
                j == "beta" ~ "Baseline correlates",
                j == "delta" ~ "Time-dependent parameters"
              ),
            
            Parameter =
              case_when(
                j == "delta" ~ sub( "time:", "", Parameter ) %>% sapply( ., function(x) v[x, ] ),
                j != "delta" ~ Parameter %>% sapply( ., function(x) v[x, ] )
              )
            
          ) %>%
          
          # plotting proper
          ggplot( aes( x = reorder(Parameter, b, decreasing = T), y = b, ymin = PPI1, ymax = PPI2 ) ) +
          geom_linerange( aes( color = `Predicted by:`), size = 1, position = position_dodge( width = case_when( i == "factor" ~ .4, i == "test" ~ .6 ) ) ) +
          geom_point( aes( color = `Predicted by:`), size = 4, position = position_dodge( case_when( i == "factor" ~ .4, i == "test" ~ .6 ) ) ) +
          geom_hline( yintercept = 0, size = 1.1, linetype = "dashed", color = case_when( i == "factor" ~ "black", i == "test" ~ "red" ) ) +
          
          # scale the axes and colors
          scale_x_discrete( labels = ifelse( j == "alpha", parse( text = "alpha"), function(x) parse( text = paste0( j, "[", x, "]" ) ) ) ) +
          scale_y_continuous( limits = case_when( j == "alpha" ~ c( 139,142 ) ) ) +
          scale_color_manual( values =  case_when( i == "factor" ~ cbPal[c(7,2)], i == "test" ~ cbPal[c(6,3)] ) ) +
          
          # label and flip axes, position legend and add title
          labs( x = NULL, y = ifelse( j == "delta", expression(Delta*"DRS-2 (points per year)"), "DRS-2" ) ) +
          theme_minimal( base_size = 10 ) +
          theme( axis.text = element_text( size = 10 ), legend.position = "bottom" ) +
          facet_wrap( . ~ title) +
          coord_flip()
        
      )
    
  )

# list plot layouts for each figure
lo <- cbind( factor = c(1,7), test = c(1,23) )

# save them
for ( i in names(f4) ) {
  
  ggsave(
    
    # arrange the subplots
    plot =
      with(
        f4[[i]],
        ( (alpha / beta + plot_layout( heights = lo[ ,i] ) ) | delta ) +
          plot_layout( guides = "collect" ) &
          theme( legend.position = "bottom")
      ),
    
    # specify output file
    file = here( "figs", paste0(i,"_postsum.jpg") ),
    dpi = 300,
    width = case_when( i == "test" ~ 10, i == "factor" ~ 7),
    height = case_when( i == "test" ~ 10, i == "factor" ~ 7)
  
  )

}

```

## Posterior predictive check

To validate in-sample fit of our predictive models, we computed models’ “predictions” for each included patient and compared these predictions to observed values (see @fig-ppc). Note that since one of the advantages of multilevel modelling is partial pooling, i.e., shrinking parameter estimates towards each other and thus down-weighting the effect of influential outliers to reduce overfitting, models **are** neither expected nor required to replicate observed values exactly. Our models show reasonable fit to most patients with clear shrinkage in case of outliers (for instance patient S045 in @fig-ppc). Furthermore, while the **"time only," **“test scores” and the “factor scores” model provide similar posterior predictions for our patients, the “**factor** scores” model was influenced by outlying values to a small**er** degree **compared  to the "time only" and "test scores" models** (for instance patients S023, S107 or S124).

![Posterior predictive checks. Posterior predictions of included patients’ performance according to the descriptive and predictive generalized linear mixed models (GLMMs) reported in the main text. Lines represent expected (median) performance, shades represent 95% posterior probability intervals (PPIs) of the performance according to the GLMMs, dots represent observed values.](../figs/posterior_predictions.jpg){#fig-ppc}

```{r}
#| label: post-pred

# read posterior predictions
ppred <-
  
  read.csv( here("_data","ppred.csv"), sep = "," ) %>%
  mutate( `Predicted by:` = factor( Predicted.by., levels = c("time only","factor scores","test scores"), ordered = T ) ) %>%
  mutate( anid = as.numeric( as.factor(id) ) %>% sprintf("%03d",.) %>% paste0( "S",.) ) # anonymise patients

# extract mapping to anonymize patients
anon <- ppred[ with( ppred, time_y  == -2 & `Predicted by:` == "factor scores" ), c("id","anid") ]

# plot predictions and observed data for each subject separately
f5 <-
  
  d0 %>%
  filter( complete.cases(drs_tot) ) %>%
  mutate( anid = sapply( 1:nrow(.), function(i) anon[ anon$id == id[i], "anid" ] ), drs = drs_tot ) %>%
  
  # plotting proper
  ggplot( aes(x = time_y, y = drs) ) +
  
  # add prediction lines and 95% compatibility intervals
  geom_line( data = ppred, size = .6, aes(x = time_y, y = drs, group = `Predicted by:`, color = `Predicted by:` ) ) +
  geom_ribbon( data = ppred, alpha = .2, aes(x = time_y, y = drs, ymin = drs.lower, ymax = drs.upper, group = `Predicted by:`, fill = `Predicted by:` ) ) +
  
  # add observed points
  geom_point( color = "black", size = .6 ) +
  
  # finish the plot with the last cosmetic changes
  scale_color_manual( values = cbPal[c(1,2,3)] ) +
  scale_fill_manual( values = cbPal[c(1,2,3)] ) +
  facet_wrap( ~ anid, nrow =  9 ) + # arrange to a 14 x 9 grid
  labs( x = "Time after surgery (Years)", y = "DRS-2 (0-144 points)") +
  theme_minimal( base_size = 6 ) +
  theme( legend.position = "bottom" )

# save it
ggsave( plot = f5, filename = here("figs","posterior_predictions.jpg"), dpi = 300, width = 7.8, height = 4.8 )

```

## Supplementary presentation of results

**In @fig-contr we present visual summary of statistical estimates for both sample and population versions of our** ***RQ1*** **estimand (see Table 4 in the main text for numerical summary of this figure) as well as models prediction of raw data yet unobserved. For this presentation we selected 90% posterior equal-tailed intervals (ETIs) so that there is 5% probability the true score difference falls below the bottom bound and 5% probability the true score difference falls above the top bound of the interval. Notice that estimates for the sample are significantly more certain than estimates generalized to the assumed population via adding patient-level variability.**

![Posteriors medians and 90% equal-tailed intervals (ETIs) of post-minus-pre-surgery differences at monthly post-surgery assessments separately for the sample (dark pink) and population (medium pink) version of our RQ1 estimand. Light pink lines represent model's predictions of raw data differences (change scores).](../figs/expectation_contrasts.jpg){#fig-contr}

**In @fig-var we present side-by-side comparison of patient-level true score variability that remains after accounting for association between time after surgery and cognitive performance (of the descriptive time only model) compared to patient-level true score variability after accounting for association between cognitive performance and time after surgery combined with pre-surgery cognitive profile (of the predictive test scores and factor scores models). To ensure estimates are comparable across models, we refitted the time only model using regularizing (Lasso) priors identical to predictive models' priors instead of the non- and weakly-informative default** ***brms*** **priors of the time only model presented in the main text. Although it can be seen that regularizing priors shifted posterior distributions of patient-specific parameters towards zero (compare the time only (default) and time only (Lasso) estimates in @fig-var), adding pre-surgery cognitive profile as predictor shifted these distributions even further (compare the test and factor scores to the time only (Lasso) estimates in @fig-var).**

![Posterior distributions of patient-level true score variability after accounting for group-level association with time (time only models) or time and pre-surgery cognitive profile (test and factor scores). The plot includes standard deviations of patient-level intercepts (top row), slopes (middle row) and intercept/slope correlations (bottom row).](../figs/reff_variability.jpg){#fig-var}

In @tbl-posttest we present numerical summary of group-level posterior parameters of the “test scores” model while in @tbl-postfact we present numerical summary of group-level posterior parameters of the “factor scores” model which supplement the information presented in Figure 3 in the main text. Since only the interaction terms (i.e., the $\delta$ parameters) comprised empirical estimands for our query (*RQ2*), the remaining parameters were omitted from the main text.

```{r}
#| label: tbl-posttest
#| tbl-cap: Summary of group-level effects’ posteriors from the “test scores” generalized linear mixed model reported in the main text

# add footnotes
t2$test <-
  
  t2$test %>%
  tab_footnote( footnote = "All cognitive predictors were scaled such that negative values mean negative effect of pre-surgery deficit on longitudinal cognitive trajectory." ) %>%
  tab_source_note( source_note = "b: parameter value point estimate (posterior median); PPI: posterior probability interval; Pr(b < 0): probability that a parameter is negative, i.e., probability that the predictor has a negative effect on the outcome (this quantity does not apply to Intercept where it cannot be interpreted but it is reported for completeness); ×: statistical interaction term; STAI-X1: State-Trait Anxiety Inventory, the state version; STAI-X2: State-Trait Anxiety Inventory, the trait version; TMT-A: Trail Making Test, part A; TMT-B: Trail Making Test, part B; DS-F: Digit Span forward; DS-B: Digit Span backward; LNS: letter-number sequencing; SS-F: Spatial Span forward; SS-B: Spatial Span backward; TOL: Tower of London task; PST-D: Prague Stroop Test, dot color naming; PST-W: Prague Stroop Test, word color naming; PST-C: Prague Stroop Test, interference condition; COWAT: Controlled Oral Word Association Test; CFT: category fluency test; Sim.: Similarities; RAVLT-IR: Rey Auditory Verbal Learning Test, immediate recall; RAVLT-B: Rey Auditory Verbal Learning Test, recall of the interference set; RAVLT-DR: Rey Auditory Verbal Learning Test, delayed recall; RAVLT-Rec50: Rey Auditory Verbal Learning Test, delayed recognition from 50 items (15 correct answers + 35 distractors); RAVLT-Rec15: Rey Auditory Verbal Learning Test, delayed recognition, number of correctly identified from 15 items; FP-IR: Family Pictures, immediate recall; FP-DR: Family Pictures, delayed recall." )

# save & print it
gtsave( data = t2$test, filename = here("tabs","posteriors_test.docx") )
t2$test

```

```{r}
#| label: tbl-postfact
#| tbl-cap: Summary of group-level effects’ posteriors from the “factor scores” generalized linear mixed model reported in the main text

# add footnotes
t2$factor <-
  
  t2$factor %>%
    tab_footnote( footnote = "All cognitive predictors were scaled such that negative values mean negative effect of pre-surgery deficit on longitudinal cognitive trajectory.") %>%
    tab_source_note( source_note = "b: parameter value point estimate (posterior median); PPI: posterior probability interval; Pr(b < 0): probability that a parameter is negative, i.e., probability that the predictor has a negative effect on the outcome (this quantity does not apply to Intercept where it cannot be interpreted but it is reported for completeness); ×: statistical interaction term; EF/Att.: Executive functions/Attention; EM: Episodic memory; VWM: Verbal working memory; VM: Visuospatial memory; SS: Set shifting; An: Anxiety; SWM: Spatial working memory." )

# save & print it
gtsave( data = t2$factor, filename = here("tabs","posteriors_fact.docx") )
t2$factor

```

## Robustness checks

To confirm that our results are robust to effects of aging, dopaminergic medication, and depressive symptoms, we carried out a robustness check by fitting parallel “test scores” and “factor scores” models with additional group-level predictors age, levodopa equivalent daily dose (LEDD) and Beck Depression Inventory (BDI-II) **as well as their interaction with time after surgery**. Stan code for each of these models with the exact specification is available at **[https://github.com/josefmana/dbs_cogPRED](https://github.com/josefmana/dbs_cogPRED)** and is equivalent to the models reported in the main text.

Side-to-side comparison of models’ group-level parameters’ posterior summaries is presented in @fig-robtest for the “test scores” model and in @fig-robfact for the “factor scores” model. All models arrived at similar posteriors implying our results are robust to effects of aging, dopaminergic medication, and depressive symptoms. Importantly, the empirical estimands relating to *RQ2* (i.e., the time-dependent $\delta$ parameters) are similar across models leading to identical substantive conclusions.

![Robustness check (the “test scores” model). Posteriors medians and 95% posterior probability intervals (PPIs) of group-level parameters from the longitudinal generalized linear mixed model predicting post-surgery cognitive decline by pre-surgery cognitive test scores without (“test scores”) and with adjustment for covariates (“test scores (with covariates)”). All cognitive predictors were scaled such that negative values mean negative effect of pre-surgery deficit on prediction of longitudinal cognitive trajectory. See main text for acronyms.](../figs/test_postsum.jpg){#fig-robtest}

![Robustness check (the “factor scores” model). Posteriors medians and 95% posterior probability intervals (PPIs) of group-level parameters from the longitudinal generalized linear mixed model predicting post-surgery cognitive decline by pre-surgery latent cognitive factor scores without (“factor scores”) and with adjustment for covariates (“factor scores (with covariates)”). All cognitive predictors were scaled such that negative values mean negative effect of pre-surgery deficit on prediction of longitudinal cognitive trajectory. See main text for acronyms.](../figs/factor_postsum.jpg){#fig-robfact}

## Exploring electrode localization

**To explore association between electrode localization and post-surgery cognitive decline, we retrospectively gathered magnetic resonance imaging (MRI) data of patients from our data set and estimated volume of affected tissue (VAT) based on stimulation parameters at the time of MRI assessment and its intersection with subthalamic nucleus (STN) as well as its motor, associative, and limbic components.**

**Only patients with all (i) pre-surgery MRI for STN localization, (ii) post-surgery MRI for electrode localization, and (iii) stimulation parameters at time of MRI assessment for VAT computation were included. Pre-surgery images included T1-weighted (T1w) MPRAGE sequence acquired on 3 Tesla Siemens Symphony, Skyra or TrioTim System (Siemens, Erlangen, Germany) with Echo Time (TE) = 2.43-4.43 ms, Repetition Time (TR) = 1,870-2,300 ms, Flip Angle (FA) = 8-$15^\circ$, and Slice Thickness = 1-1.5 mm varying slightly across patients. Furthermore, pre-surgery T2-weighted (T2w) Spin echo scans were acquired on the same MRI machine as pre-surgery T1w with TE = 80-90 ms, TR = 2,000-2,440 ms, FA = $90^\circ$, and Slice Thickness = 2 mm. Post-surgery, T1w MPRAGE sequence was acquired on 1.5 Tesla Siemens Symphony, Skyra or Avanto System with TE = 2.43-3.93 ms, TR = 2,060-2,200 ms, FA = 8-$15^\circ$, and Slice Thickness = 0.9-1.0 mm. Pre-processing was conducted in Lead-DBS software ([lead-dbs.org](https://www.lead-dbs.org)). The outcome of this pre-processing was a set of estimated overlaps between VAT and STN (and its components) for each included patient.**

### Data set

```{r}
#| label: elloc

rm( list = ls()[ !ls() %in% c("rprint","ubound","cbPal","v") ] ) # clear environment

# read the data
for( i in names(readRDS( here("_data","vatplus_df.rds" ) ) ) ) assign( i, readRDS( here("_data","vatplus_df.rds" ) )[[i]] )

# extract inclusion/exclusion stats
incl <-
  
  d0 %>%
  filter( post == 0 ) %>%
  select(elloc_miss) %>%
  table( useNA = "always" )

```

**From total of `r sum(incl)` patients `r incl[length(names(incl))]` were included into analysis, `r incl["no mri"]` were excluded due to missing MRI at both pre- and post-surgery assessments, `r incl["post only"]` patients were excluded due to missing post-surgery MRI and `r english(incl["miss stim"])` patient was excluded due to missing stimulation parameters at time of MRI. While according to our estimates, there was higher mean overlap of VATs and motor STN compared to other STN components, for some patient we estimated high proportion overlap between their VAT and associative STN as well (see @tbl-intdesc). Moreover, our estimates imply that there was only small or no overlap between VAT and at least one STN in appreciable number of patients (see also @fig-leads). Since all patients in our data set showed at least some clinical improvement after STN DBS according to attending physicians, these cases can be attributed to noisy estimates rather than true misalignment between the lead and STN.**

```{r}
#| label: tbl-intdesc
#| tbl-cap: Overlap between volume of activated tissue and subthalamic nucleus components

# function to calculate descriptive statistics
descstat <-
  
  function( stat = "mean", d = d1, nrow, intersection, volume, dec = 2 ) {
    
    sapply(
      1:nrow,
      function(i)
        do.call( stat, list( 100 * d[ , intersection[i] ] / d[ , volume[i] ] , na.rm = T ) ) %>%
        rprint( dec = dec )
    ) %>%
      
      unlist( use.names = F )
    
  }

d1 <- d0 %>% filter( is.na(elloc_miss) & post == 0 ) # keep one value per included patient

# prepare the table
t4 <-
  
  struct %>%
    
  # calculate stats
  mutate(
    N = sapply( 1:nrow(.), function(i) sum( !is.na( d1[ , AtlasIntersection[i]] / d1[ , AtlasVolume[i]] ) ) ),
    Md = descstat( stat = "median", d = d1, nrow = nrow(.), intersection = AtlasIntersection, volume = AtlasVolume, dec = 2 ),
    `Min-Max` =
      paste0(
        descstat( stat = "min", d = d1, nrow = nrow(.), intersection = AtlasIntersection, volume = AtlasVolume, dec = 2 ), "-",
        descstat( stat = "max", d = d1, nrow = nrow(.), intersection = AtlasIntersection, volume = AtlasVolume, dec = 2 )
      ),
    M = descstat( stat = "mean", d = d1, nrow = nrow(.), intersection = AtlasIntersection, volume = AtlasVolume, dec = 2 ),
    SD = descstat( stat = "sd", d = d1, nrow = nrow(.), intersection = AtlasIntersection, volume = AtlasVolume, dec = 2 ),
    Hemisphere = case_when( side == "left" ~ "Left", side == "right" ~ "Right" ),
    .before = 1
  ) %>%
  
  # final touches
  select( Hemisphere, struct, N, Md, `Min-Max`, M, SD ) %>%
  mutate(
    struct =
      case_when(
        struct == "STN" ~ "Subthalamic nucleus (STN)",
        struct == "STN_motor" ~ "Motor STN",
        struct == "STN_associative" ~ "Associative STN",
        struct == "STN_limbic" ~ "Limbic STN"
      )
  ) %>%
  
  # format it
  gt( groupname_col = "struct" ) %>%
  cols_align( align = "center", columns = -1 ) %>%
  tab_source_note(
    source_note = "N: number of observations; Md: median; M: mean; SD: standard deviation; Numbers in all columns but N represent percentage points of overlap
    between estimated volume of activated tissue and patient's subthalamic nucleus."
  )

# save & print it
gtsave( data = t4, filename = here("tabs","vat_overlaps.docx") )
t4

```

![Position of electrodes as estimated by Lead-DBS.](../figs/leadbs_snapshot.png){#fig-leads}

### Statistical models

**Since we were able to use only subset of patients for analysis of association between electrode localisation and post-surgery cognitive decline, we first directly compared included versus excluded patients' clinical and neuropsychological baseline characteristic. We applied "Bayesian t-tests" for difference in means with unequal standard deviations of the following form:**

$$DV_i \sim~ N(\mu_0,\sigma_0), for~excluded~patients$$ $$DV_j \sim~ N(\mu_1,\sigma_1), for~included~patients$$ $$\mu_x \sim~ N(0,1), for x \in \{0,1\}$$ $$\sigma_x \sim~ E(1), for x \in \{0,1\}$$

**where *i* = 1…*$n_0$* with *$n_0$* excluded patients, *j* = 1…*$n_1$* with *$n_1$* included patients, *DV* is a dependent variable (i.e., the clinical or neuropsychological characteristic in question) *N()* is the Normal probability density function and *E()* is the Exponential probability density function. All dependent variables were standardized (i.e., mean-centered and scaled by their in-sample standard deviation) and response times log-transformed and then standardized before entering the analysis. The between-group differences were evaluated by calculating difference scores $\mu_1-\mu_0$ for means and $\sigma_1-\sigma_0$ for standard deviations. Posterior medians ad 95% PPI of these difference scores were then reported.**

**In the next step we directly compared post-surgery cognitive decline of included versus excluded patients. To do this, we adjusted the descriptive model from the main text to include slopes varying by inclusion/exclusion status:**

$$P(DRS_i = DRS_{max}) = 1 - T(\vartheta,\mu_i,\sigma), for DRS_i \in N_{max}, N_{max} = \{i: drs_i = drs_{max}\}$$ $$DRS_i \sim~ t(\vartheta,\mu_i,\sigma), for DRS_i \in N_1, N_1 = \{i: drs_i < drs_{max}\}$$ $$\mu_i = \alpha + \delta_{time}time_i + \beta_{inclusion}inclusion_i + \delta_{inclusion}time_iinclusion_i + z_{id[i]}\tau_{\alpha} + x_{id[i]}\tau_{\delta}time_i$$
**with default brms priors for all parameters (see Stan file at [https://github.com/josefmana/dbs_cogPRED](https://github.com/josefmana/dbs_cogPRED) for more information). We then extracted a measure of cognitive decline discrepancy between the two subsamples by re-scaling $\delta_{inclusion}$ to the original DRS-2 points/year scale.**

**Finally, to evaluate predictive value of VATs overlap with STN components, we adjusted the predictive models from the main text:**

$$P(DRS_i = DRS_{max}) = 1 - T(\vartheta,\mu_i,\sigma), for DRS_i \in N_{max}, N_{max} = \{i: drs_i = drs_{max}\}$$ $$DRS_i \sim~ t(\vartheta,\mu_i,\sigma), for DRS_i \in N_1, N_1 = \{i: drs_i < drs_{max}\}$$ $$\mu_i = \alpha + \delta_{time}time_i + \sum_{j=1}^{m} (\beta_{predictor[j]}predictor_{[j]i} + \delta_{predictor[j]}time_ipredictor_{[j]i}) + z_{id[i]}\tau_{\alpha} + x_{id[i]}\tau_{\delta}time_i$$

**such that each $predictor_{[j]i}$ represents one of the six combinations of VAT intersection with STN component (motor, associative and limbic) separately for each hemisphere. Furthermore, to reduce the amount of regularization we used *N(0,0.5)* priors for population level parameters $\alpha$, $\delta_{time}$, $\beta_{predictor[j]}$ and $\delta_{predictor[j]}$ instead of Bayesian Lasso. All variables were standardized (i.e., mean-centered and scaled by their in-sample standard deviation) befored entering the analysis. We used the set of $\delta_{predictor[j]}$ values as a measure representing the expected prognostic value of DBS affected proportion of STN for post-surgery cognitive decline rate. All models described in this section were fitted using four chains each with 2,500 samples out of which 500 samples were discarded as a warm-up.**

### Results

```{r}
#| label: bayes-ttest

# extract order of variables
ord <-
  
  tab %>%
  mutate( p = 2 * (1 - ifelse( mu_prob < .5, 1-mu_prob, mu_prob ) ) ) %>%
  mutate(
    var =
      case_when(
        var == "MDS-UPDRS III (ON medication)" ~ "MDS-UPDRS III ON",
        var == "MDS-UPDRS III (OFF medication)" ~ "MDS-UPDRS III OFF",
        var == "Disease duration at surgery (years)" ~ "Dis. dur. at surgery",
        .default = var
      )
  ) %>%
  mutate( var = sapply( var, function(i) strsplit( i, " (", fixed = T )[[1]][1] ) ) %>%
  arrange(p) %>%
  select(var)

# prepare figure of "Bayesian p-values"
f8 <-
  
  tab %>%
  
  # extract variables needed
  select( var, ends_with("prob") ) %>%
  mutate(
    var =
      case_when(
        var == "MDS-UPDRS III (ON medication)" ~ "MDS-UPDRS III ON",
        var == "MDS-UPDRS III (OFF medication)" ~ "MDS-UPDRS III OFF",
        var == "Disease duration at surgery (years)" ~ "Dis. dur. at surgery",
        .default = var
      )
  ) %>%
  
  # pre-process the table
  mutate( var = sapply( var, function(i) strsplit( i, " (", fixed = T )[[1]][1] ) ) %>%
  filter( var != "Sex" ) %>%
  pivot_longer( cols = -var, names_to = "Parameter", values_to = "prob" ) %>%
  mutate( var = factor( var, levels = ord$var, ordered = T ) ) %>%
  mutate(
    pdir = ifelse( prob < .5, 1-prob, prob ),
    `Directionality: ` = factor( ifelse( prob > .5, "excluded > included", "included > excluded" ) ),
    p = 2 * (1 - pdir)
  ) %>%
  
  # plot it
  ggplot() +
  aes( x = p, y = var, fill = `Directionality: ` ) +
  geom_bar( stat = "identity" ) +
  scale_fill_manual( values = c("skyblue","navy") ) +
  geom_vline( xintercept = .05, linetype = "dashed", linewidth = 1.2, colour = "red" ) +
  facet_wrap( ~ Parameter, ncol = 2, labeller = as_labeller( c( mu_prob = "mu", sigma_prob = "sigma" ), label_parsed ) ) +
  labs( y = NULL, x = "Bayesian p-value" ) +
  theme_minimal( base_size = 12 ) +
  theme( legend.position = "bottom", strip.text = element_text(size = 13) )

# save the plot
ggsave(
  plot = f8,
  filename = here("figs","bayes_ttest.jpg"),
  dpi = 300,
  width = 7.7,
  height = 9.5
)

```

```{r}
#| label: tbl-ttest
#| tbl-cap: Mean differences between included and excluded patients in pre-surgery clinical and neuropsychological variables

t5 <- 
  
  # prepare it
  tab %>%
  mutate( across( ends_with("prob"), ~ rprint(.x,3) ) ) %>%
  mutate( across( everything(), ~ ifelse( is.na(.x),"-",.x ) ) ) %>%
  mutate( across( everything(), ~ ifelse( .x == "NA","-",.x ) ) ) %>%
  
  # format it
  gt( rowname_col = "var" ) %>%
  cols_align( columns = -1, "center" ) %>%
  
  # columns
  tab_spanner( label = "Descriptive statistics", columns = 2:4, gather = F ) %>%
  tab_spanner( label = "μ", columns = starts_with("mu"), gather = F ) %>%
  tab_spanner( label = "σ", columns = starts_with("sigma"), gather = F ) %>%
  tab_spanner( label = "Bayesian t-test", columns = contains("_") ) %>%
  cols_label(
    n ~ "N",
    `0` ~ "Excluded",
    `1` ~ "Included",
    ends_with("sum") ~ "{{*d*}}",
    ends_with("prob") ~ "Pr({{*d*}}<0)"
  ) %>%
  
  # footnotes
  tab_footnote(
    footnote = "Values indicate mean ± standard deviation or frequency (percentage)",
    locations = cells_column_labels( columns = c("0","1") )
  ) %>%
  tab_source_note(
    source_note = "N: number of observations from excluded/included patients; μ: inference for mean difference between groups; σ: estimate of difference between standard deviations between groups; d: difference value point estimate (posterior median) [95% posterior probability interval] Pr(d < 0): probability that a difference is negative, i.e., probability that included patients had higher mean/stnadard deviation than excluded patients; MDS-UPDRS III: Movement Disorder Society Unified Parkinson’s Disease Rating Scale, motor part; LEDD: levodopa equivalent daily dose; Levodopa test: a percentage change of the MDS-UPDRS III score from medication OFF to medication ON state during the levodopa test; STAI-X1: State-Trait Anxiety Inventory, the state version; STAI-X2: State-Trait Anxiety Inventory, the trait version; TMT-A: Trail Making Test, part A; TMT-B: Trail Making Test, part B; DS-F: Digit Span forward; DS-B: Digit Span backward; LNS: letter-number sequencing; SS-F: Spatial Span forward; SS-B: Spatial Span backward; TOL: Tower of London task; PST-D: Prague Stroop Test, dot color naming; PST-W: Prague Stroop Test, word color naming; PST-C: Prague Stroop Test, interference condition; COWAT: Controlled Oral Word Association Test; CFT: category fluency test; Sim.: Similarities; RAVLT-IR: Rey Auditory Verbal Learning Test, immediate recall; RAVLT-B: Rey Auditory Verbal Learning Test, recall of the interference set; RAVLT-DR: Rey Auditory Verbal Learning Test, delayed recall; RAVLT-Rec50: Rey Auditory Verbal Learning Test, delayed recognition from 50 items (15 correct answers + 35 distractors); RAVLT-Rec15: Rey Auditory Verbal Learning Test, delayed recognition, number of correctly identified from 15 items; FP-IR: Family Pictures, immediate recall; FP-DR: Family Pictures, delayed recall."
  )

# save & print it
gtsave( data = t5, filename = here("tabs","bayes_ttest.docx") )
t5

```

![Between-group comparisons of included vs excluded patients. Bayesian p-values were calculated as half of the probability that the difference parameter (described by its posterior distribution) is strictly positive or negative. Lower values imply higher probability of difference between groups. Conventional < .05 value is marked by the red dashed line. The left column relates to mean differences while the right column relates to differences in standard deviations.](../figs/bayes_ttest.jpg){#fig-ttest}

```{r}
#| label: locincl-desc

m6 <- readRDS( here("mods","m6_desc_check.rds") ) # read the model

# extract diagnostics
rhat_max <- ubound( max( rhat(m6) ), dec = 3 )
park_max <- ubound( max( loo(m6)$diagnostic$pareto_k ) )
park_big <- sum( loo(m6)$diagnostic$pareto_k > .7 )

# prepare a table with basic comparisons
# will do it via two (equivalent in this case) ways

# 1) from predictions via posterior_epred
#b <-
#  
#  m6 %>%
#  posterior_epred( newdata = expand.grid( time = c(0,1), elloc = c(0,1), id = "sub000" ), allow_new_levels = T, re_formula = #NA ) %>%
#  as.data.frame() %>%
#  rename( "pre_0" = "V1", "post_0" = "V2", "pre_1" = "V3", "post_1" = "V4" ) %>%
#  mutate(
#    slope_0 = post_0 - pre_0,
#    slope_1 = post_1 - pre_1,
#    intercept_dif = pre_1 - pre_0,
#    slope_dif = slope_1 - slope_0
#  ) %>%
#  select( !starts_with("post") ) %>%
#  mutate(
#    across( starts_with("pre"), ~ .x * scl$SD$drs + scl$M$drs ),
#    across( !starts_with("pre"), ~ .x * scl$SD$drs )
#  ) %>%
#  apply( 2, median_hdi ) %>%
#  do.call( rbind.data.frame, . ) %>%
#  mutate(
#    md = rprint(y,2),
#    md_abs = rprint( abs(y),2 )
#    ppi = paste0( "[", rprint(ymin,2), ", ", rprint(ymax,2), "]" )
#  )

# 2) directly via transformation of posterior parameter draws
b <-
  
  m6 %>%
  as_draws_df() %>%
  select( all_of( starts_with("b_") ) ) %>%
  mutate(
    pre_0 = b_Intercept - 0.5 * b_elloc1,
    pre_1 = b_Intercept + 0.5 * b_elloc1,
    slope_0 = b_time - 0.5 * `b_time:elloc1`,
    slope_1 = b_time + 0.5 * `b_time:elloc1`,
    intercept_dif = pre_1 - pre_0,
    slope_dif = slope_1 - slope_0
  ) %>%
  select( !starts_with("b_") ) %>%
  mutate(
    across( starts_with("pre"), ~ .x * scl$SD$drs + scl$M$drs ),
    across( starts_with("slope"), ~ .x * scl$SD$drs )
  ) %>%
  apply( 2, median_hdi ) %>%
  do.call( rbind.data.frame, . ) %>%
  mutate(
    md = rprint(y,2),
    md_abs = rprint( abs(y),2 ),
    ppi = paste0( "[", rprint(ymin,2), ", ", rprint(ymax,2), "]" )
  )


```

**Pre-surgery differences between included and excluded patients are presented in @tbl-ttest and @fig-ttest. The descriptive model comparing post-surgery cognitive decline in excluded versus included patients had satisfactory convergence statistics ($\hat{R}s \leq `r rhat_max`$). All observations had Pareto-k below `r park_max`. According to the model, included patients experienced an average post-surgery decline of `r b["slope_1", "md_abs"]` DRS-2 points/year (95% PPI `r b["slope_1", "ppi"]`) from an average pre-surgery DRS-2 performance of `r b['pre_1','md']` points (95% PPI `r b["pre_1","ppi"]`) whereas excluded patients experienced an average post-surgery decline of `r b["slope_0", "md_abs"]` DRS-2 points/year (95% PPI `r b["slope_0", "ppi"]`) from an average pre-surgery DRS-2 performance of `r b['pre_0','md']` points (95% PPI `r b["pre_0","ppi"]`). Although, on average the post-surgery cognitive decline was slower in included patients by `r b['slope_dif','md_abs']`, the difference was not statistically clear based on 95% PPI `r b['slope_dif','ppi']`.**

```{r}
#| label: vat-overlaps

rm( list = ls()[ !ls() %in% c("rprint","ubound","cbPal","d0","d1","df","scl","struct","v") ] ) # clear environment

m7 <- readRDS( here("mods","m7_stn_intersect.rds") )

# extract diagnostics
rhat_max <- ubound( max( rhat(m7) ), dec = 3 )
park_max <- ubound( max( loo(m7)$diagnostic$pareto_k ) )
park_big <- sum( loo(m7)$diagnostic$pareto_k > .7 )

# extract draws
drws <-
  
  m7 %>%
  spread_draws( `b_.*`, regex = T ) %>% # extract all "fixed-effect" parameters
  select( contains("b_") ) %>% # get rid of the info about chains
      
  # re-scale to DRS-2 raw scale
  mutate(
    b_Intercept = ( b_Intercept * scl$SD$drs ) + scl$M$drs,
    b_time = b_time * scl$SD$drs,
    across( contains("STN"), ~ .x * scl$SD$drs * ( 0.1 / scl$SD[[ sub("b_","", sub("b_time:","", cur_column() ) ) ]] ) ) # expected DRS-2 change for 10% jump in VAT/STN overlap (the same for 40->50 % and 50->60 %)
  ) %>%
      
  relocate( b_time, .after = "b_STN_limbic_right_proportion" )

# prepare the figure
f9 <-
  
  # prepare the draws
  drws %>%
  select( contains("time") ) %>%
  pivot_longer( cols = everything() ) %>%
  mutate( name = sub( "time:", "", name ) %>% sapply( ., function(x) v[x, ] ) ) %>%
  
  # plotting proper
  ggplot() +
  aes( x = value, y = reorder(name, value, decreasing = T), fill = stat(x) ) +
  geom_density_ridges_gradient( scale = 1.5, rel_min_height = 0.001 ) +
  scale_fill_viridis_c( option = "turbo", direction = -1 ) +
  geom_vline( xintercept = 0, linewidth = .75, linetype = "solid", color = "black" ) +
  labs( x = expression(Delta*"DRS-2 (points per year)"), y = NULL ) +
  scale_x_continuous( limits = c(-2,2) ) +
  scale_y_discrete( labels = function(x) parse( text = paste0( "delta[", x, "]" ) ) ) + # add predictor parameter names
  theme_minimal( base_size = 12 ) +
  theme( legend.position = "none", axis.text.y = element_text(size = 12) )

# save it
ggsave( plot = f9, filename = here("figs","vat_postdist.jpg"), dpi = 300, width = 6.3, height = 7.7 )

```

**Finally, the predictive model comparing post-surgery cognitive decline depending on proportion of STN components volume being affected by VAT had satisfactory convergence statistics ($\hat{R}s \leq `r rhat_max`$). However, there were `r english(park_big)` potentially influential observations with Pareto-k above 0.7, the highest Pareto-k reached the value of `r park_max`. Results summarising group-level effects are presented in @fig-vatpost, @fig-vatcolin, and @tbl-vatpost. **

```{r}
#| label: tbl-vatpost
#| tbl-cap: Summary of group-level effects’ posteriors from the generalized linear mixed model predicting cognitive performance by subthalamic nucleus components being stimulated

# extract and summarize posteriors of the "fixed-effects"
t6 <-
  
  # prepare the table
  drws %>%
  apply(
    2, function(x) {
      c( b = rprint( median(x), 2 ), # posterior median
         PPI = paste0( "[", paste( rprint( hdi(x, .width = .95), 2 ), collapse = ", " ), "]"), # 95% PPI
         pdir = rprint( sum(x<0)/length(x), 3 ) # Pr(b<0)
         )
    }
  ) %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column( var = "Parameter" ) %>%
  mutate(
    Group =
      case_when( Parameter == "b_Intercept" ~ "alpha", # global intercept
                 grepl( "time", Parameter ) ~ "delta", # time varying effects
                 .default = "beta" # pre-surgery associations
                 ),
    Parameter = sapply( 1:nrow(.), function(i) v[ Parameter[i], "name" ] )
  ) %>%
  
  # format it
  gt( groupname_col = "Group" ) %>%
  cols_align( columns = -1, align = "center" ) %>%
  cols_label( b ~ "{{*b*}}", PPI ~ "95% PPI", pdir ~ "Pr({{*b*}}<0)" ) %>%
  text_transform(
    locations = cells_row_groups(),
    fn = function(x) case_when(
      x == "alpha" ~ "Global intercept (α)",
      x == "beta" ~ "Baseline correlates (β) ",
      x == "delta" ~ "Time-dependent parameters (𝛿)"
    )
  ) %>%
  
  # foot notes
  tab_footnote(
    footnote = "Parameters represent expected increase/decrease of cognitive performance assessed via Dementia Rating Scale, second edition, associated with observing an increase of volume of activated tissue (VAT) intersection proportion with subthalamic nucleus (STN) component by 10 % of total volume of the component. Time dependent effects measure association between predictor and outcome per one year."
  ) %>%
  tab_source_note(
    source_note = "b: parameter value point estimate (posterior median); PPI: posterior probability interval; Pr(b < 0): probability that a parameter is negative, i.e., probability that the predictor has a negative effect on the outcome (this quantity does not apply to Intercept where it cannot be interpreted but it is reported for completeness); ×: statistical interaction term; ML: left motor STN; MR: right motor STN; AL: left associative STN; AR: right associative STN; LL: left limbic STN; LR: right limbic STN."
  )

# save & print it
gtsave( data = t6, filename = here("tabs","posteriors_vat.docx") )
t6

```

![Full posterior distributions of interaction terms of the model predicting post-surgery cognitive decline by proportion of subthalamic nucleus (STN) components that is being stimulated. All posteriors were scaled such that effects associated with each predictor represent comparisons of expected yearly cognitive decline between patients differing by ten percentage points in overlap of affected proportion of the relevant STN component. Acronyms are explained in Table S6.](../figs/vat_postdist.jpg){#fig-vatpost}

```{r}
#| label: vat-colin

# prepare variable names for parsing
vars <-
  
  v[ c("b_Intercept", "b_time",rownames(v)[ grepl("STN",rownames(v) ) ] ), ] %>%
  sub( " × Time", "", . ) %>%
  paste0( c("alpha", "delta[", rep("beta[",6), rep("delta[",6) ), . ) %>%
  paste0( ., "]" ) %>%
  sub( "Intercept]", "", . )

# plot it
f10 <-
  
  # extract collinearity
  cov2cor( vcov(m7) ) %>%
  `colnames<-`( parse( text = vars) ) %>%
  `rownames<-`( parse( text = vars) ) %>%
  
  # plot it
  ggcorrplot(
    method = "circle",
    type = "lower",
    colors = c( cbPal[7], "white", cbPal[6] ),
    show.legend = T, legend.title = "Pearson's r: ",
    show.diag = F
  ) +
  
  # finish it 
  theme_minimal( base_size = 12 ) +
  theme( legend.position = "bottom" ) +
  scale_y_discrete( labels = function(y) parse(text=y) ) +
  scale_x_discrete( labels = function(x) parse(text=x) ) +
  labs( x = NULL, y = NULL )

# save it
ggsave( plot = f10, filename = here("figs","vat_colin.jpg"), dpi = 300 )

```

![Collinearity metrics of group-level parameters of the model predicting cognitive decline by the proportion of subthalamic nucleus components volume that is affected by stimulation.](../figs/vat_colin.jpg){#fig-vatcolin}

## Estimation of false positive rates

To test our assumption that the classical two-step **univariable screening** procedure of identifying significant pre-surgery predictors of post-surgery cognitive decline leads to inflated false positive rates that can be alleviated by either dimension reduction of the matrix of predictors (e.g., via factor analysis) or applying the Bayesian Lasso, we conducted a series of simulations **based** on the data structure equivalent to our data set with respect to the number of patients, the number of observations per patient, time from surgery of each observation and the number of potential predictors. Simulated data sets used to produce our results as well as generating functions are available at **[https://github.com/josefmana/dbs_cogPRED](https://github.com/josefmana/dbs_cogPRED)**. The reader should navigate to the **“scripts/sims.R”** file to validate our findings and check their robustness to change in parameters which were omitted from current study for parsimony and computational time reasons.

### Data-generating process

```{r}
#| label: sims

rm( list = ls()[ !ls() %in% c("rprint","ubound","cbPal","v") ] ) # clear environment


# CORRELATION STRUCTURE ----

# putative covariation (correlation in this case) structure of predictors in our study
# based on grouping of tests to common clusters with ~50 % shared variability (i.e., r = .7, R2 = .49) 
cov23 <-
  
  read.csv( here("_data","sim_covstruct.csv"), sep = ",", header = F ) %>%
  `colnames<-`( 1:ncol(.) ) %>%
  as.matrix()

# plot the correlation matrix
f5 <-
  
  melt(cov23) %>%
  rename( "Pearson's r" = "value" ) %>%
  ggplot( aes(x = Var1, y = rev(Var2), fill = `Pearson's r` ) ) +
  geom_tile( color = "grey" ) +
  scale_fill_gradient2( low = "white", high = cbPal[7], limit = c(0,1), midpoint = .33 ) +
  labs( x = "Row variable", y = "Column variable" ) +
  scale_x_continuous( breaks = 1:23, labels = 1:23 ) +
  scale_y_continuous( breaks = 1:23, labels = 23:1 ) +
  guides( fill = guide_colourbar( barwidth = 1, barheight = 18 ) ) +
  theme_classic( base_size = 10 ) +
  coord_fixed()

# save the plot
ggsave(
  plot = f5,
  filename = here("figs","sims_corrstruct.jpg"),
  dpi = 300,
  width = 8.2,
  height = 4.7
)


# SIMULATION RESULTS ----

falsepos <-
  
  read.csv( here("mods","sims_fp.csv"), sep = "," ) %>% # read the results
  rename( "Method:" = "Method.") %>%
  mutate( `Method:` = ifelse( `Method:` == "Two-step procedure", "Univariable screening", `Method:` ) )

# plot it
f6 <-
  
  falsepos %>%
  ggplot( aes(x = fp, y = Freq+1, fill = `Method:` ) ) +
  geom_bar( stat = "identity", position = position_dodge( width = .66), width = .66 ) + # bars
  geom_text( aes(label = Freq), vjust = -.6, size = 2.5, position = position_dodge(width = .66 ) ) + # counts
  scale_y_continuous( limits = c(0,105), breaks = seq(1,101,25), labels = seq(0,100,25), name = "Count" ) +
  scale_x_discrete( name = "False positives per one hundred simulations" ) +
  scale_fill_manual( values = cbPal[c(2,1)] ) + # colors
  theme( legend.position = "bottom" ) +
  facet_grid( Covariance ~ Decline, labeller =  label_parsed )

# save it
ggsave(
  plot = f6,
  filename = here("figs","sims_falsepos.jpg"),
  dpi = 300,
  width = 7.7,
  height = 7.7
)

```

The outcome (representing idealized cognitive screening score) followed Gaussian distribution with unit variation and mean shifted from zero by (i) patient-specific intercept (pre-surgery shift) and slope (post-surgery decline shift) and (ii) an average annual post-surgery decline (i.e., population-level slope denoted *$b_1$* henceforth). The *$b_1$* parameter was set to either no (*$b_1$* = 0), mild (*$b_1$* = -0.3) or moderate (*$b_1$* = -0.5) average annual post-surgery decline (see columns of @fig-sims). Moreover, total of seven or twenty-three potential pre-surgery predictors were generated for each patient. In all cases, all potential pre-surgery predictors were set to have no effect on the outcome so that all effects identified by either procedure were false positives.

For each patient we generated a set of predictors based on either the test scores structure or the latent factor scores structure of our data set. Because there were seven independent latent factors extracted from our data by EFA with varimax rotation, the first set of potential pre-surgery predictors consisted of seven independent Gaussian variables with mean zero and unit variation (see the first row of @fig-sims). Regarding potential pre-surgery predictors based of the test scores structure of our data set, we opted to generate two distinct sets of such potential predictors, one consisted of twenty-three independent variables (see the second row of @fig-sims) while the other consisted of twenty-three covaried variables (see the third row of @fig-sims). In both cases, the potential pre-surgery predictors were generated from Gaussian distribution with zero mean and unit variance. Twenty-three independent predictors were generated to test the “best case scenario” whereby data satisfy the assumption of independence of predictors implicit in both the **univariable screening** procedure and the Bayesian Lasso. Twenty-three covaried predictors were generated to test the more realistic scenario whereby there is a non-zero covariance structure among potential pre-surgery predictors derived from single test scores (which unlike the varimax rotated factor analysis results do not invoke statistical independence). In these simulations, we opted to generate potential predictors via a multivariate Gaussian distribution with zero marginal means, unit marginal variances and a minimal covariance structure whereby predictors representing test scores derived from the same task (e.g., TMT-A and TMT-B) share about 50% of variance while potential predictors representing test scores derived from distinct tasks (e.g., TMT-A and RAVLT-IR) do not share any variance (see @fig-corr for the exact covariance structure used for our simulations).

![Covariance matrix of the covaried test scores predictor structure. The figure represents correlations used for generation of covaried predictors in the covaried test scores data-generating process. Orange clusters represent high correlations among State-Trait Anxiety Inventory, Tail Making Test, Digit Span, Spatial Span, Stroop task, verbal fluency, Rey Auditory Verbal Learning Test and Family Pictures test respectively. The single non-correlated cells represent the Tower of London task and Similarities task.](../figs/sims_corrstruct.jpg){#fig-corr}

### Statistical models

For each combination of population-level slope *$b_1$* (none, mild and moderate decline) and potential pre-surgery predictor structure (seven independent, twenty-three independent and twenty-three covaried predictors), total of one hundred **univariable screening** procedure and one hundred Bayesian Lasso models were fitted on the same one hundred simulated data sets with null effect of each potential predictor. For the **univariable screening** procedure, first an independent linear mixed model (LMM) with correlated patient-level intercepts and slopes was fitted for each predictor (including the effect of time, predictor and their interaction) and if the p-value of the interaction term between predictor and time showed *p* < .2 (the results were not sensitive to this threshold as the reader can validate by running the code themselves while changing the threshold) the predictor was then entered into a multiple LMM with all such predictors included at the same time; all predictors for which their interaction term with time showed *p* < .05 in this second multiple regression LMM were declared significant and constituted a false positive error. For the Bayesian Lasso, single LMM with correlated patient-level intercepts and slopes including all potential predictors, time and their interactions was fitted and all predictors with probability of direction > 2.5 % (which is equivalent to two-sided *p* < .05) were declared significant and constituted a false positive error.

### Results

The results of simulations are presented in @fig-sims. It is clear that both factors theorized to alleviate the false positive error rates (i.e., the Bayesian Lasso and dimension reduction of the potential predictors structure) can do so in our data structure according to these simulations. Moreover, applying the **univariable screening** procedure to our data set seems to incur a high risk of inflated false positive error rates even in the best case scenario.

![Simulation results. The figure presents number of false positives per one hundred simulations dependent on (i) method used (colour), (ii) assumed average annual post-surgery decline (columns) and (iii) potential pre-surgery predictor structure (rows).](../figs/sims_falsepos.jpg){#fig-sims}
